{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/autoencoder_db/\"\n",
    "\n",
    "\n",
    "loader = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = datasets.ImageFolder(data_dir + 'train', transform=loader)\n",
    "valid_data = datasets.ImageFolder(data_dir + 'valid', transform=loader)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "\n",
    "unloader = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Image Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_im(tensor, title):\n",
    "    image = tensor.cpu().clone()\n",
    "    x = image.clamp(0, 255)\n",
    "    x = x.view(x.size(0), 3, 96, 96)\n",
    "    save_image(x, \"./generated_data_vae/ezperiment_13_0.7_mean_mse/image_{}.png\".format(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3\n",
    "nz = 100\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, have_cuda):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.have_cuda = have_cuda\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1024, 4, 1, 0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(1024, ngf * 8, 8, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 3, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Change input size in fc1 to your flattened output\n",
    "        self.fc1 = nn.Linear(82944, 512)\n",
    "        \n",
    "        self.fc21 = nn.Linear(512, nz)\n",
    "        self.fc22 = nn.Linear(512, nz)\n",
    "\n",
    "        self.fc3 = nn.Linear(nz, 512)\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        conv = self.encoder(x)\n",
    "        h1 = self.fc1(conv)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        deconv_input = self.fc4(h3)\n",
    "        deconv_input = deconv_input.view(-1,1024,1,1)\n",
    "        return self.decoder(deconv_input)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if self.have_cuda:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        decoded = self.decode(z)\n",
    "        return decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    the_loss = BCE + 0.7*KLD\n",
    "    return the_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader):\n",
    "    test_loss = 0\n",
    "    for data in testloader:\n",
    "        images, _ = data\n",
    "        images = images.cuda()\n",
    "        decoded, mu, logvar = model.forward(images)\n",
    "        test_loss += loss_function(decoded, images, mu, logvar).item()\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(have_cuda=True)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvWeYXdd1Jbjuy6le5YBCKgSCICJB\ngABJMAeRlERRWbSoaKnVtuXudpix3T3ffN39dfR849TtsT2yZMlykmRZyUrMoBIJAiRIgsipgAIq\n53o53fmx177nvKoCUAwuq6fu/vOq3j333nPDOzutvbbjui588cWXpSWBf+4J+OKLL4sv/g/fF1+W\noPg/fF98WYLi//B98WUJiv/D98WXJSj+D98XX5ag+D98X3xZgvKmfviO4zzgOM4Jx3FOO47zO2/V\npHzxxZd/WnHeKIDHcZwggJMA7gNwEcABAL/guu7Rt256vvjiyz+FhN7EvrsBnHZd9ywAOI7zFQAP\nA7jsD7+tJe32LO8AarW5GwMOP4PyaS1IlXIJAFAulQEA2ZkMACCZSHhjopGI7B6gERO0jBk9ljv7\nvLbBM2sBdHSbM2eq3tS4aSaTM0cMyvxTzS1zrsMck99xrjVeFwBk83kAQL4gnx2dHbLBvmf6N8+F\nitm/Vq1yiIwpVyryWa6YMZxTKCz3LBqLyf+hsJmqIxfnOpc3Cp15/rIOcNnRb0bsp/TWHHH+Y19O\n5j3n7B3nHSTPo8pnVSoXvS2VirzfqVSq7gBO3b3Xg856HvYrHQigt7cXo6OjV701b+aHvxxAn/X/\nRQB7Zg9yHOczAD4DAKu623Hwm78PFMwPBXxRkZCXD3rxpZI3ZKx/AAAweKkfAPDcsz8GAOy+/gZv\nzPrVq+UwcT1O3JxDfyh63qDel4g1D/4w9GbzR4GgPUaecKUm+1cd+eH96LmD3pBYuhEAcNsHHpEv\niuZHiSgXqhrflLj8P9Pf7w058NrLAIBjR18DAHz2N35dNuQz5jh6HekG+Rwd9jZlp6cBALmcjBka\nHgMAXBoY9Mbky3LPO5bJPVu7YSMAoKWj0xsTDMl114JRAGYhsEW/c3gf7DEuv9MXNhDgq+ZaL+48\nxzQHmP/rir375fd+Q+KietUxzjxndYqBugmp7qrXK1kAwMSkvMsXL53xNo0My/Pfu/cWAEAwKPcq\nFE5ZB+Ci7PKzJmNcs37Aicaxa8+uq14D8OZ++PPd9zmPy3XdzwH4HABsXtHmvvbNb6Gje5m3vaVb\nXrbChOx6YVhe4qHRMW9MhVorGpYf9Uc+8hGZvLXahYKqrTitrHVHVDPG+ENx+SPPGy3oVuRgLl9G\nNUBgr7p8IMGwnCsQkh/F9bvNevfj/bIIHP7JzwAAW+++D9YB5KPAueVlcXvimR95I8qQ7z7zmV8C\nALz6/AsAgJXLOrwx2ZlJAMDEy/JjzkxPmuuoynXs2iUvQPv6DQCALaGYN2Z6UO7x6IQsEiFeTyRq\nLChE5NqC7jyaRn+ws3+4jm0DzLaYZn8auZK3OdtIq82zIjiOy895fpSXXR7mWp2XHwu4PO98i0Mw\ntIBQGRe+xnSz7BNc523qaG8FALzyiiz2GzfKQhwJm+PGYlwEHF0AeM0xo5jcQn5+a3q+6Sxo1Pxy\nEcBK6/8VAPovM9YXX3z5OZI388M/AOAax3HWOI4TAfAIgO+8NdPyxRdf/inlDZv6rutWHMf5VQCP\nQWzYv3Bd98iV9gmEgkg0NSJfNSb2ub5LAICJ7AwAYDIvvlA81eCNWb9+PQBg5YrVPLl81LIFc/AG\n8a0REZO2PDTkbSoU5HwxBq8qNVnv4q3Gp3UYQAT93yodNddaG0u0oipuqG5bc1ePN6alaxQA8OWv\nfhMA8EDWmF4VmpLZnATuErzGcCLtjVnR1QQAePKppwEAHe1tAICfPPe8N+bUMTEJ77njDgDAzQ+9\nx9yHIu+Jnpam+pH9+70hmbzEHfbcea98EZV7VsubeERAXRz11ef1x6+kNxbugevI2jwm/+yvwoH5\njjv7O9vcfSNZq8ubyws5mncdNet+BuRLdQ/TjS3etnSjmP9trV0AgG984xsAgNWr13hjdt9AdzLC\na2WcqsiYDgBEG9KWj3pleTM+PlzX/T6A77+ZY/jiiy+LL2/qh/96JZpIYe2NtwClvPddoSh/d+oq\nG5YVKxKLemMiYQ1McUw0Kf/NGI0/c0k0fJgBqliDWVEbEhxPzZBncG3o4og3Js80Wi4v2wpMsWUK\nJkiYoabOlcQqULvFCZq5ti9bDgDoue56AMCKdRu9bU1t7QC85ABKtC46O43lEY9r8EiuNTMmczz2\nmjGmPvHpfwkAaFkh56qNm0BooFkshoGjxwAALxx8CYDRKgCw+5bbdOL8Rl6DQNyk8wpZyQrE4o2Y\nI7O1/wK1jOxraVN3VjTcPsyslKmRhQSvzBgvKLcAvIqXpbiCtTLfNsaevWi+ZpRNeN8SjVY6VraI\n8y0Uxdr9wIc+BgB48rEfeiOeePoZAMBtfHaxuLzT0bSdvSpioRaOD9n1xZclKIuq8eG6qJVKCFhp\no1iTaJRYmKsj/SLXsgqK1MYVatpiRrRg6/K13pjGZrEKqjnx1aetbN6Z3vPyeeGiHIer9plTp7wx\n0aho7dZ20cqresS/6llv/Kz2TvHBWqi5kdQ8q1k/pycltXYvrYxozFzrZIbxC67WmmUslmrW/hLz\nKBblAr5Df+8D73+vNybdJn4/spLbD8RNvveZb4vn1c7r6Fkn6bxly00CJtnBdKojj7+Sk3NVLG0W\nS4nl4Naurs0ddyEafx5N5FxBe19mm7sAjb8Q7R64AjBpIVrTtcYEmVd25ih4e64ERLnEPNTdM/k7\nGW+p+//e+x/yRjz/E8Gu/PDxxwEAdzG+09jUZA4TNhbb1cTX+L74sgRlUTW+6ziohCKolQ0IolwQ\nLVghqCYQlJU0FjFTi8Xpx6REK6ca1Ek22YG+i+cAAMfOisYcnjHIvxyj8E3dovWu3bgJAPDhX/lN\nMzlFEKr/GuL57YWZ2q/GrESNMLJQxKy0FUcsjyQ1fclSHomUaPo8v6yVazyVURUBZiX2PfEkAOCh\n97xP9k2byH85KxZQkCrmmaee9LbtvPEmOS+RjyMEQnV0rzYToaYfH5FtzS1tnIeJVRSYHYhFbPTY\nGxDV3J4WnqsF59ew82t2ZwGg3SsBAt+wruP8FQpds4AyoXD9Cb24QtXMVYdrHCFoI0L1OnivpifG\nAQAx67266VbR8KePCyL+h0+I/38HNT8AdHV1YGExEF/j++LLkhT/h++LL0tQFtXUd4IhRJpaULMC\nd7UyzeWAmNqRELHyNeMOFBjcK+emAAANaQlcPUOQCwCMT0tQsOc6Kdy5bs913rbmVQIASrUL3j1L\nXEW2aOah9QBqioVpvgWCxtzSoFGNprLi0XMW8CXdLKAc/SqXM+dobIzXnUNNfMurwZe//DUAwLYt\nWwEAsYSY2kHLDHd5/h/t2wcAuH7nTd62IKsUD7wg+P+9e5m6s4KMWn/Q0tEtxyPipFAw7lEklsRV\nZSGZIy9lpyaoZRZrasut1n/CxsTXp+MCActEnhXE0zH1wb3APN/V/6/PQys7nblRujkmvr1/OVDi\nd7w2rxDJcuH4t+MV28z1R/IZca/STfKeuhWTrs5MyLu/njj+dKM8n5/+9FlvzN69e1EpW0VhVxBf\n4/viyxKURdX41WoFE+MTCFlVR8GgroQiWptsa/wIobYxBStQO+csyO7mrVKNtvHthK9alb8Zlt9W\nZhXHxawAi6atat5KLnO0136HGiEQ0AANr8E1VgGL45Bh6q6l2WjOQpF18LRqNKb33e894Y3p6BJQ\nzo6du3iOIC/ZrOTPPf8cAGDVGrFkWq1U3aEDBwAA23cKxLOpS7R61QqE5pkqTDUwFaS8ALA1LtNP\nC4sVAagPtRmFOCvVVad46zV+zTXXWK0yrcs5uZ5VYFVU8iRVBmarFZZNV8wY/dtobPle07eA0fQh\nBnT1EwCCtPjmq/wzc2VgmoCdIB9ssA6ko2XJqP+EqQiPp8QqK7NqNBw3FZWpJtm/mJV0cRtTunff\nfbc35qmnn0QmY5VvX0F8je+LL0tQFjed58oqbadCgmTKcVjEoMCGOh+K7DEOtV6EPpC9Cjc0sKhn\nXFbEYsBAGaONAhLSsypeJm5ZHimy0Fwk9HeSQJzVq00arCElYxRwoz6dxiUAYGJKio1aGmU+tsVQ\nIplGjAQak+Pit01PjHpj3v2et8u1sfZf/e8XDr7ojVm5SoBLq1euAgCULb+ufdkKAMBypi5VYwes\nGEEynOD9UIiqSDRmwT9VrqAanCv4+ObR6AFkIpWiQVaFYnz9eJP6zvZ622ZmJgAAqQa1mGT/dNpw\nOUQYz9DPeHye15n+tjIjeXjaeUFHr0MPWvsHA/pm8V3WuIKt1j0WKN5za5NOTTV/KDLLOgC8uEyU\nMZ9aVWJH8aRJt779wXfgv/zXP13Q9H2N74svS1AWVeOHwiG0dLSgYlFv5VmGWyqJJoiy3DAaNlML\nqC9OIA4IMd2zxzDfPEU6rg9u2Cb7dy835yCMd2xaltSWLloH5blgkLY2YUNRn3pkxNBaTYzLmBit\ng5YWgVjmsyYarppeNd7YqNHm6pdls3LNP/zutwEAt+3d641RNhyHanCSbDuxhClTTrKcV62CgGX5\nqN/uoj4ybXPnqaU0W+PXjZ/nuzljFHfyOqL7tv8dot6pFCRWo+8CAHR0Suamo0tg0sX8DOduNJz6\n4oHQFaCqczT7LN7Duu8ut8/VpJ5tyJ1Hn84u7pkPhrQw4JFmHmjJONZPOHTVg8w5mi+++LKExP/h\n++LLEpRFNfVrlTIyo0OGAhtAVOM7UQW3EKhhpfO8AnZNaZFhtKXZ1Jhv3bYZAPB3f/UlAMAv/NK/\n9rbF02K+N3hUL/KRLxjT0gmwjp8TWrNagmRlK402MyPmZp6mev/FC3L8qEm71KrihsyQGaWLpioA\nFFlN98wTkr5bTursdWtNADHP664w0jNEJqG0hdVPNKR5GUzDWTm3VIPcE3eWyVez1vjXY8jOl82b\nrS1ej8k/X+Wcuh5FC1CVz+hZ5B5FtV4D8wQgrzRDp/4Pl/fKwTy18h5m/jLHuqzMJiSdu88cegEb\nx8SNV7TSZ3G6O0wVBq3LCCIyi5L78uJrfF98WYKyqBo/4DhIRSOARQkMDeIx4FcgAMGGHsbIcR+K\namCHAbC0oZxeV5Ol75VjJwAA//C3X/K2ve+z/wYA0JgmCKIomruxwQTMshpk1HNGTPpLRcc3MsVU\nLsroqakpb4wu2gqkGGJPAAB4+WVhw5kmHfY7Hzb11ioaqFPrYnxMxq5bZ+iYlZFIQTYFC5yTiJMP\n/401SJpzHe48Yb6qcuXP3jRfyf2sP2xwjAb8ggTTtLUY1qSBAeFO0LjdciutOlsM9fUsk846h4H+\nKjx3HvXqzqcHZ383n1rWa5pNKW5bHvVzdOaN7mHuNp2aZ1ZpQJawcZvlx3Hmme/84mt8X3xZgrK4\nDDxwAbeMyphpAFEgu22c7bBiLYSRWsUxmCQD77Ckxs6e6gUARMLG37s4KLXlK5ZJGuj8sEmjPfa3\nnwcA3PsO0bDRpJyrAqPxAx4cV+GrsuyWrY4+6oum2AEnHJprFSSTYg2kqLGfeMLAcRsJJHrooYd5\nO+R4FesciMgKPj4uNdnqE+tx7XkoDqpiqfd5EKGyz5yZLkyU8aZ+f94jp17z21mw2VpL72M4ZuIh\nqPK6+RYu7zFsR1VumxiT59reJtZAJGkxzmC2NiewymINMs025L568aUravcr3K15tHHNqU8nBub5\na85h7HvlzZXb5qMu8HYM1A+uCxbM+v8K4mt8X3xZguL/8H3xZQnK4pr6tSqQnUaotdX7KkWcdWVQ\n+sAdelbqyAcGTEOMGOm0W5sF+aZEkiNDhh5721apv29slTE3NxqT8AfP7gMAnDosTSU27toJAMhX\nTDApSJojJWEMcE0MJ+aiwjJMO5WLElRrTBuXYZBzOvSyNL1oazfY8r1E6DU0STquyIaagbrGnIoY\nlOMoOtA29bXWwasqq6Nxml9eb5dZ1QhVrY6r219te611n0d/zDaJveysGetqR18GQiMp4was6ukB\nAJw+IUHXvj7pz7psjQnoholyDAUUwSj/u0Hb9ZkdaGOjlDpf5Er4/Vky75D61OB8/f28q3bmseP1\nds66j/YcHW/bW6OrfY3viy9LUBadXhu1EoZfOeR91csW0YWKqITGVtHmO3bs8MYk2WJKWUxSnVJ5\ntnKDSWNBGWMIwJk8f8HbdOtuaW7xg6eFlHJsRLatf+BXvDFa3af96ZXeutmiLw5qGovpxSSDi+MM\nPgLAz16QevgcQT7ve9/7vG3a/XRiUjRcU5OkJy34OooF2TYyKBbPNddcA6Ae611hZ98IA4GRyFw+\ngCuDQfg5uy/GFQfb32jAT4N83P8KKcRwVK0So+kcpvaCFb6G9o3gMTs6RMOPjYsFdOHSRW+Igpqa\nm8WCjHiWj9HAtVnhThMOnKf3/BstWpgjCyERtZp+eKdXfoJ6PH7dEdU6uBxPwgLn62t8X3xZgrKo\nGr9UKOD88WNo6TAto3bfysq0JCGpupTZlXPaoop15Jgh1NauH88KRLY0Itua0hbHHFtD/cKHpCnF\nd7//PQDAY0887g257TbhplvWLnOLM2Vnr4w5ttUqkcKnKS0a+8jxY94YZd556CFJHYatmv9xavoW\navpCSXnkjKpRS0P5AJoaDFRXRevvVdMHrUmWPMruha/pVx5Zu/wop15DXVF4iRkL7JRqJJ8g4bgz\n44NmuCPXmGbzknSbQJEfe+ZVb4xaA6GQaPomWmcBS3Ub7od63ofXm7K7olw2d2qfo7412nwH0NSt\nM6/BUM9U5dkxdsn/62BL8jW+L74sQVlUjR9paMHqux6FWzVw3CwZd4tlqcnW8uJw3ALHUPtXM7Jf\nIsT20mGr2YMj/mEI3M/avVgTOPDA4HkAQLpDNjanTFR/+pRsW5OWrMAUgSOJDhNFjtC3rgVE0w71\nir/Zf8K04rp1761yDgJVLOJYT9PrIl3m6h+2Ki2GByTmsXnjtfIFi3WCVs15mFHr+XRWMKRFHKgf\nY2kGD6ai8YArabigFs6Y8zsslAmyWCpQnb3TPFITQE6qyRynlJVrjSTlXmWLpuXzxLj8fV2LFEtp\nG7X77zINJF46KPGUoy9JtmbLZinUaus0z8wzfLSJC5+dRS+IIuNLDhl8g2GTQdFh+sZqvVjQuvmR\nUv0NNE0z7O/0n2DdcQATs1Erbd7bOQuvc7lHtlAqAV/j++LLEhT/h++LL0tQFpdss1pFcWoCUQsU\nk0yQ0pjc13k2EajVjDuQII4/1EDTPifmbzkz7o3RPnLliprGxs6KJsU1OHdGquNaCarZfNNusz/t\nsklSZTVpz3q78QKryHJjQgT57LPSzOD666/3xnSSMkpN7WLJXEcgEq7b5tF0W+aZVvUpvZfd0MOb\nx6xcXcXyJ9SknB38mZf62q37uIzJf3XgiHuFbJgnwbkHd7xnJMcuWVWGSS+oqTdLzHC7nv+GXTcC\nAM6eFlfr+LGTAIAVFsV0z1pWNXqdZHkd1k2PevdY3sVM0fA0lBm4TMSUL0K+z+TNPU/GlQJdKbxJ\nF25lJ/X9Cga0OtBsi0SYFn0dwbk3K77G98WXJSiLm84rFXDpwgm0tpugWmObVKxFYwxYhURDViwG\nnmJJrIByRVJcEVc0bzhiVXqlJN0T1Yq5ktn/8MsCGKqVJWizbfPtsiFhUn7VnAQAm7ra+Y0sv5kJ\nU0mYInz2uRekoUXnMgkiXbvJtOsKMn1XYfSmYuVYwl4LrtnsOEYmJyWotXadzEM1Rblqqw+lbxax\nCSyj4WD9MecJBs1O0Kmmn69izFBG29vmY6+ZBeudUzw2V8eECISqaoOUormO7mVKlsqAG1VkLmeI\nWsO81rXrpa3UihUC7Dr8yivemOkp+VuBUNpII2DxLczMyD0PhpSm20CwY/yJFPg+lomQSsfnWmIm\nhXp5DT5vGu5Ncie8EfE1vi++LEG5qsZ3HGclgC8D6IIoi8+5rvtHjuO0APgqgB4AvQA+6LruxJWO\nFY1FsHbDStgJi1pFVttCRtI1WtoctTtJhrRGnj5xhMAdy8+auHAOAJBqEN+84prClRdfEh/wgYfe\nLV+0iIZwC6YFlwJnNJ5QZfooFDXzOHda2H0mpsQK+NCHPywbLHWopfGq6cPW/mH6larXtI6+WDaa\nLpOV86ZS9HHps5cs7j8tTqlRd5ct60j1UHVWUihgg2xcHcNtmHMZFqo3VPdpiwfVnY+xWqWeOKZ+\nE/32DJuhVmtmjmnyJJYJSAoG5ZmHwkaNaiONPK2AWFwsup17bvHGDF66BAB49dXDAAzoZ9nybm+M\nVwDFe120mrqCDDexkFiXYRYE5ctmTGRWm63ZTTht8dp+Wc9MQUYLKbby5I0SLFAWovErAH7Tdd3r\nANwE4LOO42wC8DsAnnJd9xoAT/F/X3zx5X8BuarGd113AMAA/55xHOcYgOUAHgZwJ4f9JYB9AH77\nigdzAEScejAJGx56HpPCVx2zspcZGS8WWCJKIE9T13pvTHNEgDcIiqY8dciAalrapOVU1ypG36uy\nwjtho/ETcYk1FMiHF0sL/HNq2DTUOHe+FwBw2523mesBUCwbBp0yrydI/9UG58x1+eQbbSYCGC0R\nTybqR1oOozbvrGixjKVOZzPweCx01v0MzMuqM8tH97IB+orUe/l1c5uHDGb2gbQAxS5ZDfHYWTY8\nCYXNNbt8I7SsVi8/EjHgmlxBtG5MC7R4LmU4BoCubgEAaTOTQ4ck3nPi5GlvzIbrxAJcywxAPGI0\nb57xpSJjRlHGlVJhC4hUJPhsTrttiwloVlzEhmlrHMe9Iub2rfXKX9fRHMfpAbADwH4AnVwUdHHo\nuPyevvjiy8+TLPiH70jvon8A8Guu605fbby132ccxznoOM7BkfEF7+aLL778E8qC0nmO44QhP/q/\ncV33G/x6yHGcZa7rDjiOswzA8Hz7uq77OQCfA4Bdm1a51fEhBGMWkD6qgRExoSoe4aCFDSfwJcZA\ni1Pj/lWTzstlxfy/eFGCfAdeOeFte/8jn+TV0iTUuEps7uWrmeZWxPx+/oX93ra114hr0b1cUk0F\nBoGCYXM9yk6jcR0rCec15whqzzcOKlodZFMNTG8ygGmIa4yp6HjmLwNfVp9BpZp2ZkXa6gz1WUgd\nTePV1dN7oJzZ1NGWS3AF3LjhmZFr1qPYYCOXwbRcQcYkG+YSaapFrKb+mEXU2tFqjwemWNGolZUy\nRzlz1ZVz7dpzEwBgdMhUAr7ymgT+Dh58AQBwzbUbvG1bt24HAAQDehx5VnYKVRmiZosdwKta9Sn2\n8QBzj5XnwJTg2Xr5cm7AG3MBrrqXI47KFwAcc133961N3wHwcf79cQDffkMz8MUXXxZdFqLx9wL4\nKIDDjuO8zO/+HYD/DuBrjuN8CsAFAB+46pHCEQSXraxDNrgFCezk8oThsvbeNM8AQkzl6Oo9NCiw\n2qef+KY3Zt8zAqrRDN3bHny3ty25WiC6JRLlBKv6aVbkGaboGsgHqKAfe2W/diPTgPxfefoca/3U\nQI32M7fbWymcOMRKO03tTFvBqJaWNl6qjNF0lp3q8ThcqKojlvbQNN7cwJ2ZhwHw1Otqi5XaAurO\n1Q1zOWT03Pb5Kt5f9rayRQVe4bZiSY7U2WFaoultJ0YHeRpFbZaWH58UaG2EFlRjU70FYM8ySsht\nIS+pv/Yuk867l23ORkeF9ejFF1/0tn3t6N8CAJavkCChNjaxW5rVKnId2izE6+Jb17RD+QkJ4rJ/\nA+QeMMFApdCerzHIWyMLier/BJfPGt7zls7GF198WRRZ3CKdSg2liRwQNL55IEKGlXbRdBWIv9Q3\naHy5lw4eAQAcOSJ++9e/+vcAgMEB055K5eabpR7+3R/+iPfd8KVxnku0Zls3rQlLRTW0iKafYR3+\nkdeEVeed7zJtrnRFrlKLa1GGldkxwB3PbzMaTmGn6q2XuepPW6w0zSnx8dWPrxIiGopcHgxS953H\nLadnUa1hp5bm/7TF2zaPAx+Y5dvrbXStiIY7yx7QNF7V+tpRMAtr5VMxY+XlZkQzh5nWdFjPn8+b\nV7aBrcxUUaqVYN+XEoE2WpOj/n+pbOIqLo+tjMb333+/t216Rp5NX5/wNZw+Je9g2WrxliRcXK0A\nZYFuajTQ9KgHEWY9vs25t4jFOSo+ZNcXX5agLKrGd8JRRDrWo5o3S1z/sKzs3/vKYwCAE2cF9bv/\nwHFvzPHjwopbJrQ1FhLNEIqZRpLZgmjqux98DwCgucPw2RfYunp0WjR/rDQXhAE2wNz3tJTa7tmz\nR8ZYjTW1bDRMy8F1qIUsOG0wqBBXEbv5p/rpZRbwJAjyGRkw/QFiXTI31dfVWe2yAEBp/JTX34aG\nBjTz4c1g9v9AtSb3Qw8ZISuN7fN7jSipzusgtxrGwOzPywOJAnzV7Fqj0UGx2DSbkM8atmLvxaQ6\nHLp4FgDQ0LnKGxMN0RrQ+0EmnZBdks3sSM2VE2vzyXDYxExM5oKFOJY1ECcf4ObrNskXrMeqVMyY\ng4ekh4IWEPX29gIAJiYMm3Q+J+P1vYpYfJHaL0KzPjWvasrWy4zdKJNPoJ5pSa5j4eJrfF98WYLi\n//B98WUJyqKa+sPD4/h//vivcPhIr/fd6fMSPDn4ihAvuo6kVgplYwrVIN9FWLo3VZF9kpZtc/PN\nwqazY5fQdWesyrtgXEyncFzWuUxeAoepWqM35sgrAuJoa5HATDs/7SL1IKuwDDkiTX6LObFMdyAY\nZSAvYLkT1Xoa5Rpt5mK+aO1vdc6FqaorW0w+mg5Ut8LOw7m0/cq00cMBZeSxbparLac0EDh3/dfA\n2xXg94Ych//aMSo9nw4tMPLmVs25+s4LWemGnh4AQCJqTPRqhilOBv6KU/J+tK5Y441RWvFqVVNk\nrOWoM5EZQGTKrUSTOWgx8IQUtGU5JmZ3duClP+EoKMc6x027b6rbX10ObYMGAOMEHmlFYcSuB2DN\ngb5P3qnrgrezSiC1kvHyJRR1whwtAAAgAElEQVRXFF/j++LLEpRF1fgTkzP4++/8uA5OW4MENoqQ\ndFoyJkG5gGuCalVqiZwrwR+Hfe3LVVMTfcfdDwAArr9BKJazJQOKiYRklYyGZUkslCQIMzluNO3h\nVyRAc+vtUnmXapZUjFuxOPdIXV3hih4hT4BrRVi0FViN4J6Q1QZJNYG24pph843x4TFvzJrlq2W/\nWQG0/IyJilUZlPS0uc3VrKmtslJGy/91teG0YgIMFDnz1I3Pic7Ns03TejqzeTW+Wix5UqNb1XUD\nvVIrf+t2Vk3mTHAvGJP9X/uxND8JK224lYP14C40QdQC0LEyj1lsQfzXBtBUZwFnlCdA/tEcoV4j\n79k8eU7FJkWouTWtBwBxVhAGCLZqSBoAkFoKakm6tfr5ACYoCe++avMNK03ra3xffPHlSrKoGj8c\njqNj2SYED09a30k1r+PK6pgrkV3GWpHDhO/WmL4KQvzg1lbjo+/auQUAkGBooFwxa1olJ5o1Gmc6\njWmTo68e9cYEqrJcdneR601Pb2lT4wGyHr5SP1TmJhohwC/t9FWN8NtYTK7xIjX9uTO93pi7br29\n7mSqxVzrfuhxArQ4yhasWF1Xp1bP+1a1imMCs4pBHFpU9Q0gZl20reBU+/EwWutv19ornNjlPGJs\nMDrY1++NaaTWq7DBKKxmG8X+MwCAs0elSOrmm6WJ6sykqQULOQKcCbFISu/VfJrPq5GnmVK2gUSY\nxZxj+f+qfRV6bSgEzRjlYKjy04modWJuqGrofjaJbWw08OQsWZciHoekwnvtefBT06we20/9dS6U\nv8/X+L74sgTF/+H74ssSlMU19SNxrFi1BdGEocXK5MVMK3g2sdInW2SErjYjEJOwVhME3t13G0z1\n9dskzZNlxVYsaGy5QlnsIaVWnhiTdODpE2fM/jtvAAAEiKgqTTLFYnEHeLRaJNDMs7GHYyHFlHhR\nrelywSYWZUCG5til82L29fca8zdNrH4ho3UAsjaHrLTgbDRdzbJbHS9FR5ptoh2rViWi42qPNpqN\nwfpzAYBX4q+PxSYU5WeVJr5WBNouT5XnCNBcTTJY9+LzB70xa5cLMWpIO0+UTAp2/49+CADYvV2C\nnQ0hea69o6aOPsr5poiRDzDNWbNq3z2ac36G9Xk6lhnucQ/wf9tE12uuaUBU+RYsElWHqVOvMQev\nve7XJd9NT0sAM5M1NOFeGs/VtKK6SWZvNfu9zzkzlCvwTX1ffPHlsrKoGh9wUK3GUC2bdIkqoiBx\n7AEGgcpWGVcwJBq6VJIKqQSbbjz0TtMCKxmV1FwxQ6BE1ACAUuzu6uRlRR44KfX8tha9bgNB2MTP\n5LOifZIWqKJqonucD7Hy1socisstVSh3xWoLpX3bs9PynQb1qlbzD+27dOqEtIPyKr1aTDCoOquq\nra6Qnl+phq/SGqha99Ng8utbPzkWvXVI4396CnMGr7KsQnOgwkFVK3WpWlNTXKqEc1NG09Va5CbF\n2Xbs+BNf8bZNDAqTUtd9ErSdPCWNMWqpbdZEZP8gcfgeFbhjW0D6B1Nlmoqci9Gpu43eKRj0rbFj\nsxIhRSz693KlxHMp2aae21gOWkMRZsOX6WnT5qt7mXADFIsKQOK8rOCeBlK9IJ+36Y3xbPsa3xdf\nlqAsqsavVYFC1q1rzuD5h1UB3FS9Bcz4aU6AXHVBWSW3bBU2lDWrTP32k499DQBwx80C2Q1XjTYP\nBQTwMzUiGuLScWFa2bZjizcmzMaa1Wnx7cMBTSua+esqmWHzj0BI/WjLjyf7So6U0TYcVjX+YL9U\npZ0/KxaMwoQBYJh03gcOSO/3TVtEw+1qa/XGuFVt5zSPQ8f5FnJisVQ09WflfaJkOQowf1ejWrb6\nlHp3P6iNIC2dX1ZNr9VsWl5naXwdH6TfenFIrLawxSQU1xr1UYG29p456W1bs0LSvDOnBUrtlsWS\nC1g1/1VW0eXyZOLhdUQsDsKw/q1gJ4/T0VyrYrS82InNmsRnq1WWyq4TtNJ5EbvKEwaoFbBMQU3n\naVrx5ElzrWlyDYYt7kZ7H3u++mmIjOxeXAHfx/fFF18uL4vcNLOMi32X6k7bkmYUW1U9tWi2kLH2\nJAAnKqvurl3XAgCKxVFvxN/99Z8DAO6+SVonh+rC0LK+TVDrTI7Qcth8txlD7r8swSTpVvGpS7Zv\nTO1RyMpxGlpkpa5aGr9MX7CYF42bShjosS7TYwTujA6LpuvuNvxv+t3x48JH0NZ6+XYFCnJynLnr\ndyEv1+PO055JsxAK2dUxNTvUoJqR4CBb41fVp0d9UUzNsQ5AfkTVTGdPSj392Ihpbb7pHXL/v/zn\nvwsA2LPN3IfOZtHmr73yDADgphulHr6vaGDa02x+kidLcTQhFmCzVWsfJpOy17pKrSQLpKNJBb2f\ntqbV+IcWX6nJUAlbY8jj5zE08Rw226+2ZlOWn8FhU8BjinOuwInkaXxmYrwv5hYkLUR8je+LL0tQ\n/B++L74sQVlUU7/qFjBePo212wwNcr5GMEyNtek0k9JupzcmwnRNwpVKvijEDP/T3/srb8zbbhM6\n7YaU7GeDMCZzYlZ998XvAAA23Sm4b6RNym+gX8y1eFLOcWlcTOW2ZcZszLFHXjBOvHeFJl7ZamiR\nl/HpsoBK3CFz/cmIjG+rSlBvfaOwlTdFDKil4bRQj+11xR3ZWyaA53TWGxNqlEqveKtc42TRgFoc\n1vO3BMT8HbnETrLdG81EErLfEDNrMZqIqYLBwTcobHxSXI2C1aNiICzHbumWeUxdkrkmXBN404rI\nRhJiTp6TdNyanDH1Rx9/AgCwlsGxa3fd4G2bCog7tHsz6+8zAnyJvWjuVXur1FWc75V5n+wV1++9\n/+4/eGOmSZteapTnqg6kXfneEBYXsjE/N683cEzqOZIMNjqtYqpPBIwr2sBnHiI/Qpic4COT5lq1\n/r5rtbgzrxw/7G07c16IXTddK89IORmKRQNoSpOItEKKuCJduVTSVDsWsjkEa1ZxyBXE1/i++LIE\nZXHptUHwSdCChjIQ45BdJ+xqiskEioIVWfnCrKo7fFi0R2H8kjfmvW9noI45GSdqKLwrE5IqDDAY\n1d0lq3/fOaOOV64RS0EXWSeovdfN/CuOEjaSzYUrc80iD40FxIogqlfJbmR/Aj3yDCBef73Uoa9e\nZeZ69gXREnfcdzMAYPC8EI2mR01313CyR/4ISWA04poqxQhTa9NjYjlMsVlHyyqTKmKmzyNxCfB5\n2JbL7Ha7FSvepGmniTE2q2Bn27QFb54isenFadHCU1mxuta2Gl2777nvAwDe9eiDAIC+fgPlDnfI\nuCCjg/Gqzt1oQaUyP3NGoNftnWIdjL1mtGnrDTtlHkW5D7GoWGI1CxLuBfz0nZsw1pUGDhuZAq1V\nFbpr3uESG4J4Lc0YOKxZNy1AfoZKkZZQylBv57Kq4fnuKkuRxVakQUYPkKWfFvirWq756TxffPHl\n8rK49NqOI4UUQXPagKYyCJhRN7FYMOw4+YKswCVy5YXYbitiFbtfex0bHQa55FnplsFB0ZrhgIzv\n7pQYQzlj+UMcPnRJ/MW25eLTlS1Np+ANuMq9R8iuBRgxkNn66QCmj/qlPpnP5s0rAQBdnWb9PZuU\n8zdtpE8ZELDPT/d/yxtzZ8/HAABjA2KOlCxWG7coFlN5RnzCkWGZ40bLqR0t0EIhaWGA9eO1vO35\nEpQSlQvJVc3zCJLWupAl8w2topkZk2pzCZEdm5D4w1RWCpEmwuae777zGgBAfAUtBut1DDeLFVTj\nMYNpieusWLXcGzM5LnGABPkNdm7fCgB41dL4zT1sedUk92OarE2OZXUqnLnC1NiQxZWXoxaO0MfO\n0UxyDNIMblmPI581fU1qNoW3WpAyuL2ly9vW19cHAMhOyz1OspisZr18Zb7rNc6nwt9AsWaeS7FQ\n8sBYVxNf4/viyxKURfbxHdQCwTrMgev5WkoypyAK2wejL83Kl2hKVsTuJhP57+oi7JXxAFjlsBfO\nCRims01W7XSa2sxqlrH/qacBAMOTEq29tfk+AECy2UT+Swp48XjXZEUORax4wrSsuIUiy1Fti4F/\njwxLbKFpj/AD5qZNVL6hnQ0gcqIFGjfKdVVf+5k3ZnJKfOHkComC12qGvy1KJXPujGi20RHRMBEb\nVUomI/Xfa47sVHHsgiQWTcUIi80Zbe64ovHTZMUdYtHTxSFTXnz9zWKBnZySa33+oETwu/du9sas\nuesOOfaQXE+4w8r20Cqpsf15LCvnCsXNhfzkuZ8CAHZtEtBWgqAr9zUTKzh6QBh8tjwgnIyTkxL7\niKRMXETLlEv00cemTWAnGJVrDbHoq6YNUizNGrQ5+gCvlDlkgZ4CNZl3kWw7jSkD0z4yJhyU2UkW\nhvGdC1QtaHuRvwv69mVCwlEy56gUS3VMTVcSX+P74ssSFP+H74svS1AWuR7fRbVWm4XprtV9ap1z\n1OqoW4uQYYUxrGJezLWWNhMgKZXFPCvSjHXzJog0xbTfzhv38AASJBy7YAArf/93nwcA3Hz722Q6\nDGaV81baJshgXnRWUbdVzaVkjjUGjIIRqybbY7Vhioi47UrGUIGvWi/04g5BMqDJf8vN13pjfvKc\nmM07H+gBAEwUjTvSFJeblM2KaTkzRZPZqrxTmvEi5Bxac25XTbLkACVXAquBmLkO7WGYZpB2gjTZ\nGcvUT98jqcrXXpEqw2hc9nnHe+8wE5mRmvtEmzzrbMWk0WJhuTfhmJj/oaK4d02dVs+5dhlz3Rb2\ntaMXsHHVCm/M/qPSaXn9Fgn8pVOswrRYi5RNR5uw5Kyqx64OvmN8ri5dONdmPZpVyK/Wdsgx77D3\nyldIr50wiKgIx2XGxc3sTEslZrhmnkeNqWAvnailA2WrQ3G5umC4vq/xffFlCcrianzHQTASru/c\nygCIgmtC83UBdbQdlWidQkFWueYWE9QqVzzkDQBgbMRon0hQVst20jdfOPkiAODl/Sbtc+m8BADX\nrZJUWTrO48wYKvBgSvaPpmS1VgBJtWgsmFhUxhSy1KZl0xKrwm6qjqYhmVIKWWxBy1ZSW2nLrEEJ\njsXXmi6xy5jGO39a5rx66wZvm6ZDtZGH8s9NG/QoEu3KvEMuBI/exQTOStQcM+wvn2hp87ZNTpHt\niPG+8pikv1oilh7JC8T29DGBJT/8sPAjJpPmHDPnxeIKkjsvZ92HpnZJZ05ekkrI9lZJy5XLxkq7\n5ZZb5A9tvZUVy6l5tanyayEA6uV9rPJ77wfluAXzXBzCaUfJxVhyzM+iqUMCyJpddgnKCdpty3jP\nPVYfvg5Rq7y+xtNFA/JlyNLMnS281mF5SJUumb8dj1XOhyifa0XbsFkaP1Apea3Pria+xvfFlyUo\niw7gCYVCqFhwXIXmOh45G9lL7DgA/W2Xab2GpPhEiYTxoQLUGmVqqNOnTLOMOFfe7JSkzV5+8SUA\nQNDC0265RjRtGGSuocYqF0xqJ9kkKZhATVthaQNFM9UAocf5nFgKNYvdNsyiHrUKXEKJc1nDK9B7\nrFeujcUYDXS2UzETB1jfJtDUJ45L2iqQOu5t6+yUQo/GJsZMQnI/hvv7vDGrWwU4lK3U88iFLDXA\nW+01bgjZ3TbYniw/JgCapCvX1ZEwaa2xs68CMEw6W9lf/uCPXvTGbEhLevXceanVb1q5zpyC9er5\nQd6HfmmwuT9res6vameD1RF5Vp1p0c5Ou2Fmuna1PNeDpy5wYhIfgpWCqxFoM9Av1oTNoJumlTg+\nogw8cpOi1k/H5bur1qriZsOW2Zpn7Em/K2QN9LizWdKQLzL1uH6lgJQSFq9frSS/AWUUCvI3UbMs\nSqdarqfmvYL4Gt8XX5agLPiH7zhO0HGcQ47jfJf/r3EcZ7/jOKccx/mq4ziRqx3DF198+fmQ12Pq\n/xsAxwBoRO13AfyB67pfcRznzwB8CsCfXukAruuiUirU9cXT9JeaknGaUiELS+1V87FhgZuXffIl\ngyarMF81Rdrik5apv2qZmOiTI5J26jsn2x5++7u9MTUGus6dkq65Tc2yT7DB0FpHSZ6Yy4oZ73Cu\njms1YCDCamZyqG7OAJBukHGdbXLsAtNHQ4PG1G9xJLDTGdfuqrrFuDVoE3N+6yq5nqd/+n1v00Mf\nEHO3sUXMzVhY5jo9Ykz9SFnM32iJjz8q99PKPEIZx6LsW+haNOHBkqTdggUJRrXE2PvNNd1u+3rF\ntL77VgnAre4Q87WcMeZvio9v2ybyI1hU5jXi1gPbySPwipBTpqLGjK8Sy56mqex0kqbMCnA1MuXX\nwKYlR0hiumr7jd6YMjnVJ8bkevTZA8YNyjEw25KS8wctfm5XG2rQRXAI3Ys45tlni0ofJ35nPjNh\n7gMp2ceH5HnmJuV9CFqurFuWdyUal+/ckrznNes34LruW2vqO46zAsA7AHye/zsA7gbwdQ75SwDv\nnn9vX3zx5edNFqrx/xDAbwFQcHsrgEnX9ShXLgJYPt+OtsSjEWxavxanThtq4Wau1lWmnTJMnzW1\nGCy1FkIpOKdClpF43KR/pqYkFVOY1gCNOW+Fq+OrhyQYtmeXgDmiEaPFcjOyyiYb5ZjFvBwvGTVa\naHpYKuXcqKyqxbJWRhkttqxdAm+FGQl8jY2alT2+XrT5hQuiDdesltV7ZMxoyplDYo387JRoqMCQ\nrPST4ya4h5Wi2WI3SjDs/k9/0Nv0w8f+DADwrvtlHV4hcTwMXTjmjQmXRdtViA1PtYp14ZYMyifM\nNGs8LI98fMxUrIVZEfbSgScBAHevl3kMDxp+hFMnJeCYhkzg//7P/xUAUD1qOBDWl+TYzUGyy1jB\nrDiZbkozcm/SDMYN3GTMEg1Gbr1OmqE0N8g7c+16k96MxuX9amkVQ/XV14TLYfMtd3pjLo7Isx44\nL1bRffe+zds20C/X2t4sxw5qCrRgNG2YlaDlPLUwqzYzBWN5hGiFFGZkTCVvwEozOTIYEVh1nrUl\n61YbIFKN7cUaIgJoCrgMDlZN8DkzPen9jq4mV9X4juO8E8Cw67ov2l/PM3TeBKLjOJ9xHOeg4zgH\nC9bN8sUXX/75ZCEafy+AdzmO83aIo5mGWABNjuOEqPVXAOifb2fXdT8H4HMAsHr1WvfmXdd7PgwA\nZKYUICOrZIp+dNJqg1Qhq4ym7AIR0RTDo0YLFZXimgCemRmjRQtM4y1vp0ZYJ40Y7TZdKVbsnT8v\nTDe33CKMPhnLFwtT01e4+uZpFYRDxvI4NShzusQU1XCfqbwLVeVY56hZNm8RC2BswvC3XXhG0lYN\nrEbrrMkKXxw162rfhFg1RUcW0j2P7PW2rVwj+337B38s266RbcdfPuGNKU7IPV/RLb4sSWYwbqF8\nmpvkmrKjcq2NaYslqFc4A9etEq2capZ7/4PH9nljEuvFANy4SbTxIw9/HABwcPBxb0zTGTlxhyPP\n0w1boBhWzM1MEzLsyrWefMkAeLZulxThiZNiQV0YkHk1NhprcdkysTi2bRErRy3BgePG6hwng9I1\nK+S9CJTMva7m5PxFFt1HNBVdNum4fI4MTwFtFKr97c1xSkXZX+nbMzNT3jalYtdrnByWd6DSYVGz\nK3tThulvNbarRplGgiWvaerV5Koa33Xdf+u67grXdXsAPALgadd1HwXwDID3c9jHAXx7QWf0xRdf\n/tnlzQB4fhvAVxzH+c8ADgH4wtV2CAeD6GpMoTlq/LRihRFhavMw2WDCFbOS1ci1F6XmL5F/rGIV\nSsQS4qde4qp/jlBNANi0RoAe11wjjC/a6rhUNn7WqlWifV995ccAgPPnRCOsXL3eG1MYF22TK4lm\nrDqisTIF41cFHTZ1IJPtawNmHm2N4qfuvfVOAMAN73kIAHDsCbNmDjGy2xWWQo21CfHzmsIGnjxd\nFqtkaEbm39VutnWskL8LJZnrodfkemwShGOvCQjm+oTM4+IlmeO66821Dl9iC3EWALnWM+u/1AsA\nuJ2tzBAT7XNmyNTB33EX+QSvEX+7ze2Rff/SAhsFRIuti4rlUQ6Y+1hwWDBDmHSIFuHzRfPMPvXo\nrwAAWm67ntdIy8ludkGQVKhRip/OPS8xlP4+81x6+8UC2rxLMhCuBdrS2qQyY08FNnoJW5x9UxOi\noTViH/FaYZl7ns/L+6zNMm2LtEwXOMzswiXGgK5ds8wbo5D2sRGZR4KNQkoWE69Tq5o+YFeR1/XD\nd113H4B9/PssgN1XGu+LL778fIqP3PPFlyUoi4rVL+ZzOHfkMIIW6KAjKWaR4u+VgrpkBU8cJgyq\nJLvU3u8hC/ChdFg50g0PjYx52+7duwsAsIJ9yEdGJC1Xcoxp2b1czNZlXQKA+cm+pwAAj37YpFRy\npJHK5iWAl0yxGciYCYrF4mKiO2yEMTp00dt2YFrmdP/b75IvwuIWnO41Ka5lNQlMtRTExE5o5V/F\nXGs7pDqQ8T8kUhaohfGgbbuFVvpSRK51KmLcoscfF+LOzhVS8Zcgxn5i0Ji/pZKYuwkloOw3c4zF\n5bvEGmZwq2K2rr9xhzdmxRZSbLE34viYBDsn+8xz2VITU3YVqcOm8iaQqjyoafYeDEUIksmYkrdq\nlq9vTb5zaeo7cTOmxPvGtvToWC7Pd2TgjDdmhG5h6967eTnGDG8gzdtIVp7x9Jjcz6hFqzU2JLwC\nEVKwRZXa3cL8Kz12PifuYSFrXJYio6tBBgNHBuWdKeZN0FfBVVkGEquJKI9jxgRDjvfbuJr4Gt8X\nX5agLKrGLxeL6D9zAgmLDiZAauQUg3tVpkQKQbNqu4TzFtipNMwVtWZRHE9MMe3D1Fo2Z2iHq9yv\nqHTYXInLNWN5lAl13HDtWgDAs0++AAB49dB+b4wG0eIhVkYx1dfVZFJdMzOyIjtlmfP6HoNr6huQ\nNKbXXJdppKJVB99Vk/k3kEQxBDlH0gomNTF4lVCLJ2Q0foZkkPEmsVRuvEe08Ey3SX1WC3K+Z3/8\nPQDAfe96GACQzRtNN0BC0BaHvetHznnbrt9DxptGmhdsCHHPhx7xxiTWyn2s8nlMsgVW1dJQy1hp\nltJ8IoyVF1SwVoj3iEGsrrSxwArjDOIlhCvAoeVSDZmKNYW4KqVQcoPMK7fPVPm1JuX+tdM6GRgx\n1k0lzw7Jk3IfShlq/pxJx5WmJupnT5xvyGKRcvidNu8o5c37WeL1V3mNeQYAy0VzHXFq+Crr70t5\nDVBblnHJ9ck2ffHFl8vLomr8gOsiWq16jCsAUMioBpCpxJk2stlHHLZmUpc8x9UyFjO8ZWXWlp85\nK+m8gSHjS07SGqhyjPaKj8TMijwyJumv1jbRHlsIPDnw0594Y27bK9pz9co09xHNMDlkVt1ylZDf\nimjDgA1EosWRJYMQEnKcstXCMUlN30n4aoO26YoaeHETjaE4mWPQYKyKaIw92r3eV2IpNKwzoJb7\nH5FYx99+8a8BAN/53lcAAHfc96B1HTKPoyfE8nHT5om0beiRPxwFNMnzbN5gfPwMn2eZTzJMXzlm\nNdRo0fRdWbRoCsYSTJIPfFopwKmx2yOGUr2a1fdInmO+KqmuTMgcpwKx6lro5Ed5X4aHDLBq+0aJ\nh4D3U3kGAGB6ULR5jWApxyEAZ8rsr+29yixkKikwzDF+fCCk7xrZj6yipwo1fj5LhiZ+X7SsAjfO\nlmJBtRzICWGxBZUrRb+Fli+++HJ5WWQGHiDquIhbLae0pXBro/hZyrI7NGEivFUCeILaZosrat5a\nEccmxIc8cFDYdao1s6aN8lilii7N8lm1gB5F+sbRiHzXs0Yi3v1nTbPKkyzwaIiIn6iFEgnrOA4b\nPrhB0fjn+wxnX5qMM16LpjDZVS3OvhobOce8Ul/CQavGqqiV5HoqFTZeDBhoZ5HWg2r8OLVfoGx1\n/2SM4sMfew8A4P/6Qyns+f7jP/SGbL/+JgDAwBAhzDvuMftrU0haLrUEC2pg5jFKTZukxp8qyHUU\nrFbcgZCWv+r1m7iOU3J4jXwufE9mhkxcJuqQdplMSmE2xKxapSQlAn/ytE76Dr3I4xr/eWWnWBFV\nAmdsAE8hI88vVxWrJB5XK8fEKuDKc3ToXytDU9VqulGmL67ZJxtnow09CoxLxdjEo2g1MSkn2dCD\nxoSWdEet31KhUELNZ+DxxRdfLif+D98XX5agLC69ds2FWy4hljLY8sZ2CaatY9pL64nHJoyJrA0c\nokkx7VpaxOx51aqwWnFS0jxDQ2JGr17T420bHBDzcnhI0mndbXL+bM4i0kxKFVyVPfeqdAf27DZM\nLV//mz8HAHSS3WbDBgmSBcMGx372ggA8YmkxW8MWrU13t4w/cYqYdgZ4bMaXBB9JWCvVymrumbk6\npAsPaZA0ZLrlltmEQUmLhkblPi5rspjRWpj+o3vzzoelr9zXvvWMN2Tfs9KXbhXjp1t2bjP7k+hR\n2xMmklLzPmO9Tlkmt2I0bauuzDliuUVJPkfMMBgXsPiomf5zaTY3N4o5Hp4yLk9zo4CltFddjn8U\n6yrE5brDnMehV4TuO50272CQBJjH2WW3ocOwLiXIxzAyxHQk71ld0JZU3Q4rQ4OkwHYtl0MbrKj5\n71hkn1ESCyhVdjzCAHHRql3gOZQSPcM6DSdlnn0uW/C75friiy+Xl0XV+IloEDt7mnHpkmFqSbFj\nbWeaLDAM4PU3mZTKpVEJDKWiopW1g2rS6j9+6qAwzDQEZbVes8KkfYb7BS76wsuSgnnbPVKl1xI3\nPHRBttUK10TFTeVlhQ1GTMDq3vf/AgDgC9+QNNg9y6Tqr6O71RszlZK5tbFeuj1ltFhro2j2yhit\nmREJEDWUTT1/b7OkI6dpgZTjrFlf1eONOdErAbdx7UdvVWg1k8K73CDX4TTzEVtpHw/XSyajTbuk\ntdj9OROw+r3/+QcAgG0fEVBOMWxSn9Eg55uQay0xOJewYKw94wzuMSg1RS7Co80mYHXmE9IWLEnN\nVpk2Vp5iiVLc/0dHROJohWcAACAASURBVBvvnzFBuYdXSjq1JyraL00q7rStz7Sj8ohYfSf3Cy/B\nbXv2eENeHJCAcI2dgfuGTEBXuRwDCTmmJuiKFnhsJdOKja3yHoyz2i4DM9cJNnzpJ713wrI4ltMS\nLKflWgcuyTuwKWjOMT4tgKEcP1exacjQ0IA3puy6fjrPF198ubwsqsZ33RrKxTzaW40PpawlF85I\n0USVfpLdjamZqb5sQdbbGMEYAWt5Gx6WFX3DNZJqcy0usghr9c+Q+WaQHGsdnSan4jDdEovIudLs\nUX5pwFgeybRo4Ztvk9TWd/5R/OC3PXC/uZ687HfdRgEAXZo0UNefsmHCwx8Ujrz9+74LAIg3m5V9\nhD79hjUCi405cq12y6dkm9y/xi5qbqupQpCw1TKUvViBNxaFrp5OEVFs8LHtBgPA+eCHHwUAbN8m\nte7RBtO7XvVFhecNMY5RszR+JErfk/5ulIVE//Jf/WtvzLpbbpNr+7Hcx6btW80pyHijqcNgSu7r\nDqu4pamToCQFArG+H43WXMl08/VvCC9se6cUBsUTFr/BqKTqynltWmE1bGVadZyxkirTZXGr6WUw\nKj8jhSWPELbdRdgyAAyel/fgwEuSTly3wfACJnisCIFqQaboChbIp4Ht4gq0ykbGJF6Vs+jsYrFo\nXeu5K4mv8X3xZQmK/8P3xZclKIveOy8SDiCZNCkI7dyg9NhlVtKlEiaoFmI1npsRk84hBVfEarqR\nZdonlZb98jnjBkSTYhJeYp3z8y9Lz/R33m/O4ZIyepx97JoTEqiJpc0tGiYlcnuHUFS9duQ7Mvfp\nF7wx73rbOwAAz+0nnVV3h7et51o5Vnq5mL0vvSSppb333O6NueN3/7380UBUHmsO2qzUzvRL0hTi\nTD9ryu3ChhCx4DS7K1DsvpEg7x9YOwDiwJNdJiD64MNCC9YQpzltISG1V3yQVYVq4Aes1ykU5Xii\n6lq6Jd3aYqUewXqIJkUyxqx0XjGjk5Uxa3sAAKkhU0fftFWozFFlpVxSmwAaE/l8nwR2978sAbzd\n2wSXPzVjXMFJ9qUvEisfi5hgq7qitQy7IBPxV86ZcxRSdGeIzAwzaFqNmAczxWPX+HyiSVNR+coR\noQO7fou4OlXa6/2DpkowxeYagQgbcrBVcdkK5tVKJdT8brm++OLL5WRxq/McIQkMWPX4oZCsbl0d\nBNCw6ihXsPDrZC9ppmaqkdwyFjBjWhsl+KFkhqm0CfBosVQ5INrzx/sFc79u3RZvzA2bJcU3XZAA\nYP+YaOymNlP/3XtOgjYj08oLIHTMR0+aAEtu6nkAQE+raI3l773L2+akZP5jebEq3vvZDwMAZiZN\nSgbLOe+VcmxUGMyKtZhrzcg2N0NG86j1GKmhqgSzVJS9yAruBdUq4GdIKaOtjriJNAOwFR7bIjbV\n4GCC2HjVfTZgxVWrIi9b06uk9uHPvvBlb8xtDHht3sznYGHkEaM1RkDXEJuXuAkrSBnivKm+SrTI\nIkmjsf/6H74GAGjWtmV8l3rPm5RyW0quNR6QIFv/RfM8Bi/JPXZ4r7qXC113R7uxjjIlSROrsg0k\nRJsPjhtmpmkG4a65Tq61pcMQaR4+IinGtmbR8C5/lkWLTSdPcE+gVv88Q2FjJWULeSwQv+NrfF98\nWYqy6NV54RBQLZuqOu033kif3q0S7lg2YJIKVzttUjldK3GsxT7iNSysb7AJAE5cNFOJrZoGJsUn\n/Nb3TFupFcvFv+rsFL+x9/RBAEA8aM7R1CXHOcdYQzwtcOMZq73U0IhonQfvkEYWPzlgGHxWrJE5\nXRtmXystp+/o8sb84Ad/CAB42+3C/xYkuAMTpoXWOFt/7biTjTSs+5kjdXiIGrPmaX4jYU31pUTD\nVZg6q1jpuAqjAimXGsVKJ4KsNo5nRcjxXBsq62hsQc4cbGDlXMJoqK/9UKoB/+Pem+WLKTNLl3xz\nDlupXZgR4MsqKw2moKQiU1zRFtHqP37KQI/7B+TZLKeG1eq2hiaTUs5Myv4T/ZISHh8yzzPA62hv\nlphPOsmHVrYq52hl9TFWEWYM6+K4aRwzzRjN8lW05Byjc5ctF7j6y68KSKmDbeVSVsNWB5riI1sP\n4wilirGep6ZmUPE593zxxZfLyaJq/GDAQTIRRjhooLaef8nmFkFqrPa0GRMnwGQkx2IIgnOcktF0\nRXLctXaQRXXaAD2UBWaC7bXDDbL6HzpieNO+/h1pj/3wgwIj7V4nEedy1fDQadeiSFKO19wm2qhz\nwqyyK9pEM/zyr34EADA5/Iq37fNf+u8AgJ89J2pn9VaJK8Qsf69tu2QM/ux74pt+9v/8T7JheZs3\n5sD3vgkAePBRgRDDKhJyqb31G13ZSzWjsR3CoiO6le2cqxbE1PFeDY6xmoeaWADjCSwur1oaX5lh\nQjHuR9/6o7/0aW/Mf/qt3wYAnDnNJpHLzX2o8fzKyHz0nMBo73rgnWYeFbLaJsSnP/6SRMf/4Wum\nQcn6NWIhBFnzPjlJIM60iScMnJHIf3FKrKo1K1d62zasFxBOlO/gVEbemYkJE3EPMR6iQDFljBqw\n2p8XCfxJkdfPTrNcu17AWhdP9gIAxskQPdlh3s8U2YHi5KhU9qOhS4bFeWpq0rOOrya+xvfFlyUo\n/g/fF1+WoCyuqR8KobWtCSHLzqkRiFDJEifNjFA4aoJzoZCYkDmai25B++0ZE7erTQJkWuecsaii\n1ewvuLLNJSgk55ig2uM/lZRMgLRUj35IcOu5kgmqTWRInU0QSkeXBAtHLKDFv/230hW2fYOMad9k\n+tF9OHsfAOCFVySIc+KQmLjb77vWG3PjQzLmj778F7LtR9Jddud2wwtwflqCUKlOVgVa5KVJzq3I\ne6x3yDYA1TR3aY7XaKK7rknHhVkzgSCjYVawVNVFWd0HBqoijnke3pG8+J98k15hzPm1m9YBAL73\nxA8AAI+89yFvW8caCbIefeYJmX9Fnsu6jh5vTPa0pNoiBMN8/o/+XwBAe4tJfY4zuNfE4OLpIwLe\nGmTHXwBYzmDapk1i1q/vMSncAN2f8QlJ/1Xo7zW1GwDOOLt/NDKl3D8qJn7Jwtq3dQqQq5IXVyyT\nMa5GA0ljN16zsW6OBQtk5NDTC/LmZzLyG8haYzZuvA6xF17GQsTX+L74sgRlUTV+KOigsSGOXNZo\nUYdgngRJKqMMHNlkiC4DFmFqjbK2d7JaJW3YJAGS4/0SEClUzZrWNyhAikhKwDHDDJ5UgmZljxEI\n8eOXRAuvvUbGNjVbYKOIaFNt0hAJy7Ybrjf01nt2kE0nJ8FCTJi+9Nt3yPm6O+XYwSRBIP0WcKVV\ntMbed7wNAPD3T4k2vDBpatW72PSjuZsWi1WxBoJHNG8VJ9y5Gpj7qLWaTj+dqknnsVsZ3JqkM52Q\n1eBEQUF8dqGQAmaqc8dUlSiVBJ15cx2//O//DwDAH/66VOzte/oxb9vWDRL4/MZX/wYAcN89kt50\nogbyG2FV3e/9NwmatijxZM7cj4kBAeM8fkBgzstJrLlhjQngdbXI80g3yjVmrTmGwnJPks2yrUir\nc6ZgAnehkOx/qU8CbfsPSbOO7tWmOu/atWL5vXRIrL1+i5Ni+0ZJJa9fIam+KbI49XSb93MZg9aj\no2KZXrwg+8fCJuj64Q/8Av7HP5p7eCXxNb4vvixBWVSNX3NdFCsFdHYajrkRarvGmGiNck40zIQF\nWEk3iX80nBW/fWxCVvqeNdu9MTlSPWvTzL6LBoRRYoHJzKQcuxIQLThhabh4RPysvCPAl398Qgpv\nPvDuO70xWe4fIwhFizoy4yalUi3yb/V/I0Z71Aj/TENW7ygLL2A1BgEtnw//i18EAHzz69LgcnjE\npHYe+aikCtGisFpr/aafHbUais6Wmpd2Y7ETHfFAaK4eqIZ0rLHA9K4FQ8otV8Rs0SMFg7X675N2\nrECsgV/7D6L5X/1Hk4Z78rty3Tuuk3Tcnl3kCmDzTQD47pfFp7/42nMAgA3b5H3IWkAgpRr8zMc+\nBAB454OSDmxrMpDuf/zmNwAAzU1ibY0O93vbojGxoKbYLi3VJOm4ggVhHhmUmMux42ItdraQR3J1\njzfm+R9JYxZN5zVYFtRAby8AYOMttwIA7r1dirZa0qaIrMrfxfmTktasktHnF3/5X3hjwvEonMDC\nCvJ9je+LL0tQFrdIJxBAIhVHqWI0RDwp2k4bAUwRfulaBSM1Rp+n2WBg2coeAEDOijQPk8tscEgs\nhemsgdoWKowbBBRaKmqgeZWJzF64IIy9LUHGA6gNn3zqsDdmfY/4nTtukGi0Uxa/8fCLR7wxJw8L\nw0pihoyprmm1FGDUvPe4FKe0dLP11JQFh90tEf5GMsV84pd/Wa5hxmJaIVQYyvuWsXz8OK8poNF4\nfm9RGrkESWn78YBaADULVaK4qrB+Z8A5eiSHun8+7WGdTT70mYcsWK9CrtkYc9udt3ibtu1g4Y5C\nUtl0cv+X/5s3JjMgkfk7bhB/vWeTwJtvvNNq/tFNiKze4g6Jxzz2J3/uDRkZIQNPkRZQxLQbiycl\nc1KoiIY+10vf3Hr3+tmI41rGJZywbDt/xnD37dkp5cCPPirW2v/8/f/hbXvie+KXP3iraPoay6Wj\nFqy3n4w7Q4Pi///qr38WAOqsZ2CBFTrwNb4vvixJ8X/4vviyBGVRTf2qW8NMIYdqwap4S2rfMTFT\nKqx0ckNmakPTEtS7NCrmfOsKwdGPDRuX4QJx0SOkdbaLyWoeplxNfZGRjGnI0dotLkcsK59jxGI/\ne+ZVb8zAGjloQ1xSM5uvESLKYwf2eWO+8CdflM+v/Ef5YtyiWD4pWPI0ASfDgxIMal+9xhszTWBG\nWtNWBCTFGk2NubdeaxzHZjQi7l6psxU4Y8d8tG7emRXkqyvmZnG5+Wa+nmyBumnYYSWrlYR8sJ4d\nJevBsDGH54ZYgCxMi/k9c1GCpSV2Ve7pNkO2bd0FAIj3iOtVyPDYrqmDR4bRvaiY7OeeErO6/6IJ\n4IWC8syTSTGbg1azi7OnCQBqp8mfF1fyhYMHvDFvu10Cj3n2sy/QPfng+97tjVm+ogcAEGCH5g1r\nzTN/njwTId7tlazI7Dtv2IaOvCo1Hx/9qJCgqokf6jA1HNWJUcDvneeLL75cThak8R3HaQLweQBb\nIErgFwGcAPBVAD0AegF80HXdicscQk4WCqG1rQ2TVifcEjXTJLV6jiRihaJJyYxOi4WQapOAVzUk\nK/R03gBfJqZEUxarrEcPmxRZhUEwzd651IK1oEmRhVlRVWLKLsGUX6LBcOZdu34zACBKIE+Jgcgt\nG01asTgtwcAXvy3pm507jYpqbpFVPlch61A7V/2YsYDSbTK+yqq0TEnuSzBi0j8xR+YW8rgHrNQd\nr99D4FCJOpburnpBOYX1MoBnB/f09kd0f6MjVJsHPcuh/nuRWYEmQl1rVpvYgMKytTNwwQQpz12U\nwF2mX4JZCV5P0jFp3gA1dXVSrIIY22zNTJqOvDFaQOHl8hz3Ma3WP2Se/fbNu+V6HLGqCgWjNYME\n5xx+uRcAMMgg2733vM8bMzV2kGPlXI8+Klq5a/01ZgzbtyEq13ru7ClvW5WBz3JR3ucSH93hoyaw\nfNOt0gBkx60yV7AV2czgBW9MQ2tjvWl3BVmoxv8jAD90XXcjgO0AjgH4HQBPua57DYCn+L8vvvjy\nv4BcVeM7jpMGcDuATwCA67olACXHcR4GcCeH/SWAfQB++0rHqlSrGJuaRsBix61wCiGmoZpjkko5\n02t4z/pGBWKbXiYraIatszJls7rlqdU19RewWka5yibLhTzCopZ0wjROyJCVJx2U/bT+uVw0/uLe\nW8WnvPZaSbl98Us/AwB88tO/6I0pjkrc4OVXnwUANMUNCGPd7dJzPpETUM/glHx2bbRSMlllT5XJ\nNpAPrmZR6aqm9ShWq2Vrf/q5ZHxVn69olekUlBWHmj6svn2dktaUX4RjzTObXesPdx79wXpxjSdU\ntT4/aoGVwHkro27SPI+eLQLBznXIvSmShbmlw6TaMCna/9K4WEVNCTlXrMkU6YSbRdOfelF85NFJ\nsSqu22qstMFhecZhcu5VLL7HUTZvVbbdnTtukPlYTUxayMvwsU/Ke6DMxm7BFIol9domyeLcahp6\npJvEgpzJyTW+/IrED+646zZvzG1338q/6p9vuWCVX0Wdt1TjrwUwAuCLjuMcchzn847jJAF0uq47\nAAD87JhvZ8dxPuM4zkHHcQ6OW+QHvvjiyz+fLOSHHwJwA4A/dV13B6Rv4ILNetd1P+e67i7XdXe1\npBNX38EXX3z5J5eFBPcuArjouq6yRn4d8sMfchxnmeu6A47jLAMwfNkjUPL5PF49dgRtzcYUUxbm\neERMoRpr5ocmLbJNVn+FErJfZpLmq9XkocpL0QBeyQoiVStq2mpfPjGHStNm/+aIpGvcDBtrZNiL\nb5WZ6823CG6853ox9bOVewEA+3+0zxvzv/2KIO1wt9Bqf+ULf+Zt+9EB6d/2/k9K77wgsfa5jDEb\n4xqTY6VZ1WuIYUy4Ak30JCm0HKtxgxXNq/u3ZlNfe+SY/M4D1lvBPd7HME1924DUZ4aaowfE3EFs\nROFoBaD8n4cJZOppI5y/02jM3xo7AIcZcIwRt168aFKwkaRQdi/fwerIshxxwiodOP+KYPv/+E++\nBADYtlWCZOGYSYG6jliiL78qqMuwlUreQfx/nsHWUEjM95YWM9eHH/2l+jmz0nPaQlQ6ROE1LBPX\nZXDUuLIJ9oYcnxGXY8duSRPf9d53mAtx+Y7E5CaPDElAs7nL4h7IT6NSe4vINl3XHQTQ5ziOskXc\nA+AogO8A+Di/+ziAb8+zuy+++PJzKAsF8PwrAH/jOE4EwFkAn4QsGl9zHOdTAC4A+MBVTxYOo629\nA+GgOe042UouzcjnubOyks0UjPrYulMwzLFWVumdk1TIVM5oypKm7OY5b5CrrctAV5W1/rGgYeCp\nkl2nMi3qaz0pjx96u+mjnkrLqp+flDTLjpukXvrIa+Zc0zxOOimpx0d+7Xe9bU9966sAgP/yB0Kk\n+Z5PvwcAsPO6dd4Yh73nw6wArHBtzsEE8LRxg3apCletqJyXW+N3mro0Izztrym+MgNGYRv1xH72\ngVhT3eFkAgE9EP/np61G9F7z/DkGFPNWMxWdv6bRQg3mvXBUe9JycFi7EUyu9saUWGvff0ICcD9h\nS7KfvmQeyJk+GRNmld07SKJ6+PBRb8zRQ7JfioSi973tQW/b8KBg8zMZ0cZ37JF3cfutpq5gelTe\n2QjBOSXWiaTbTNB2lAHExIS85+3LzLanHhdQ0TseFPal+z8meP5yn0nVhdtZFZhjLUmDvB9jGZMa\nd6LBWQ/q8rKgH77rui8D2DXPpnvm+c4XX3z5OZfFZeAJhdDW2YFE1KRtOthMYmZatOnpcwKlLFZN\nmiLCZhvHjot/N0AGnamMceZKdO4dBWyErIYarFEvFmV8pURtEjOpobFBqaJ7953im7//fqkOG7z0\nE2/Mb/zvnwEABJNynE1bZczObXu9Mb2XBHiyaZn4XqNWOyY3IKv8oSOiRb74AWGe2X33Zm/ML37g\nE7L/Lqnm6t5MeuiggewGeT0ewtaiGfe0cVlsnwr7y5esdmMlL7VHfgL2dY+Pm6xLlByIwWZqWNtk\n8JC+s1JHVsNGl+pfG3qonk8ErHQc6/jHaqLFmq1UVES1Jb86+bKk44qvmet47JmnAQBn++XZda8X\nKLUbMrX2Tliu6b0fECryo8cFBnv8hIkVXL9TUnSZCYnrnL9gtmWm5V175BGB367k8yiMGDhtgGCx\nmLbuInQ3lzVxqlBEnlmWbcI09gEAv/k7vwUAuOtBsTQKF3rleCnzzMfZ8LVJfXpWNGZz5tlHY5G3\nHMDjiy++/P9IHHeBbXXfClnZ2O3+xs2fQUeTgZiGyrJa56fEb29tEQ2xdtMqb0ylWVbUkzOioZ48\nJRrzTMYcp3eMXGj8LloxqcNkRbR/KMtWXHlZJWcaTD3+GrK6xsgEdO6c1Mz39xl2HYf+aohR3zw1\nbZPF5hJPyHkjhKPmi2ZFnpgSzZbNEdjB1TkSMdeRIh/h8hUCP33gQfGmdlxv2Ho3bZG5rrtmGedl\navWjKTXiyEhErr6ENcdpsvmkWxnjKGq3RwMLrtDfD6XZHjpnoLIhRv9DEWotNTJmDGAlzAwMJnn9\nLIBB0dJIbJgKxlwOPfkdM8cZecavHRZ2nQt9omE7A6a4RZ/Z6XMSuVcrI2/xNRZZFLSKTTsPHxXu\nhPe9z0Bu9+wSBuNPfPyjAIAt123ytn36k58EACzftg0AkDvXCwBIdBnYSr6ZlgsLxZoJ2ko2mgKa\n2oBYDuW83Ltoo2mPBbVuvbiIxl4sNmrvbxmjGLiAhboKwsHuD30aB48cv6ra9zW+L74sQfF/+L74\nsgRlcevxawVMZk+gIWnAD63EUaT4XVurmL2RpMG4jxDqe75PTKn8tJg7FYMFQbAqZmpUU0MBE0Cs\nVsQcKjL9V5oSYMWloT5vzMyUpEXiBHZMT4tpW7RM9STr3tU0V/z2jEV9nSO1swZz1D0AABBUpJTX\nXs8Ki2ZMgTtnzor5+sUviavxF64x59s7xUXZsV0aMPSsNU0qNlwjJu2OG8Q07VlFiuaqcSfUxM+P\ni8kfJ7a9OGWuI5riM2LlWCxmgYSUDovVZNpXL2z1pQcJURGQe3bgh0ITfvaUSVEdfVXSbo1peXb5\ngjn/hT4xycfH5BndepukVbcuv8Eb88ILQojaRjz/zl2SeDp11gTeDr0sfArqnn3qU58CANxw5+3e\nmGPPiTvR09MDALhxt0lg9fXJ+VtIxJlYTVpu670YJR3WylVCp10alfs6csJQq7dzWxS8Z1aHY2iH\nW/IRuF6a07w7AWcW9wHdgoAVYHV86i1ffPHlSrKoGj+RCGL7zhRWdRvwQluDBMPKBQl2VBiMyVhI\nnKFxCX6MjsoqV8rLPlHHqnAi5LfK4El2ypgDVUJio4yhRGlNLO8wwT3VCDWFiBI7G42E5oxxCUJR\nIFAwZFZdl5VyJdIhu1Z6JcjUmoJSajUFFJnUZYD12rGAzDHMY2dzBvhy4Tyr+/qf5zktqyQhmnnl\nCrnHq1aKdm9tMWm04RFJmbY2yzm2bpZ0Ylu7gX+mUnJvlrPJRGubCQ72EkCVIohkcFCOd+6sob4u\n8Dls3yoViccOy7YDVounlkaBSS/vksDl2JgJpD5IEM3KVRIg+9a3/x4AcCJz3BtzO7X2Le+XQN3z\n3xTw6Pe//31vzK7dEri7+z5pyLF283U6QW9MjFwMv/4bkl7t7jGNMJ76tnQm3rdPUoe7bpA0azxh\nAqEr18scJ3slINzU3M7rM++XZwGxs25hwLRdi7VLoNBVK4DvjMW1iYCjoCvCrQlYcyzGHafma3xf\nfPHlCrK4AJ5IDZ0r82juMBoqRP92ZEbADucvCMfZ8KTRgkM5Wd0msuyHHmGNusFHIDMmvvX0JOvZ\nS2b1ixDUE4qrb074Z8Cs+oW8HKxEi0PHhCx2mxrZgjQFqr551Crq0NZflYo2orQYZ2q6SvM7Xa1r\nZtXOVZlG04YYjAc0RIz2qGoPdFoKJUt7lViffeGs+JJtTbL/slajsU++JqCkocFeAMDf/o20qVpu\n1br3sHFkJ+G8n//857xty98u0FIU5J4FnxULpNRo4jKd62X/s71iHbz/ISk4Wd1pGImeenofAGCQ\nbDv33nGHt+2G3QKOyhKiunmzxCzeecd7vTFqgYF8fDk2YH3g7Q94Yx559BH5Iy3W4RR99lzGpCfX\n3CRaHIxxFEaMNr7n3e8CAFw4LACix58Qa2LZMhNX2fv/tfflQZZd5X2/8/al92V6ehbN9Gh2bUga\npJGGRbtAhcDYgC0LlUIgJHaqsImdBGJXUalyubANhqRMXCYmLgIOiwUIs0kQIRYJGCQhENoYDZpV\ns/T08np5+7335I/v991zeqZHaoH8ppW+X1VXd7973r3nnnff+bbf9/uGrgIAFDVow7RmerW71/o+\niTsUSxIHKZQ91qSUgpxkrfVxiHwfn758ium8DJ/BhQhdi6VSbCcaP5FEVqB0FMCzeU2X/et3XoJi\nyfmSIYE2x06IFXDkOfFlpz1wTt3Kbt0AufZYfnngxGQ85shJ2aWVlKd/wIEnurtZ0tmUc89xR055\n216doB7Vpmk2TFDNDwBBW2HB9NXZOKHd9hhwVOyZ5UK6gWtMQK+f8ibi4LTyWtDU7d+dJ8vS5Tyt\nka6SKzHNK33dnKzNIJs9RoEr5hgakvf19cg8dl8l2nVsgytauvXN0rL68x/8MwDA9u2ulffQiFhc\nk1Oy5lPMaoyMOg23/TLRgs/8TCLbn/uc+N/XXHtTPCbSUmry8V396t3uPvrlnmrTJzhW1rOry2la\n6Lqf/gx7MZdmnVyMLKvtGeJz4SVbpsjkO6DH/M9T/eYin70jYp088ICDcqdzMreb7/xXcj8HxapI\nF/3WaGKxRfrsrXL3MTsuWYEc4yrtxQptOI80rcQsLYDsguIpYNdt/yYB8CSSSCKLS/LFTySRFSgd\nNvV77Ife9Uq0ApcKmWNqbnJWglATMxL8mJp1gJHpOZnjbF1+P3eSFW+enZMupPib7/N6xQU0nRqM\nmrQZFOvPOLy1AnVaLTkWssa9UXeByJqm6OxCU98H+Wjtv1FzzTP5lQ9AiShz5CXIeF1q26zpLuRl\nHUIGKUseXbh2x9V+ehkvoNNmHcDIoLg3MwTAFHIuvXnZJRsBAO97nzDHXHSxpK/mKq6SEEYCTbOP\nCffAXXf9U3zoptdJcG/HTtJHD9J188FKSv1DINX4fjGR//A/ONa2Sy+TVNt//M/kaB12Acg6qxzz\nTE/qek6MO1ab4TG5j9mT3rwB9HhpSW3E0WTgz9JnynvVmzmmbDVV1qi6axSKBILx2Qnqso6ZHpdK\n/u6XpbNvhufcR9UzNwAAIABJREFUc4MwMwVz7jyZ9QKsCqckWJkuOIDZLFPARQZH29pUxv9usvo0\nE5ASPdD/vTGRxa7b/nVi6ieSSCKLS0fTeZHNoNYaRKPpLjtdFc02Pi874BHiHI6Ouwqrypz8HSqN\nNHfEoUGnBQeG5DxBWrTvqVkH/5xvESbJXbaLLaxmD7uUTpxCsacx1viaoaQwXE0HKkGeC0TqVpvi\nbh1Zl5a0UWvBxfQabQ94MUfkksKM6zXWb5fcmuVpKRjW2Hd5UNl2WjRSpSJBsd27LgIAXOhVO37z\n68IAVCdlNRi07F7r2G1+9q17AAAf/OM/BQDsVOALgFWrOW6IcGDW8yPnp6j4e16ucdfnxWKIPJx1\nP2mlv3f/NwEAY+dvjI+tV2isrig1XbnHaxfG50FhzmpJBV5jjpBr3q1ErwqPDlwAr02LrcnWbl3d\nTpuj7T4/AMgwHec3H9lz9TUAgA9/+CMAgM1bBBA1smWre+O8fI6WadoZ77y9bJkFWqs+hFvFUMMb\nNpqxrMOPPIvUNtpnciScRRKNn0giK1A6qvGDIIXJqW60jdNQc4Fo38mqaLiD45J2Ojbh2GByBdmt\nh8k+MjIoO2MYTMRj6k0W8ASy24fG7cj5In1xboZVMvDk864mWv0pbqxot7Tflpu/Zt0iwiXbCuTx\nm0TQpzfUCFnjLIZMSu5ba6ht3LrKA/DUCTIyTMOxh3zg1ZibSJmERJv6jEbttqTx1q4RMM6f/Kn0\nUV896DTlIz+U1NrDP5KGIFfsFlbX4w+5BqEf+C/S9HOeFsjG7ZfHx37w0FMAgFtHWRuvtfYtByRS\ncNHX7v0WAODJp+U9b3vbW+Ihv/lWoWn8+le+AgA4csCtw/rzCZulb67xg3zRPTtVAm4UPpsiJLpe\ncxpfYdJqXzWq8lwZL/aSZ7o3UovSYy1ukftP4zHg78CL62R6JFZ0y5vkfr5y7/0AgHftdAVF4DM3\n25KYw4AWTwEAYetqkS6ujflqQ+Zooirn4R7QwNgFoJ/nk0TjJ5LICpSOanyLLAIM49lDjoL/iQNS\npnm8Qi1IcM/oercj9g7IjlzMy65dmT4IAMil3c5uU/SB1D1qe5z72l6LDDOGv30AT6RwWm6YGrFf\n0O6LSqLN1lXqh/vVFCkCfww1TOzXeyfPxRmHM4t0BvOr+RqZgAfkhurVU/GYnj7RehNV0e5Nr8lj\nd5f8/fY7RLNu3iz+ajHrNMHObbK2jz7CVgk1YZl58DsPxmNa8zKnwfOk9PfaN7wtPvZXf/WXAICN\nF0j56kWXXsTJO9DUvZ8TGPDf/N3/AgDc+kYputlzjWsLpW2grr1BCmge+tHe+FDlmBT+9J23UdaD\njVbDjNPU6gurtRYGZ4KmYnAU196Bp1w8osES7JTGbDwAj36e82Qk0qKpfLfLQKAp1tRTz8qcx7ax\nPZfHaGTpv8dQ7B6XeUBBgUwy/1akWR83x9jr10ajZFrKRu4r3GhO4fTWpWeTROMnksgKlOSLn0gi\nK1A6aupXZmZx99fug8m4AI0pSoDtvA1CLpnpFhPIZJ2Z04rEFJtnRVUuK6aYH/AKmZ6xVsyrrHHv\nL1gxxbJWTEsLmvrG4de1G5SahpYY/cgZWciwZVc6TTJEpuFM6MwrrbGPtJeXB8IIGcxrBjQXM6y9\nLziT0LA5epiS+ymQ3aacd8G5akXco+FhmU8x5VJk732PmO23vk4q3Yp9NFsD5w6MbWD9d1PScB/+\n8w8CAFZ7+PHrXyMglEePSdD0qUMn4mOpstTRf+ouCcr9+SsEiPOFT34mHvM//ua/AwC2bZOU1m+8\n7bcBAEOrPBOZblCxW56HfNnd4+S0BC77hsh5UJbnwqZcUC3Q6sQWQS36GXoBLq2rsJG6XjT5C+4Z\nnJyQ56BXCTAz7vOYZQBRaz9MUeb4zM9d7/pjx2WOTx+RNZp9QuoTvssOvQDQZrB5+8VSF3HZHleX\nEBXlObjwEgmymjTTkt6z12ZlaI5sPSkN6Jb8Oo/KglZpzyeJxk8kkRUoHdX4xgDpnEG5y+2o3ewT\nXiTAIuJu1wxd4K7ekr9bBKdo2qbmpTIaLa11Z5NH6+rX04Gmu+S6GfZBD+2xeIw2gkxrxZjCa7x0\nXJs7sFWNog0hfVo9avUcg2n5rEu1pWLmnibnIa8XPT67kCCSAg2WsC1aubvoNQHNy/uLGRm7+5Vb\n4mN33P4GAEBQF405NyF14N3dLphUZvYoQwCQMgrt3LY9HrN5g7T1uud//m8AwPDa9fGxCy+VoN6n\nPy3HPvbxTwAAPvuZT8VjXvNaaUzyx38kTUSH10vKL5idisfEi86qtGMT7tjeh4Vz79U1WfNLqA3T\neaerMrTKQm3Lxeci57VoU84DG2iaVa5Z8a61aqvQaduKrNm816hlYJ2kFY8+K+w63/m+pEJrVWdl\nmaIEZK+6UXgAdr9S1qd7lYOERwQVpQhBDlPu2d1/7CAAR9eeVk5HT3tHmm7mfWijUeXpk4ksTdvL\nuRNJJJEVJ53l3CsXsWvXTqSMu6wWvLTb4r/X6+Iv2bbz33XnKzB9c4INCKsNl3ZpNBdykqVCd42Q\nMMcU4bOpHAtxMq6eXzE0ISlOA6ua39P4kVy/wTSeZo/yJecvpqhRSoTR9nZ7x3juGttTpSyLM9Je\nu69cm++X105NiI/pN8LetFa0d6MuFsttb3ljfCydY9yB91xv0nIaGozH9BAwMlMR//3O26Xp8XzF\nAXAOHRZLYdvWMY516cQ5NmqssEHIpz/9aQDAxrG18Zh/+3tSAFToEp84IEvQbNMBs7poeSlv3DNH\nnAV2z73fBQBM10T7HZ+W+7n+ta6xiLId5zIL06O+mxsxDhBSY2o6rafHA5GxzZlliq/lleP/8N77\nAACPscnmhjGxrt78VtdYM9sv1lBOtW+ez56XXjQhjynoq+RAXxoHqVRkXY3V+I4bk2Na2Wo6s83P\nymt0ms7YJSv9ROMnksgKlOSLn0giK1A6G9yzFjkbwngVaymaYgWm44oM1DQjN6ZGpFyV6bReIqxy\nRQ+jzrSXJZIpE3hBoBxdBaL7Smm5Rs2jrGqHC833Fk39VuTOo54FvZG4Q287dOarosiygf52959i\nSidv2a2Xq1/2qtp6B/g+uiNZS/x22l2jzPu54hJpMnHNqxxJZYs0zjk2xCjmaOo3nf06QOLNNivl\nVrOz7+GGo7eutcTsZFk/vv2NL8TH5llpNtQtDsillwuO//d+/9/FY8ZIthkySBsZcW/yfiUhU6eN\nOtNyafd5Pjct13jkKUldHjwpi75pnXtkN26UisOC1sYrPbVXOae8Cmr/G9Kwz027ysyeDRLAe46E\nmHfd/bX4mKae336ndEoe2S7pOFTd54E+CRq3eR8NUpEVvSq7jPZp1KBey+8GI89RH+m4q3Oy9u3I\nfWY50njFXjK77rbrjnHW2joWtjU+uyQaP5FEVqB0VOPDArYZIu3tyEUGdkoMSuSIkQ/TLuU3n2EK\nhgGS1cMSqGpmnIaoEsRR506c8ZpM9HKXLVPToi07cuhRTgfMyWmZdJOavrGIxq/SAuElMT3jtEdL\ne9Vb2YkDv1KM8yhwh+8uyfz7Sh7ghHwCSpm9ZkTWoTrjdvY2d/vfuvXN8kLW0VrnGNSbf06CcV29\n2qXWaY/5OXm/AqCmK1I7sePaK7z1kDTinm4BtaxZ5+r57/6SaMQsKyHf/Y7fBQCsH3H03JMnhPmn\n3C8as95iWrLfrbllULNFLdU36q5hSvIZz1taCA15VB//masg7O+R6xXIrxDFGHun9ZSWOk65Mj3b\nMzQSj3l67yMAgO/vfRgAcMEFl8bHbrjtDr5PnoMpgnR6vW63k5Py+ZcJxOru4+fhAcziykU1AjJ+\nFC5YMO1UTT7rattZBTmtg1BgG1PcUdN1KEa76ijbX0ASjZ9IIitQOttQI5XBYHkYOc9/L1Izd2nr\nKt32rKdpiWaZoRUwQf+7lnNWQYPpQISizXvy7hpjQzKuB7JLNkjZPGG8xprcgNvaJIPgkILHaNIk\nMCSfYSsvavyevNNiTaYhG9TKocc4kyXUt6ss1+2h31cuepVijBeYSH6nLVl/ImfB7NgiKa2LdkiT\nCbR8wIrELUpZTq5A7WPcekRtbQiirZp4rM8lDXv75ZznbSFwx2uEEVbFQrjyUqHc3rSVmjr0qgw3\nyPjWnKQM2/S/I+M0UpufealPtNmmHRfFx3K0VFpp8W0zPaKhDz7rGlFefinr3bU6j+aaT1eeJiza\nMh5jmf565sD+eMzDP5G2XhdfLJr+yptdehQE6szMisYeWE0Kci+/2sU0oOH1awTrVI49F485eehZ\nvk3msWrYWUfFEunS2bZtrjrD/93zDdXsVVbwkc8v8ioJs6loyY0zE42fSCIrUJak8Y0x7wXwLggf\nzc8BvAPAKIDPAhgA8BMAd1hrW2c9CcWGaWS9JhW9jMb3KtRVARehiwOkCJxpcZstUvNGHvBFG0nY\ngux469Y4yO7l2wU6uSonu/bcKdl19x70ND4tjJBLEqTk3AHcrtvmsUbs/8vrdQ9EETAS22jSf226\nOWoUv6dL/NYSmYEWMKzRL8wTaHLypGjXwNvZb7zuegBATpl3y87iiKbZsGFEtHDzkLSwyg87Hrmh\nIVmP1dRea6mdw/1PufMYXo/reegbX4qPbd4gxTxX/64Af3CSQCivyAZV1rjzc121Vt7T8LjuJqfE\nOlvHdl3n77ggPtY3LHOrVDie9zWf9aPYirPmCmrRVNrzn7mOUVssqBYbbOzbty8ecuWV0vxjy0X0\n7T2eRTVAu7rlPM0aC7S8oidD9/vhR6Rt95H9cu5wzvnf4bzcay8zUbUZx11Q7pLrTU5LXGZkjVg3\nW7Y5sJJmA2oVWevqrJy77LEvlXJ5pF4qAI8xZi2A9wDYZa29EPKc/g6AvwDwEWvtFgDTAN65tEsm\nkkgi51qWaupnABSNMRkAJQDHAVwH4C4e/ySA33jpp5dIIon8S8gLmvrW2ueMMR8CcBhAHcA3ATwC\noGJtjMQ5CmDtWU4RSxEWF6Wa8O2RNP+2aabj0nLKwAMvZHJiyo3Ssu0n0eG8lypbzVTdZEtMzL4Z\nh01f2yNVZ9rb7acVSQldmvpRPCZFk9ASsFGn11JrO9My0J7krIzKEpsdFZypH9FFadE0r7WcSahA\npFYg5mbUoKnq0UDNT9NFycu1+gfl2P5x13v+wt1iAgYDTBlal07MbhDXpD4vfe3y67QfXDwErYyk\nok5WlEBSTO10yTkdawxr9vnG+6YdselNt0k/+igr17I1OU960HsEZgX/3hqQ9ZxlwGug6NyBOHk3\nIRj9VSMuLTl8nsxl9oi4Kq9aL5/dutUuDZfRx4+goGzqTA6EGbpKvZulAu/z/yB1BWM7Xcpuy3XS\nyXeSzTp6I692gn+2SEFumWJrV91z8cCnPgoAKLDscTvrIoY3ufTk8KikSouDTAN69R0gDn+anXyL\nDFqnsl5wb550XJDnI5VTN9GjfQszWKouX4qp3w/gTQDGAKwBUAbw+kWGLhpONMa82xjzsDHm4Zlm\nfbEhiSSSSIdlKcG9GwAcsNaeAgBjzBcBXA2gzxiTodZfB+DYYm+21n4cwMcBYNvgKpvNRwt3CKZ3\nrKZ5GFTKeO2xikx/dbFm/8BhCYK0W14skRZCjimzOlMiAPDkE6LhTxyXKZ4aFy2wc8gFWGpN0dTV\nNtlcGDjs8TqehgRxaNddbctUyHrBIP6dUbLOnLsPQ+2fpuXQIv7SZ/np6hWNONuQ4M0cW2Jdd8O1\n8Zg1hKqCQaG0R2utbbpUs4STXAcvYNU/IMHAnNa2j7BWf9pV4OX6Jd304IPSD377TtdQY4h15qmQ\n1kk/U43zTgtqJDNiUCpNsFXbg7pGxEfnNerpEZvu2SMBt8e/9RMAwLHjog1ffdX58ZiTbJ2Vfugh\nAMDUtAS+5upuPYZGxZr5+v1/DwAo9Ig23nONW8/KuFhMpZJYHNPTXpuuVfJ5KGdBZUIsqS9+wbUU\nu3qrWDqr14pVsnoNmYwy7nOdpXVaPyGp5IFVw/Ex9Mtn1b+GFpOW2IUeGIfpu5hYlJZlEDpTLjTt\nmGnohWQpdsFhALuNMSUjPEbXA3gSwP0AlCT9TgBfXtIVE0kkkXMuS/Hx9xpj7oKk7AIAj0I0+NcA\nfNYY82d87RMvdK5U2qJYjuJe575EBPUot1g66/ak3l7RVgMDon1Xrxb64qlpx5l3fFy01clx2fVn\nPYjr8cPiJ7ar5E/jDtvjURx3UZs36DZOVQlnnXcAHK3DV+rtHsI2217BhYJH4r0+dBo/IPRYOeLU\nRQ29FlotwjfnCdjIU6vffMuN8RiwSGee/emt9ymWWMNdm5RjYY0tpIounZcvyPsHBgkiaXCtvEaj\n1ZMCPskQVnzlax0tdo1rpdo7q00zvXp+sHCmnZL7SDNt26i5tSpr+o9Q18gDdt1wvRQefeljwupT\nJLfc1ITHC0A+vMPsWd9g7KdvyDHfmLxo8wobjL7jDsYnPCh2mQVNzVBr9t2CtqqiQU8dlwKmH31f\nmmWMDLj13LFNavQL9NsNnw/rpaQzfC7atMga815jTo1JaI2+Voo1HGgrrMn8Q58sAEDGo3aXhq1L\ny+ctKY9vrf0AgA+c9vKzAK5YZHgiiSSyzKWjkN1UCij1hAsaWcRNEfi/9pawHidZTzeLbMpsXU3/\nd6DPRcPLBdnl1w6J/zrj7agnTohPPz8lPmFIPrrHDrsYQR+LNvqGxT8rs61S3VOnDfpZdUbs1Zsy\nHu2J+tjafLPlaXOFqLYI/mhqlN8bk6JVUI9EM15ykXDNbbjA8eop/FZbg+cKbh3SBB6VhujTRzzW\ndNo0T4aYzVsUaku/u+zAIE89LSyym69gcwiPGbnGiHae0e+sam4vg4EunotmTZvZmnKvg6qm9Jxa\na1pz/v/W88U3v+Ya0S1bSuI/X/dqx/23dowtvLTltH4Og07j3/N/xBffdoHAgQM+8nMzDlxTZllt\nhoUzBQ8KXmVb670PfFvug1bj7W/7rXiMCcQKUXBQneAleO3PtfVXjoCbtscwNXVK1rPIMRr78But\naNPMtDZlYfzA1/gmlYJZIoIngewmksgKlOSLn0giK1A6a+qnLco9YQx8AZzZmWblXYspurZfdcQG\nGimIKdWiqZ7PO/OzxIBKV7+YUsN9Dqs/SBNWce9NFtbPz7pAU+WQpItah0i8yPRTuuBAJVmCT/LE\nW1u6Ke2WC8LAMN1C873edubvHCOHCuqpsbFG4OU3WxHrCVhvfckuAk0810fN52JJ79FdI2K1Y0r5\nDAgWgtfdtdQtx4paFUj3KDrsQEJ9Q3LffUzdtb3a8izN1W42uUCTn2fuzMepwADqXENM5EJ3l3dU\nO8DKHEtelWKBZvfNr5W0XpEAlrUbPJAQqaqjWXke6i2Cv7x03NHjYobfcas09MizF32Xt5z79ksg\ndOtWcffmJt1zETDw+cunpDnGO26XjrjGOrekSdx8imnJbjI7hZ5aDRTYVQ8XjAWALqaM4/oUBvv8\njzzDZy1N0z5jlVzWkyBcAF56Pkk0fiKJrEDpuMYvdYXIeqk6jcsoRXKLteX1utP4ARtQBATZjAxJ\ngKjhVcVpYMXyljJep9FV/ZJ66c2Lpptj1VSl7GC9M1XREien5Ng4OdmqLdd4IVsUbdXXL+/rIUda\nzgNqRMrdx0Beve1SOg0GbWoEZmiVX+DtvxqU7BqUa1y+m62WPF6+Rku0p3L9+cHSHCsfUwwcNng/\nhWEHde3bLBxzc19kEIrr+9WvOyjGdddfAwBIs1a+5sGjHZSUF1bgTZeD40YpvW/RSdmcaLW2cRop\nq6kpgk6KZc8aII/B2FoBuhx/nNV0WRfcszPTnI9YfuUBsU6eePSJeMzOiyU4qsHJE4cEetw97MBb\nI6PU9Iz31WsuFXzyyEEAwNZNBOkMyj22po+7ueo9atWpNsTw2HBibR4uXBf5k+vH50Ip2lN+4M4u\n/K2a3XognyiKEo2fSCKJnF06nM4zKJQMjPEAPGyCaLmVmZSmLdwYLdgJmNKYbsiuXZ1xgJHuslgB\nfX2i3ZW5FQAa3Mqr8zJ+YlzeHxUcgKe3XzRL9yrRKEME8Bwddxr/FOvHT0zI+8eZ6hnbtNG7S2p8\nTed5AGW1T1qs/ddjPoAnQ7+9h/S2NYJ9ujzASY7Q0mZNfNuM1zIqqzX6yu83rGk1b4+vkCOuzPgF\nmXkrsy7Fdey4aLQt2+T6ZS/W0WRQokWASU5NDq8VmPafD8gkVE6Jpmw3vYIi1XoKJ/YYfNQKSJOr\nrz47zrE4Q6pML5YJXnp6/y/jY5ftvg4AkO8TC6qPy3H0hAN/bd4sQKzjR+Q83UV3H08/Iew8uy6R\nQq/GjMQDCl6jFESM+XD+bVqPfneLDH16BQe1vXtVMI+CvzQ9bDyNr4+RKnT9dqQ9yyGdSi+5jVai\n8RNJZAVK8sVPJJEVKB3vlpvNmthkBxzFswYpIuZAfOot7WluaRIXGMyZbLgKvFyGnWhpT8/PeOkW\nVtOV8mJGrx6W256MHFKtVheztVIRs6vKVFvOq84bOU/cCI2nhKyManpzVTNN7zDw+gQGdF/arERs\ncpC3HAiJhjtwWEzKT/7j5wAAV1/v+qm/4gpp6lAuiXsThC7IWSe6sFmR+89xPb99zz3xmOcOHQQA\nbNTUGNOib3ij41J5ep/QcD30GeFaeetb3xofKyrVV3thIClouDXPELeeJ/JRzfrAby1MpFps4s+5\nzxM0iUP258srIahXeWdYI1CYoWlNNyntUbIp9flYWt8un/PaUUePffSovNbDuoSugruv489JHUDh\nQlmrAgPLmHV9F9VVUdRmSgNvfvyOx4yRiWT9Zhunmfjxe/x/9PuhXX91in5kd6m8W0g0fiKJrEjp\nqMYPwwhzc1Xkck7TFgsEOxDoUmf1VsbDhhfIpDk/S61cIyW3l44LqKGPHZuKr6WiJcpNaiS1IOat\nA7VoC62Q2kLfX/POE5A+WZWWBl8iv485K8wCnq/WckGceab2mtTCbX2/V4euXXr7+iXFdPfdoqnv\ne+B78Zh0kQFEyPxvuuGa+FhPgZ1wxyV4NTYqmuqb994fj/nxDx8AADz4wHfkPKxAHNi8LR5z9Vap\nDajc96j8f4W7xp23vx0A8LrXST/40fWC+e/yOvKqStL0oo1BOh4hp7a8mhWtPPELR519Yt/Tch8M\nMl55Oam0c05TNk5JwK/AysNwRiwGH/w1OsI05jyBYU35nWk6PH43aayrs0wP1p0Fpc1b8tqPvlbh\n/bkxWgOvGlvrT3zjJq6j9/D3p8vzJeIUzKMBwNQig2UeSTovkUQSOYt0OJ2XRrHQi4ZXZ9yiFtb6\naC1aynplxyn6yU3uloFiXAO3++tGGtByCEN/u6UPpSAI+lktD2DR5vYcQyvptgdeGq3FnT2K0yxk\n6/H2T9X+WonX9AAVTV5DX2swZmE9iyEgnLdJXy6dEstnbtat2clDUht+ySuER+71N7kGEBs3sGKN\nVpGtiqb98Xf3xmN2sPFjiz56Rvu5e2lFTQtlC+LPZ1LOAvu/35Ce8T/83g8AADe96RYAwGaPDrrM\nuEGaAYwMAVqFbqfxDxwQnoQT+0TTp6dciu2qHZI+u/AKVn5v2iC/qy7lWGD9ulpi45OijcsFN9eQ\n8Z2AlX95NlytVnyabvXNZezMnPPfFVhW1uYWyiC/SNosWoKLrZr6xYxdTBZ7//ONP2Ps0ocmkkgi\n/79IRzW+tQZRmI0LDgAH00wZAXxMVdg4Yc4VSkSMWrdbtAra6i+5czeporVfg+/jm9gnlz9SBAk1\nvRO0VBvHbbK1Vj46Y0wE1fw8r/UyEPw70CIdrwKnwevV2cK7TZ6e0GsrVcqJRgwI9xkeksYSUcb5\nlM1QtPjFF0qt/MbzxtxCaFEQfemZI+IjP/usK8A5f0x46yps55wpGl7Lg8yyEOmhn0p0f3TUXaOf\nfvbIGvF/b7hR+OsC48y0Y/sPAAAeZ0PKRkM+z8v3uOzE1q1bAQAXrBXQ1NSTrqHHhtXkrWNdf8RM\nhO130fg0ORMstXeDsOIur326YRyhTY2fZtu0oOosqICsR71l0erj4yfjYzlG7PPKjqOEsZ7KPJv2\nts+j1V+Mdl7snGaR9y/Fioiv/6tdPpFEEnk5S/LFTySRFSgdNfWjMML8bBODg45auEyzE6ze6tt3\nEAAwcepwPEbBNUiJmaY4/NDDn2vWLKRpHXp2lgJ/1OS3BNL4lJ8tpcXSijmNH3omleJV9Nwhz2A8\nu0tjee1I3QlnxmtwT432ptJ0eR9DSVN8vLA2DamHDtxSYnXczq1Mv3nkkKgTzMKb2/cLSYv5JI1K\nXd3F6sLDx8QNGF7vahdAks4f/UzM70zOAZkmJySNtnvPLgDAuk1Ck4WUu9eNY2K+j/WKOZ6nC1Ma\ndbRYBf2bPAXVZw7ExyqsJ+hbI1V0qX6Za93rR1c0C4Evw6xoPHrQmeqhrgfr6tt0G/Pes2P42RfZ\nmXd2ygX34lGs9lQXMu31f7Seq9YpOZsbsVQPItH4iSSyAqXDwT1J1zW9VF256R0EQHwF6h4cVEvz\ndWetkjgy9KYfWQ2Uyf+hXwttNMXH9BmvlfdSMiFTaprR0iYXfsAkiMeqVcF5LdLEQIODbS+dp7cU\nWw4wC34DQEQIc2+PaLiQENzqrAvuDRE2unEdIbd+DTZhpyAQ6omfSzORbM5dY/sOAed0r5JAWe0g\ntaJHr31yXOi1jxP6fH7ZkWTquV9/i6TxFDY623DU1+lp0bCP7H0QAPCGd/8+b95jK9LcLbVpxkvD\ntZSGmxp2nhZAzmNdAoE2auV1D4sFMXXqu/GQ/l6ppFzN9l5Rs8FLOgsmo8+KBgLrLrBc1wYg2sWZ\nz1nag8q+mKDacpFE4yeSyAqUjmp8KTtI4dS486Hm56gB2J1wgpqi2fI1tuyyyqlWY8oq8nIiEf1L\ny72svYDYhcV+AAAG8UlEQVTvjBqajm+bKbc+rzmi+vtqjOiZI29vVM6AuH0RNW3kAV+iuB7/TOps\ndfe1UKVNTRF5MYKQzDONmtxriz5q1rNOVrEF1lr2UUfN+b3atqnFhho/f+xhmXvkNG2KVNdKM57W\ndmXdbj32/1hiAzVCmE/OOAaetSzAGV4jqcaQUYtiwaXRmhmBTm/dTOCNrqzHvtSM6G9zXU5OuOdi\ngD70KnIGhBlZ82zGQW2bqvG1SIpLFDTcXCeOSKzo/PUSSzIaC2p71NXkM2jOykTynv8+Pycaf55A\nqDybqyLlvjpL8asXS7/9KvJ8KcIXI4nGTySRFSidL9KZraPWdD5UGAmIRFtQN1rcGtNOe9iU7PIa\n3W/TAgi9vTagnx1Qd0fe1qjaV/3/iBt60HJx/ZCwYIXPBrGv78UBIrvgWGxJRO480Wksu36sQf1+\nZecJCASy1mmYKhljT02IFu9ms4eRVS7iXiZDTB8bbMJjpwWvN8nmjiAM9cKLtsdDRkYkUn7ylDQR\nLRT5GITOKnjscWlWmWEJbjtwWYVrb7xe3tcvx6oQ3z4Fp0V/8pMfAwC29DCDU6E297ju8hn1s0X/\nFLtdW6oW2ZL0I67T4un24dH8zPPkUtSWU5vO2xCPOXxQYhX1WT5nVtuhu7kqo1GrLtq9v68vPlZn\nGfA8Yw6lwTOZjc+mzH3l/HzAm6XI6Zr+1zUgEo2fSCIrUJIvfiKJrEDpqKkfBAEmJiaQybsATZ71\n42oat2luWuv1/abRVGVNtxJShvZMU78NNfm9FBkNo8hoAFDf45nomlpjmkZdhchL1cU11VG04P/A\nM+c1tRbGfcy9wF+kv/l+uheRZzZmWJu/8TwBxfzmb0vl3dg2Ryt94NCT8kdZTWUPijQnaa8f/EDq\n92dIQX3l7sviIalhMWVP7Zda+9KA9rBzaz4xKSCdWlvWuujZlq969Ws5Xn61CIrJpd08Dh4WMM5r\nbia9db+a8R67TUV6xY92S5DQejUcOpOIEdFQm5d4QTlLAE9acfTE3+/c4XgFDhAQ1pgX1yliTUih\n22H+tQKvQUalfq8eIOZyYA5aA4FR5NKrS2xQyznzLUuw1V+qQN5ikmj8RBJZgWLsEgn4X5KLGXMK\nQBXARMcu+tLIEF5+cwZenvNO5vzryQZr7fALDeroFx8AjDEPW2t3dfSiv6a8HOcMvDznncy5M5KY\n+okksgIl+eInksgKlHPxxf/4ObjmrysvxzkDL895J3PugHTcx08kkUTOvSSmfiKJrEDp2BffGPM6\nY8wvjDH7jTHv69R1X6wYY9YbY+43xjxljHnCGPMHfH3AGPMtY8wz/N3/QufqtBhj0saYR40xX+X/\nY8aYvZzz54wxuRc6RyfFGNNnjLnLGPM01/uql8k6v5fPxuPGmM8YYwrLfa1Pl4588Y0Q2X8MwOsB\n7ARwmzFmZyeu/StIAOCPrLU7AOwG8O851/cBuM9auwXAffx/uckfAHjK+/8vAHyEc54G8M5zMquz\ny38DcI+1djuASyBzX9brbIxZC+A9AHZZay8EkAbwO1j+a71QrLX/4j8ArgJwr/f/+wG8vxPXfgnm\n/mUANwL4BYBRvjYK4Bfnem6nzXMd5ItyHYCvQoCkEwAyi30G5/oHQA+AA2CcyXt9ua/zWgBHAAxA\nIO9fBXDzcl7rxX46ZerrYqkc5WvLWowxGwFcCmAvgBFr7XEA4O9VZ3/nOZGPAvhPcPWigwAq1loF\nty+3Nd8E4BSAf6B78vfGmDKW+Tpba58D8CEAhwEcBzAD4BEs77U+Qzr1xV+s3GBZpxOMMV0AvgDg\nD621s+d6Ps8nxpg3ABi31j7iv7zI0OW05hkAlwH4W2vtpRAo97Iy6xcTxhzeBGAMwBoAZYgLe7os\np7U+Qzr1xT8KYL33/zoAxzp07Rctxpgs5Ev/j9baL/Llk8aYUR4fBTB+rua3iOwB8EZjzEEAn4WY\n+x8F0GeM0QrM5bbmRwEctdZqU7+7IBvBcl5nALgBwAFr7SkrJaRfBHA1lvdanyGd+uI/BGALI585\nSDDknzt07RclRkjaPwHgKWvtX3uH/hnAnfz7TojvvyzEWvt+a+06a+1GyNp+21p7O4D7AbyFw5bb\nnE8AOGKM0Rra6wE8iWW8zpTDAHYbY0p8VnTey3atF5UOBkVuAbAPwC8B/Mm5Dm48zzxfBTHTHgPw\nU/7cAvGZ7wPwDH8PnOu5nmX+1wD4Kv/eBODHAPYD+CcA+XM9v9Pm+goAD3Ot7wbQ/3JYZwD/FcDT\nAB4H8CkA+eW+1qf/JMi9RBJZgZIg9xJJZAVK8sVPJJEVKMkXP5FEVqAkX/xEElmBknzxE0lkBUry\nxU8kkRUoyRc/kURWoCRf/EQSWYHy/wDvLaxPc4YqQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2841088c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = unloader(iter(trainloader).next()[0][0])\n",
    "_ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150..  Training Loss: 217964.8813..  valid Loss: 181494.4062.. \n",
      "Epoch: 1/150..  Training Loss: 149520.9062..  valid Loss: 152079.2457.. \n",
      "Epoch: 1/150..  Training Loss: 127783.3823..  valid Loss: 133278.4396.. \n",
      "Epoch: 1/150..  Training Loss: 118445.7948..  valid Loss: 132465.2109.. \n",
      "Epoch: 1/150..  Training Loss: 106301.0911..  valid Loss: 122612.9815.. \n",
      "Epoch: 2/150..  Training Loss: 92870.6986..  valid Loss: 102514.9261.. \n",
      "Epoch: 2/150..  Training Loss: 93519.0344..  valid Loss: 93002.5845.. \n",
      "Epoch: 2/150..  Training Loss: 89578.0714..  valid Loss: 88943.0817.. \n",
      "Epoch: 2/150..  Training Loss: 85593.9083..  valid Loss: 84134.9062.. \n",
      "Epoch: 2/150..  Training Loss: 84172.1687..  valid Loss: 80617.1676.. \n",
      "Epoch: 2/150..  Training Loss: 78109.1703..  valid Loss: 77153.0277.. \n",
      "Epoch: 3/150..  Training Loss: 72755.7490..  valid Loss: 74627.6864.. \n",
      "Epoch: 3/150..  Training Loss: 72491.1031..  valid Loss: 72754.6374.. \n",
      "Epoch: 3/150..  Training Loss: 70649.5964..  valid Loss: 71039.6605.. \n",
      "Epoch: 3/150..  Training Loss: 71422.3646..  valid Loss: 69783.1346.. \n",
      "Epoch: 3/150..  Training Loss: 69675.7529..  valid Loss: 67769.0359.. \n",
      "Epoch: 3/150..  Training Loss: 68328.2276..  valid Loss: 66513.3906.. \n",
      "Epoch: 4/150..  Training Loss: 61371.7987..  valid Loss: 65330.0291.. \n",
      "Epoch: 4/150..  Training Loss: 64959.0383..  valid Loss: 63878.1332.. \n",
      "Epoch: 4/150..  Training Loss: 62394.6323..  valid Loss: 62758.3864.. \n",
      "Epoch: 4/150..  Training Loss: 62809.6906..  valid Loss: 61836.1825.. \n",
      "Epoch: 4/150..  Training Loss: 61192.2438..  valid Loss: 60884.0021.. \n",
      "Epoch: 4/150..  Training Loss: 59702.4909..  valid Loss: 60094.9755.. \n",
      "Epoch: 5/150..  Training Loss: 55695.2173..  valid Loss: 59470.9645.. \n",
      "Epoch: 5/150..  Training Loss: 56619.2951..  valid Loss: 59195.5384.. \n",
      "Epoch: 5/150..  Training Loss: 57613.1880..  valid Loss: 57999.2947.. \n",
      "Epoch: 5/150..  Training Loss: 57168.4734..  valid Loss: 57390.3942.. \n",
      "Epoch: 5/150..  Training Loss: 56822.0891..  valid Loss: 56799.3597.. \n",
      "Epoch: 5/150..  Training Loss: 56472.9477..  valid Loss: 56046.5653.. \n",
      "Epoch: 6/150..  Training Loss: 51641.5592..  valid Loss: 55631.9915.. \n",
      "Epoch: 6/150..  Training Loss: 53041.7320..  valid Loss: 54970.6293.. \n",
      "Epoch: 6/150..  Training Loss: 54604.8654..  valid Loss: 54669.3374.. \n",
      "Epoch: 6/150..  Training Loss: 52932.1932..  valid Loss: 54198.6573.. \n",
      "Epoch: 6/150..  Training Loss: 52743.0924..  valid Loss: 53879.3043.. \n",
      "Epoch: 6/150..  Training Loss: 51594.9742..  valid Loss: 53432.1740.. \n",
      "Epoch: 7/150..  Training Loss: 48586.1767..  valid Loss: 53314.9950.. \n",
      "Epoch: 7/150..  Training Loss: 49730.1737..  valid Loss: 52788.6726.. \n",
      "Epoch: 7/150..  Training Loss: 50542.7214..  valid Loss: 52538.4336.. \n",
      "Epoch: 7/150..  Training Loss: 50549.4195..  valid Loss: 52105.9439.. \n",
      "Epoch: 7/150..  Training Loss: 50429.4529..  valid Loss: 51871.7646.. \n",
      "Epoch: 7/150..  Training Loss: 49953.1250..  valid Loss: 51490.3754.. \n",
      "Epoch: 8/150..  Training Loss: 44271.2526..  valid Loss: 51222.3256.. \n",
      "Epoch: 8/150..  Training Loss: 48453.8716..  valid Loss: 50742.8874.. \n",
      "Epoch: 8/150..  Training Loss: 47656.9135..  valid Loss: 50378.2326.. \n",
      "Epoch: 8/150..  Training Loss: 46718.6188..  valid Loss: 49921.1673.. \n",
      "Epoch: 8/150..  Training Loss: 47298.3667..  valid Loss: 49868.0558.. \n",
      "Epoch: 9/150..  Training Loss: 45172.7538..  valid Loss: 49738.5004.. \n",
      "Epoch: 9/150..  Training Loss: 45056.2888..  valid Loss: 49415.2326.. \n",
      "Epoch: 9/150..  Training Loss: 46239.1883..  valid Loss: 49240.2862.. \n",
      "Epoch: 9/150..  Training Loss: 45275.2281..  valid Loss: 49201.1428.. \n",
      "Epoch: 9/150..  Training Loss: 44678.3911..  valid Loss: 48764.4528.. \n",
      "Epoch: 9/150..  Training Loss: 45259.2289..  valid Loss: 48631.7056.. \n",
      "Epoch: 10/150..  Training Loss: 42259.4207..  valid Loss: 48632.6829.. \n",
      "Epoch: 10/150..  Training Loss: 42860.4896..  valid Loss: 48292.9457.. \n",
      "Epoch: 10/150..  Training Loss: 43303.9484..  valid Loss: 48434.2209.. \n",
      "Epoch: 10/150..  Training Loss: 43318.1534..  valid Loss: 48268.3874.. \n",
      "Epoch: 10/150..  Training Loss: 44122.7070..  valid Loss: 48331.8239.. \n",
      "Epoch: 10/150..  Training Loss: 43745.2544..  valid Loss: 48655.9698.. \n",
      "Epoch: 11/150..  Training Loss: 40235.2248..  valid Loss: 48235.4719.. \n",
      "Epoch: 11/150..  Training Loss: 41209.0456..  valid Loss: 48017.0160.. \n",
      "Epoch: 11/150..  Training Loss: 41806.8070..  valid Loss: 47800.9016.. \n",
      "Epoch: 11/150..  Training Loss: 41493.4214..  valid Loss: 47623.1960.. \n",
      "Epoch: 11/150..  Training Loss: 42544.5534..  valid Loss: 47645.6388.. \n",
      "Epoch: 11/150..  Training Loss: 41907.7953..  valid Loss: 47456.8157.. \n",
      "Epoch: 12/150..  Training Loss: 38839.1297..  valid Loss: 47322.9585.. \n",
      "Epoch: 12/150..  Training Loss: 39994.1513..  valid Loss: 47467.3192.. \n",
      "Epoch: 12/150..  Training Loss: 40306.6398..  valid Loss: 47411.9123.. \n",
      "Epoch: 12/150..  Training Loss: 40024.4062..  valid Loss: 47325.3885.. \n",
      "Epoch: 12/150..  Training Loss: 40905.2430..  valid Loss: 47341.4105.. \n",
      "Epoch: 12/150..  Training Loss: 39928.8333..  valid Loss: 47014.5224.. \n",
      "Epoch: 13/150..  Training Loss: 37252.4657..  valid Loss: 47151.4688.. \n",
      "Epoch: 13/150..  Training Loss: 37317.5990..  valid Loss: 47068.2116.. \n",
      "Epoch: 13/150..  Training Loss: 38749.5073..  valid Loss: 47153.0092.. \n",
      "Epoch: 13/150..  Training Loss: 39619.7633..  valid Loss: 47403.2131.. \n",
      "Epoch: 13/150..  Training Loss: 38255.2273..  valid Loss: 47425.4038.. \n",
      "Epoch: 13/150..  Training Loss: 38895.9359..  valid Loss: 47252.1612.. \n",
      "Epoch: 14/150..  Training Loss: 34245.4142..  valid Loss: 46942.1009.. \n",
      "Epoch: 14/150..  Training Loss: 36885.0638..  valid Loss: 47476.3675.. \n",
      "Epoch: 14/150..  Training Loss: 36856.3914..  valid Loss: 47128.5281.. \n",
      "Epoch: 14/150..  Training Loss: 37365.3362..  valid Loss: 46920.1580.. \n",
      "Epoch: 14/150..  Training Loss: 37187.3423..  valid Loss: 47073.1914.. \n",
      "Epoch: 14/150..  Training Loss: 38599.0948..  valid Loss: 46949.2010.. \n",
      "Epoch: 15/150..  Training Loss: 33357.4650..  valid Loss: 46925.1112.. \n",
      "Epoch: 15/150..  Training Loss: 35639.0057..  valid Loss: 47196.6779.. \n",
      "Epoch: 15/150..  Training Loss: 36342.1615..  valid Loss: 47271.6744.. \n",
      "Epoch: 15/150..  Training Loss: 35834.7667..  valid Loss: 47263.2095.. \n",
      "Epoch: 15/150..  Training Loss: 35061.0138..  valid Loss: 47163.3217.. \n",
      "Epoch: 15/150..  Training Loss: 34913.9265..  valid Loss: 47919.0522.. \n",
      "Epoch: 16/150..  Training Loss: 33600.2240..  valid Loss: 47321.2028.. \n",
      "Epoch: 16/150..  Training Loss: 33739.0682..  valid Loss: 47346.4709.. \n",
      "Epoch: 16/150..  Training Loss: 34126.5049..  valid Loss: 47517.3175.. \n",
      "Epoch: 16/150..  Training Loss: 35094.6328..  valid Loss: 47416.7965.. \n",
      "Epoch: 16/150..  Training Loss: 35384.9025..  valid Loss: 47442.8718.. \n",
      "Epoch: 17/150..  Training Loss: 33129.4589..  valid Loss: 47339.7621.. \n",
      "Epoch: 17/150..  Training Loss: 32725.0844..  valid Loss: 47485.2937.. \n",
      "Epoch: 17/150..  Training Loss: 32203.2940..  valid Loss: 47798.3267.. \n",
      "Epoch: 17/150..  Training Loss: 33417.2118..  valid Loss: 47487.8991.. \n",
      "Epoch: 17/150..  Training Loss: 33918.5004..  valid Loss: 47774.3963.. \n",
      "Epoch: 17/150..  Training Loss: 34242.2376..  valid Loss: 47670.6456.. \n",
      "Epoch: 18/150..  Training Loss: 30837.2383..  valid Loss: 47590.6470.. \n",
      "Epoch: 18/150..  Training Loss: 31747.8026..  valid Loss: 48009.6690.. \n",
      "Epoch: 18/150..  Training Loss: 31774.5212..  valid Loss: 48136.4560.. \n",
      "Epoch: 18/150..  Training Loss: 32338.8203..  valid Loss: 48471.0447.. \n",
      "Epoch: 18/150..  Training Loss: 33308.9081..  valid Loss: 47678.2422.. \n",
      "Epoch: 18/150..  Training Loss: 31910.2069..  valid Loss: 47998.1360.. \n",
      "Epoch: 19/150..  Training Loss: 29881.5234..  valid Loss: 47946.5284.. \n",
      "Epoch: 19/150..  Training Loss: 30838.2938..  valid Loss: 48210.6214.. \n",
      "Epoch: 19/150..  Training Loss: 30991.9204..  valid Loss: 48173.7095.. \n",
      "Epoch: 19/150..  Training Loss: 30859.0197..  valid Loss: 48305.1612.. \n",
      "Epoch: 19/150..  Training Loss: 31280.2294..  valid Loss: 48308.5629.. \n",
      "Epoch: 19/150..  Training Loss: 31935.0635..  valid Loss: 48353.9918.. \n",
      "Epoch: 20/150..  Training Loss: 28648.2971..  valid Loss: 48624.7827.. \n",
      "Epoch: 20/150..  Training Loss: 30157.5012..  valid Loss: 48542.3874.. \n",
      "Epoch: 20/150..  Training Loss: 30148.4973..  valid Loss: 48542.7962.. \n",
      "Epoch: 20/150..  Training Loss: 31070.1599..  valid Loss: 48840.7607.. \n",
      "Epoch: 20/150..  Training Loss: 30177.7960..  valid Loss: 48444.8800.. \n",
      "Epoch: 20/150..  Training Loss: 29951.4620..  valid Loss: 48675.4652.. \n",
      "Epoch: 21/150..  Training Loss: 27018.3726..  valid Loss: 48353.5636.. \n",
      "Epoch: 21/150..  Training Loss: 29082.1993..  valid Loss: 49020.3285.. \n",
      "Epoch: 21/150..  Training Loss: 29614.0991..  valid Loss: 48836.3285.. \n",
      "Epoch: 21/150..  Training Loss: 29978.4790..  valid Loss: 49085.7575.. \n",
      "Epoch: 21/150..  Training Loss: 29543.1375..  valid Loss: 49576.0646.. \n",
      "Epoch: 21/150..  Training Loss: 29416.5745..  valid Loss: 49040.8189.. \n",
      "Epoch: 22/150..  Training Loss: 27458.6825..  valid Loss: 49196.1286.. \n",
      "Epoch: 22/150..  Training Loss: 28118.4182..  valid Loss: 49073.1648.. \n",
      "Epoch: 22/150..  Training Loss: 28121.9507..  valid Loss: 49088.6488.. \n",
      "Epoch: 22/150..  Training Loss: 28922.4901..  valid Loss: 49703.5153.. \n",
      "Epoch: 22/150..  Training Loss: 28968.3822..  valid Loss: 49202.0352.. \n",
      "Epoch: 22/150..  Training Loss: 29247.0120..  valid Loss: 49499.1673.. \n",
      "Epoch: 23/150..  Training Loss: 26067.3639..  valid Loss: 49266.0543.. \n",
      "Epoch: 23/150..  Training Loss: 27710.3510..  valid Loss: 49767.9592.. \n",
      "Epoch: 23/150..  Training Loss: 27543.2090..  valid Loss: 50006.9425.. \n",
      "Epoch: 23/150..  Training Loss: 27839.7115..  valid Loss: 49247.3072.. \n",
      "Epoch: 23/150..  Training Loss: 27728.4273..  valid Loss: 49227.1772.. \n",
      "Epoch: 24/150..  Training Loss: 26489.9435..  valid Loss: 49465.8881.. \n",
      "Epoch: 24/150..  Training Loss: 26689.4043..  valid Loss: 49276.5831.. \n",
      "Epoch: 24/150..  Training Loss: 26253.4991..  valid Loss: 49421.7560.. \n",
      "Epoch: 24/150..  Training Loss: 26803.5628..  valid Loss: 49524.5092.. \n",
      "Epoch: 24/150..  Training Loss: 27202.5116..  valid Loss: 49652.1843.. \n",
      "Epoch: 24/150..  Training Loss: 27767.7339..  valid Loss: 49533.0668.. \n",
      "Epoch: 25/150..  Training Loss: 25626.5580..  valid Loss: 49717.6548.. \n",
      "Epoch: 25/150..  Training Loss: 26514.9486..  valid Loss: 50045.1605.. \n",
      "Epoch: 25/150..  Training Loss: 25407.3581..  valid Loss: 50001.9226.. \n",
      "Epoch: 25/150..  Training Loss: 25501.5641..  valid Loss: 49634.2901.. \n",
      "Epoch: 25/150..  Training Loss: 26168.2566..  valid Loss: 50130.8274.. \n",
      "Epoch: 25/150..  Training Loss: 27150.1993..  valid Loss: 50841.2504.. \n",
      "Epoch: 26/150..  Training Loss: 24579.6879..  valid Loss: 50528.9833.. \n",
      "Epoch: 26/150..  Training Loss: 25335.4945..  valid Loss: 50279.5096.. \n",
      "Epoch: 26/150..  Training Loss: 24900.6999..  valid Loss: 50238.2003.. \n",
      "Epoch: 26/150..  Training Loss: 25721.9659..  valid Loss: 50381.4773.. \n",
      "Epoch: 26/150..  Training Loss: 25666.7872..  valid Loss: 50124.3491.. \n",
      "Epoch: 26/150..  Training Loss: 26499.4854..  valid Loss: 49984.5458.. \n",
      "Epoch: 27/150..  Training Loss: 24475.3163..  valid Loss: 50452.7262.. \n",
      "Epoch: 27/150..  Training Loss: 24654.4600..  valid Loss: 50159.6069.. \n",
      "Epoch: 27/150..  Training Loss: 24722.2451..  valid Loss: 50335.1594.. \n",
      "Epoch: 27/150..  Training Loss: 25315.8005..  valid Loss: 50469.2294.. \n",
      "Epoch: 27/150..  Training Loss: 25361.7935..  valid Loss: 50524.3523.. \n",
      "Epoch: 27/150..  Training Loss: 25351.3396..  valid Loss: 50642.5437.. \n",
      "Epoch: 28/150..  Training Loss: 23577.0116..  valid Loss: 51118.6349.. \n",
      "Epoch: 28/150..  Training Loss: 24172.6277..  valid Loss: 50909.0550.. \n",
      "Epoch: 28/150..  Training Loss: 24079.0971..  valid Loss: 51455.5597.. \n",
      "Epoch: 28/150..  Training Loss: 25120.3189..  valid Loss: 51159.1548.. \n",
      "Epoch: 28/150..  Training Loss: 25547.1271..  valid Loss: 50983.9297.. \n",
      "Epoch: 28/150..  Training Loss: 24663.9077..  valid Loss: 50860.9354.. \n",
      "Epoch: 29/150..  Training Loss: 21976.6229..  valid Loss: 50770.4560.. \n",
      "Epoch: 29/150..  Training Loss: 24027.7771..  valid Loss: 50793.6367.. \n",
      "Epoch: 29/150..  Training Loss: 24712.7267..  valid Loss: 51263.2663.. \n",
      "Epoch: 29/150..  Training Loss: 24066.3882..  valid Loss: 51202.8136.. \n",
      "Epoch: 29/150..  Training Loss: 24457.7520..  valid Loss: 50841.0898.. \n",
      "Epoch: 29/150..  Training Loss: 24456.3491..  valid Loss: 50964.0426.. \n",
      "Epoch: 30/150..  Training Loss: 22420.5045..  valid Loss: 50930.0266.. \n",
      "Epoch: 30/150..  Training Loss: 23668.8983..  valid Loss: 51099.9233.. \n",
      "Epoch: 30/150..  Training Loss: 23883.7507..  valid Loss: 51310.8469.. \n",
      "Epoch: 30/150..  Training Loss: 23255.3612..  valid Loss: 51373.0884.. \n",
      "Epoch: 30/150..  Training Loss: 24033.6602..  valid Loss: 51434.2024.. \n",
      "Epoch: 30/150..  Training Loss: 22421.0755..  valid Loss: 51843.6523.. \n",
      "Epoch: 31/150..  Training Loss: 23018.9329..  valid Loss: 52072.1893.. \n",
      "Epoch: 31/150..  Training Loss: 23267.1431..  valid Loss: 51809.3526.. \n",
      "Epoch: 31/150..  Training Loss: 23650.0789..  valid Loss: 51473.1985.. \n",
      "Epoch: 31/150..  Training Loss: 23400.1233..  valid Loss: 52308.4237.. \n",
      "Epoch: 31/150..  Training Loss: 23774.7531..  valid Loss: 52539.7837.. \n",
      "Epoch: 32/150..  Training Loss: 22403.8287..  valid Loss: 51545.9158.. \n",
      "Epoch: 32/150..  Training Loss: 22651.9497..  valid Loss: 51670.9769.. \n",
      "Epoch: 32/150..  Training Loss: 22510.5322..  valid Loss: 51729.1438.. \n",
      "Epoch: 32/150..  Training Loss: 22866.4741..  valid Loss: 52148.6577.. \n",
      "Epoch: 32/150..  Training Loss: 23023.0191..  valid Loss: 51908.8370.. \n",
      "Epoch: 32/150..  Training Loss: 22581.1193..  valid Loss: 51557.6481.. \n",
      "Epoch: 33/150..  Training Loss: 21767.8224..  valid Loss: 52117.1793.. \n",
      "Epoch: 33/150..  Training Loss: 22402.0273..  valid Loss: 51619.6381.. \n",
      "Epoch: 33/150..  Training Loss: 21786.8855..  valid Loss: 51616.6158.. \n",
      "Epoch: 33/150..  Training Loss: 21977.3107..  valid Loss: 52178.4208.. \n",
      "Epoch: 33/150..  Training Loss: 22912.1423..  valid Loss: 51740.8036.. \n",
      "Epoch: 33/150..  Training Loss: 22278.6240..  valid Loss: 52311.7756.. \n",
      "Epoch: 34/150..  Training Loss: 20720.2320..  valid Loss: 52139.0007.. \n",
      "Epoch: 34/150..  Training Loss: 21066.5820..  valid Loss: 52323.0884.. \n",
      "Epoch: 34/150..  Training Loss: 22004.7901..  valid Loss: 52477.2830.. \n",
      "Epoch: 34/150..  Training Loss: 22233.9107..  valid Loss: 52158.8295.. \n",
      "Epoch: 34/150..  Training Loss: 21711.9572..  valid Loss: 52896.0909.. \n",
      "Epoch: 34/150..  Training Loss: 22472.1971..  valid Loss: 52621.4460.. \n",
      "Epoch: 35/150..  Training Loss: 20846.1057..  valid Loss: 51965.6126.. \n",
      "Epoch: 35/150..  Training Loss: 20997.1849..  valid Loss: 52743.9535.. \n",
      "Epoch: 35/150..  Training Loss: 21402.9910..  valid Loss: 52537.2085.. \n",
      "Epoch: 35/150..  Training Loss: 21755.7918..  valid Loss: 52202.1040.. \n",
      "Epoch: 35/150..  Training Loss: 21566.5837..  valid Loss: 52357.1484.. \n",
      "Epoch: 35/150..  Training Loss: 22088.2389..  valid Loss: 53047.7415.. \n",
      "Epoch: 36/150..  Training Loss: 20195.7768..  valid Loss: 52286.9762.. \n",
      "Epoch: 36/150..  Training Loss: 21446.6257..  valid Loss: 53213.9989.. \n",
      "Epoch: 36/150..  Training Loss: 21577.2710..  valid Loss: 52811.5891.. \n",
      "Epoch: 36/150..  Training Loss: 20865.3280..  valid Loss: 53095.2898.. \n",
      "Epoch: 36/150..  Training Loss: 21416.6020..  valid Loss: 52897.2582.. \n",
      "Epoch: 36/150..  Training Loss: 21212.9917..  valid Loss: 52204.4766.. \n",
      "Epoch: 37/150..  Training Loss: 19826.1566..  valid Loss: 52380.8519.. \n",
      "Epoch: 37/150..  Training Loss: 20706.5944..  valid Loss: 52921.7241.. \n",
      "Epoch: 37/150..  Training Loss: 20788.6646..  valid Loss: 52883.4563.. \n",
      "Epoch: 37/150..  Training Loss: 21602.6937..  valid Loss: 53006.9503.. \n",
      "Epoch: 37/150..  Training Loss: 21220.9324..  valid Loss: 53812.4759.. \n",
      "Epoch: 37/150..  Training Loss: 20749.0462..  valid Loss: 52794.5835.. \n",
      "Epoch: 38/150..  Training Loss: 19218.5675..  valid Loss: 52408.9972.. \n",
      "Epoch: 38/150..  Training Loss: 20239.5975..  valid Loss: 52724.3033.. \n",
      "Epoch: 38/150..  Training Loss: 20841.9176..  valid Loss: 53199.1293.. \n",
      "Epoch: 38/150..  Training Loss: 20970.5823..  valid Loss: 52881.7312.. \n",
      "Epoch: 38/150..  Training Loss: 20447.7395..  valid Loss: 53062.5430.. \n",
      "Epoch: 39/150..  Training Loss: 19811.0490..  valid Loss: 53353.6701.. \n",
      "Epoch: 39/150..  Training Loss: 20334.6839..  valid Loss: 53059.7116.. \n",
      "Epoch: 39/150..  Training Loss: 20453.5181..  valid Loss: 53120.4357.. \n",
      "Epoch: 39/150..  Training Loss: 20471.1048..  valid Loss: 53374.6634.. \n",
      "Epoch: 39/150..  Training Loss: 20676.3277..  valid Loss: 54624.1495.. \n",
      "Epoch: 39/150..  Training Loss: 20729.0918..  valid Loss: 53681.3569.. \n",
      "Epoch: 40/150..  Training Loss: 19334.6386..  valid Loss: 52849.3313.. \n",
      "Epoch: 40/150..  Training Loss: 19943.2314..  valid Loss: 53033.0898.. \n",
      "Epoch: 40/150..  Training Loss: 20406.1789..  valid Loss: 53599.1800.. \n",
      "Epoch: 40/150..  Training Loss: 20392.4540..  valid Loss: 53248.5039.. \n",
      "Epoch: 40/150..  Training Loss: 19901.6849..  valid Loss: 53476.9343.. \n",
      "Epoch: 40/150..  Training Loss: 20150.4445..  valid Loss: 53745.5050.. \n",
      "Epoch: 41/150..  Training Loss: 19290.0516..  valid Loss: 52965.5586.. \n",
      "Epoch: 41/150..  Training Loss: 19952.4770..  valid Loss: 52870.1985.. \n",
      "Epoch: 41/150..  Training Loss: 20250.7882..  valid Loss: 53296.2891.. \n",
      "Epoch: 41/150..  Training Loss: 19693.2327..  valid Loss: 53515.0352.. \n",
      "Epoch: 41/150..  Training Loss: 19776.8552..  valid Loss: 54289.8288.. \n",
      "Epoch: 41/150..  Training Loss: 20586.9772..  valid Loss: 53256.9883.. \n",
      "Epoch: 42/150..  Training Loss: 18658.3306..  valid Loss: 54010.5994.. \n",
      "Epoch: 42/150..  Training Loss: 19409.9496..  valid Loss: 53121.1800.. \n",
      "Epoch: 42/150..  Training Loss: 19877.1249..  valid Loss: 53521.6275.. \n",
      "Epoch: 42/150..  Training Loss: 19279.8868..  valid Loss: 53761.4748.. \n",
      "Epoch: 42/150..  Training Loss: 19891.1905..  valid Loss: 54567.8200.. \n",
      "Epoch: 42/150..  Training Loss: 19958.8768..  valid Loss: 53855.5469.. \n",
      "Epoch: 43/150..  Training Loss: 17927.0174..  valid Loss: 54058.6438.. \n",
      "Epoch: 43/150..  Training Loss: 18908.4757..  valid Loss: 53131.2241.. \n",
      "Epoch: 43/150..  Training Loss: 19101.6434..  valid Loss: 53134.3214.. \n",
      "Epoch: 43/150..  Training Loss: 19256.8267..  valid Loss: 53658.3984.. \n",
      "Epoch: 43/150..  Training Loss: 19838.6013..  valid Loss: 54451.4503.. \n",
      "Epoch: 43/150..  Training Loss: 19462.0772..  valid Loss: 54191.2468.. \n",
      "Epoch: 44/150..  Training Loss: 18293.4145..  valid Loss: 53537.2564.. \n",
      "Epoch: 44/150..  Training Loss: 19065.1928..  valid Loss: 53348.6832.. \n",
      "Epoch: 44/150..  Training Loss: 18909.7938..  valid Loss: 54075.9801.. \n",
      "Epoch: 44/150..  Training Loss: 18824.9645..  valid Loss: 54166.4851.. \n",
      "Epoch: 44/150..  Training Loss: 19019.6482..  valid Loss: 54035.2333.. \n",
      "Epoch: 44/150..  Training Loss: 18986.6930..  valid Loss: 54322.0895.. \n",
      "Epoch: 45/150..  Training Loss: 17869.3934..  valid Loss: 53471.1214.. \n",
      "Epoch: 45/150..  Training Loss: 18640.6729..  valid Loss: 53689.3555.. \n",
      "Epoch: 45/150..  Training Loss: 18924.9691..  valid Loss: 53925.3416.. \n",
      "Epoch: 45/150..  Training Loss: 18853.9710..  valid Loss: 54862.9599.. \n",
      "Epoch: 45/150..  Training Loss: 18469.7686..  valid Loss: 53807.1243.. \n",
      "Epoch: 45/150..  Training Loss: 17456.6082..  valid Loss: 54233.2369.. \n",
      "Epoch: 46/150..  Training Loss: 17903.9525..  valid Loss: 54134.1712.. \n",
      "Epoch: 46/150..  Training Loss: 18392.3572..  valid Loss: 53819.3018.. \n",
      "Epoch: 46/150..  Training Loss: 19232.8238..  valid Loss: 54335.3107.. \n",
      "Epoch: 46/150..  Training Loss: 18354.7807..  valid Loss: 54163.7212.. \n",
      "Epoch: 46/150..  Training Loss: 18994.4441..  valid Loss: 54780.3214.. \n",
      "Epoch: 47/150..  Training Loss: 17811.9326..  valid Loss: 54220.2923.. \n",
      "Epoch: 47/150..  Training Loss: 18293.8013..  valid Loss: 53991.9751.. \n",
      "Epoch: 47/150..  Training Loss: 18449.3133..  valid Loss: 55464.0025.. \n",
      "Epoch: 47/150..  Training Loss: 18730.6850..  valid Loss: 54219.2521.. \n",
      "Epoch: 47/150..  Training Loss: 18305.3728..  valid Loss: 54369.9581.. \n",
      "Epoch: 47/150..  Training Loss: 18631.6736..  valid Loss: 54381.1406.. \n",
      "Epoch: 48/150..  Training Loss: 18194.4737..  valid Loss: 54727.4979.. \n",
      "Epoch: 48/150..  Training Loss: 18516.0965..  valid Loss: 54714.0980.. \n",
      "Epoch: 48/150..  Training Loss: 18691.3714..  valid Loss: 53909.3601.. \n",
      "Epoch: 48/150..  Training Loss: 18440.1232..  valid Loss: 54534.0241.. \n",
      "Epoch: 48/150..  Training Loss: 18863.9225..  valid Loss: 55392.1463.. \n",
      "Epoch: 48/150..  Training Loss: 18507.7232..  valid Loss: 55592.7145.. \n",
      "Epoch: 49/150..  Training Loss: 17228.0209..  valid Loss: 55310.2450.. \n",
      "Epoch: 49/150..  Training Loss: 17761.2166..  valid Loss: 54291.4535.. \n",
      "Epoch: 49/150..  Training Loss: 18397.7852..  valid Loss: 54252.4499.. \n",
      "Epoch: 49/150..  Training Loss: 18196.4791..  valid Loss: 54236.9400.. \n",
      "Epoch: 49/150..  Training Loss: 17941.8014..  valid Loss: 55007.4567.. \n",
      "Epoch: 49/150..  Training Loss: 18330.5242..  valid Loss: 55352.5444.. \n",
      "Epoch: 50/150..  Training Loss: 17195.5135..  valid Loss: 54960.7021.. \n",
      "Epoch: 50/150..  Training Loss: 17305.3053..  valid Loss: 54970.7106.. \n",
      "Epoch: 50/150..  Training Loss: 17692.8206..  valid Loss: 54722.3807.. \n",
      "Epoch: 50/150..  Training Loss: 18056.7790..  valid Loss: 55350.7891.. \n",
      "Epoch: 50/150..  Training Loss: 17721.8350..  valid Loss: 54505.0753.. \n",
      "Epoch: 50/150..  Training Loss: 17851.7576..  valid Loss: 54775.3839.. \n",
      "Epoch: 51/150..  Training Loss: 16470.9577..  valid Loss: 55205.7777.. \n",
      "Epoch: 51/150..  Training Loss: 17078.3461..  valid Loss: 55452.7475.. \n",
      "Epoch: 51/150..  Training Loss: 17472.5334..  valid Loss: 54306.6431.. \n",
      "Epoch: 51/150..  Training Loss: 17384.5748..  valid Loss: 54786.3565.. \n",
      "Epoch: 51/150..  Training Loss: 17419.9570..  valid Loss: 55086.6914.. \n",
      "Epoch: 51/150..  Training Loss: 17899.0520..  valid Loss: 54854.2521.. \n",
      "Epoch: 52/150..  Training Loss: 16188.7609..  valid Loss: 55531.6971.. \n",
      "Epoch: 52/150..  Training Loss: 17464.7773..  valid Loss: 55306.2543.. \n",
      "Epoch: 52/150..  Training Loss: 17036.3709..  valid Loss: 55101.1009.. \n",
      "Epoch: 52/150..  Training Loss: 17464.1281..  valid Loss: 56040.1967.. \n",
      "Epoch: 52/150..  Training Loss: 17366.3531..  valid Loss: 54791.0518.. \n",
      "Epoch: 52/150..  Training Loss: 17624.6542..  valid Loss: 55211.3587.. \n",
      "Epoch: 53/150..  Training Loss: 16564.5279..  valid Loss: 55047.8732.. \n",
      "Epoch: 53/150..  Training Loss: 17058.9093..  valid Loss: 55077.4528.. \n",
      "Epoch: 53/150..  Training Loss: 17247.5028..  valid Loss: 55143.1321.. \n",
      "Epoch: 53/150..  Training Loss: 17140.2829..  valid Loss: 55163.1868.. \n",
      "Epoch: 53/150..  Training Loss: 17389.2389..  valid Loss: 54600.2891.. \n",
      "Epoch: 54/150..  Training Loss: 16246.1396..  valid Loss: 55231.9506.. \n",
      "Epoch: 54/150..  Training Loss: 16661.4755..  valid Loss: 55436.0614.. \n",
      "Epoch: 54/150..  Training Loss: 17427.4132..  valid Loss: 54831.2575.. \n",
      "Epoch: 54/150..  Training Loss: 17066.5167..  valid Loss: 55720.8434.. \n",
      "Epoch: 54/150..  Training Loss: 17245.0180..  valid Loss: 55173.9574.. \n",
      "Epoch: 54/150..  Training Loss: 17074.1389..  valid Loss: 55014.7699.. \n",
      "Epoch: 55/150..  Training Loss: 16370.3419..  valid Loss: 55552.0011.. \n",
      "Epoch: 55/150..  Training Loss: 16728.9605..  valid Loss: 55366.9556.. \n",
      "Epoch: 55/150..  Training Loss: 16977.5353..  valid Loss: 55194.0124.. \n",
      "Epoch: 55/150..  Training Loss: 17013.2137..  valid Loss: 55367.3842.. \n",
      "Epoch: 55/150..  Training Loss: 17155.9068..  valid Loss: 56167.8175.. \n",
      "Epoch: 55/150..  Training Loss: 17260.4870..  valid Loss: 54806.9890.. \n",
      "Epoch: 56/150..  Training Loss: 16193.0297..  valid Loss: 55272.7525.. \n",
      "Epoch: 56/150..  Training Loss: 16168.0217..  valid Loss: 55676.0316.. \n",
      "Epoch: 56/150..  Training Loss: 16645.8745..  valid Loss: 55677.7578.. \n",
      "Epoch: 56/150..  Training Loss: 16798.7001..  valid Loss: 54943.9347.. \n",
      "Epoch: 56/150..  Training Loss: 16669.6467..  valid Loss: 55246.8714.. \n",
      "Epoch: 56/150..  Training Loss: 16716.0233..  valid Loss: 55716.3253.. \n",
      "Epoch: 57/150..  Training Loss: 16093.0404..  valid Loss: 55622.2624.. \n",
      "Epoch: 57/150..  Training Loss: 16235.2147..  valid Loss: 55999.0288.. \n",
      "Epoch: 57/150..  Training Loss: 16668.8130..  valid Loss: 55513.5994.. \n",
      "Epoch: 57/150..  Training Loss: 16399.6710..  valid Loss: 55114.2372.. \n",
      "Epoch: 57/150..  Training Loss: 16483.8320..  valid Loss: 56239.8413.. \n",
      "Epoch: 57/150..  Training Loss: 16722.6732..  valid Loss: 55697.2983.. \n",
      "Epoch: 58/150..  Training Loss: 15235.9841..  valid Loss: 55653.8249.. \n",
      "Epoch: 58/150..  Training Loss: 16515.8893..  valid Loss: 55828.4229.. \n",
      "Epoch: 58/150..  Training Loss: 16988.0812..  valid Loss: 56347.0980.. \n",
      "Epoch: 58/150..  Training Loss: 16428.1008..  valid Loss: 55091.6410.. \n",
      "Epoch: 58/150..  Training Loss: 16428.6657..  valid Loss: 55846.3136.. \n",
      "Epoch: 58/150..  Training Loss: 16453.4512..  valid Loss: 56031.0352.. \n",
      "Epoch: 59/150..  Training Loss: 15138.4358..  valid Loss: 55326.0320.. \n",
      "Epoch: 59/150..  Training Loss: 16336.0860..  valid Loss: 55540.8445.. \n",
      "Epoch: 59/150..  Training Loss: 16209.3064..  valid Loss: 55625.1509.. \n",
      "Epoch: 59/150..  Training Loss: 16319.1561..  valid Loss: 57079.8636.. \n",
      "Epoch: 59/150..  Training Loss: 16494.6942..  valid Loss: 56105.8846.. \n",
      "Epoch: 59/150..  Training Loss: 16368.5590..  valid Loss: 56417.1932.. \n",
      "Epoch: 60/150..  Training Loss: 15280.0191..  valid Loss: 55781.1527.. \n",
      "Epoch: 60/150..  Training Loss: 16181.1122..  valid Loss: 56150.2326.. \n",
      "Epoch: 60/150..  Training Loss: 16189.1572..  valid Loss: 55706.6083.. \n",
      "Epoch: 60/150..  Training Loss: 16292.8564..  valid Loss: 56320.6477.. \n",
      "Epoch: 60/150..  Training Loss: 16268.9576..  valid Loss: 55623.1779.. \n",
      "Epoch: 60/150..  Training Loss: 15735.1080..  valid Loss: 56082.0913.. \n",
      "Epoch: 61/150..  Training Loss: 16031.4648..  valid Loss: 55730.1179.. \n",
      "Epoch: 61/150..  Training Loss: 15841.2001..  valid Loss: 56382.0028.. \n",
      "Epoch: 61/150..  Training Loss: 15812.9587..  valid Loss: 56485.3263.. \n",
      "Epoch: 61/150..  Training Loss: 16156.8688..  valid Loss: 55983.6516.. \n",
      "Epoch: 61/150..  Training Loss: 16175.3587..  valid Loss: 57434.0344.. \n",
      "Epoch: 62/150..  Training Loss: 15431.7495..  valid Loss: 55581.9467.. \n",
      "Epoch: 62/150..  Training Loss: 16266.2705..  valid Loss: 57312.6225.. \n",
      "Epoch: 62/150..  Training Loss: 15923.1023..  valid Loss: 55541.3956.. \n",
      "Epoch: 62/150..  Training Loss: 15891.8075..  valid Loss: 55671.9936.. \n",
      "Epoch: 62/150..  Training Loss: 15798.3803..  valid Loss: 55902.2919.. \n",
      "Epoch: 62/150..  Training Loss: 15947.3704..  valid Loss: 56580.8452.. \n",
      "Epoch: 63/150..  Training Loss: 15436.8213..  valid Loss: 56706.4755.. \n",
      "Epoch: 63/150..  Training Loss: 15518.0986..  valid Loss: 56027.3406.. \n",
      "Epoch: 63/150..  Training Loss: 15535.9342..  valid Loss: 56416.1655.. \n",
      "Epoch: 63/150..  Training Loss: 16086.6154..  valid Loss: 56263.0778.. \n",
      "Epoch: 63/150..  Training Loss: 15733.4626..  valid Loss: 57049.8569.. \n",
      "Epoch: 63/150..  Training Loss: 16020.8099..  valid Loss: 55954.9638.. \n",
      "Epoch: 64/150..  Training Loss: 15204.1836..  valid Loss: 56698.6960.. \n",
      "Epoch: 64/150..  Training Loss: 15196.4820..  valid Loss: 55849.5039.. \n",
      "Epoch: 64/150..  Training Loss: 15643.2367..  valid Loss: 56615.1087.. \n",
      "Epoch: 64/150..  Training Loss: 15501.1562..  valid Loss: 57535.1623.. \n",
      "Epoch: 64/150..  Training Loss: 15010.9327..  valid Loss: 56241.5458.. \n",
      "Epoch: 64/150..  Training Loss: 15846.0273..  valid Loss: 56524.2440.. \n",
      "Epoch: 65/150..  Training Loss: 14629.3185..  valid Loss: 56455.6101.. \n",
      "Epoch: 65/150..  Training Loss: 15477.4883..  valid Loss: 56475.5053.. \n",
      "Epoch: 65/150..  Training Loss: 15419.9153..  valid Loss: 57265.9648.. \n",
      "Epoch: 65/150..  Training Loss: 15295.9559..  valid Loss: 55982.1875.. \n",
      "Epoch: 65/150..  Training Loss: 15215.9111..  valid Loss: 56976.2852.. \n",
      "Epoch: 65/150..  Training Loss: 15470.6099..  valid Loss: 56542.6005.. \n",
      "Epoch: 66/150..  Training Loss: 14340.3635..  valid Loss: 55902.0565.. \n",
      "Epoch: 66/150..  Training Loss: 14999.1029..  valid Loss: 56832.5163.. \n",
      "Epoch: 66/150..  Training Loss: 15125.0871..  valid Loss: 56256.5728.. \n",
      "Epoch: 66/150..  Training Loss: 15424.1894..  valid Loss: 56648.2397.. \n",
      "Epoch: 66/150..  Training Loss: 15204.8633..  valid Loss: 56401.5288.. \n",
      "Epoch: 66/150..  Training Loss: 15691.0225..  valid Loss: 56299.3114.. \n",
      "Epoch: 67/150..  Training Loss: 14185.8481..  valid Loss: 56293.4460.. \n",
      "Epoch: 67/150..  Training Loss: 15026.3193..  valid Loss: 57079.2589.. \n",
      "Epoch: 67/150..  Training Loss: 15071.2624..  valid Loss: 57254.1744.. \n",
      "Epoch: 67/150..  Training Loss: 14849.9555..  valid Loss: 56848.6648.. \n",
      "Epoch: 67/150..  Training Loss: 14961.5546..  valid Loss: 56989.2859.. \n",
      "Epoch: 67/150..  Training Loss: 15394.8320..  valid Loss: 56186.1392.. \n",
      "Epoch: 68/150..  Training Loss: 13901.8369..  valid Loss: 57315.5842.. \n",
      "Epoch: 68/150..  Training Loss: 14678.6493..  valid Loss: 56762.0678.. \n",
      "Epoch: 68/150..  Training Loss: 14995.6889..  valid Loss: 56644.8125.. \n",
      "Epoch: 68/150..  Training Loss: 15229.5417..  valid Loss: 56482.3342.. \n",
      "Epoch: 68/150..  Training Loss: 14842.9784..  valid Loss: 56910.3420.. \n",
      "Epoch: 69/150..  Training Loss: 13967.2364..  valid Loss: 56509.1928.. \n",
      "Epoch: 69/150..  Training Loss: 14489.7022..  valid Loss: 56532.6591.. \n",
      "Epoch: 69/150..  Training Loss: 14687.3952..  valid Loss: 57078.0185.. \n",
      "Epoch: 69/150..  Training Loss: 14766.9585..  valid Loss: 57947.3196.. \n",
      "Epoch: 69/150..  Training Loss: 15002.8240..  valid Loss: 56656.8995.. \n",
      "Epoch: 69/150..  Training Loss: 14988.9503..  valid Loss: 56902.7653.. \n",
      "Epoch: 70/150..  Training Loss: 13988.9918..  valid Loss: 56076.6946.. \n",
      "Epoch: 70/150..  Training Loss: 14648.1793..  valid Loss: 56822.3697.. \n",
      "Epoch: 70/150..  Training Loss: 14728.7516..  valid Loss: 56505.3725.. \n",
      "Epoch: 70/150..  Training Loss: 15268.6232..  valid Loss: 57316.7884.. \n",
      "Epoch: 70/150..  Training Loss: 14738.1301..  valid Loss: 57140.6161.. \n",
      "Epoch: 70/150..  Training Loss: 14895.1301..  valid Loss: 56840.4311.. \n",
      "Epoch: 71/150..  Training Loss: 14101.5420..  valid Loss: 56628.6783.. \n",
      "Epoch: 71/150..  Training Loss: 14455.2355..  valid Loss: 56964.5632.. \n",
      "Epoch: 71/150..  Training Loss: 14570.6199..  valid Loss: 56696.6950.. \n",
      "Epoch: 71/150..  Training Loss: 14662.4235..  valid Loss: 57486.0721.. \n",
      "Epoch: 71/150..  Training Loss: 14925.1497..  valid Loss: 57025.5884.. \n",
      "Epoch: 71/150..  Training Loss: 14706.6522..  valid Loss: 57063.6286.. \n",
      "Epoch: 72/150..  Training Loss: 13497.5699..  valid Loss: 56737.8928.. \n",
      "Epoch: 72/150..  Training Loss: 14501.9602..  valid Loss: 56877.5433.. \n",
      "Epoch: 72/150..  Training Loss: 14316.1938..  valid Loss: 57169.5359.. \n",
      "Epoch: 72/150..  Training Loss: 14694.8343..  valid Loss: 57596.3224.. \n",
      "Epoch: 72/150..  Training Loss: 14965.7769..  valid Loss: 56926.0955.. \n",
      "Epoch: 72/150..  Training Loss: 14824.8951..  valid Loss: 57163.4460.. \n",
      "Epoch: 73/150..  Training Loss: 13338.9988..  valid Loss: 56496.7251.. \n",
      "Epoch: 73/150..  Training Loss: 14374.0859..  valid Loss: 56743.4993.. \n",
      "Epoch: 73/150..  Training Loss: 14848.1549..  valid Loss: 56104.4560.. \n",
      "Epoch: 73/150..  Training Loss: 14814.0147..  valid Loss: 57544.9521.. \n",
      "Epoch: 73/150..  Training Loss: 14358.9542..  valid Loss: 57935.0763.. \n",
      "Epoch: 73/150..  Training Loss: 14677.6993..  valid Loss: 58385.6950.. \n",
      "Epoch: 74/150..  Training Loss: 13896.7830..  valid Loss: 57046.3516.. \n",
      "Epoch: 74/150..  Training Loss: 14036.0811..  valid Loss: 56593.7216.. \n",
      "Epoch: 74/150..  Training Loss: 14011.9087..  valid Loss: 56600.7116.. \n",
      "Epoch: 74/150..  Training Loss: 14415.8490..  valid Loss: 58015.3949.. \n",
      "Epoch: 74/150..  Training Loss: 14642.2325..  valid Loss: 57204.9105.. \n",
      "Epoch: 74/150..  Training Loss: 14685.8755..  valid Loss: 57776.4336.. \n",
      "Epoch: 75/150..  Training Loss: 13641.1278..  valid Loss: 58462.1531.. \n",
      "Epoch: 75/150..  Training Loss: 14296.0644..  valid Loss: 57891.7830.. \n",
      "Epoch: 75/150..  Training Loss: 14284.8932..  valid Loss: 57026.8732.. \n",
      "Epoch: 75/150..  Training Loss: 13798.6564..  valid Loss: 58652.5930.. \n",
      "Epoch: 75/150..  Training Loss: 14370.2983..  valid Loss: 57090.6239.. \n",
      "Epoch: 75/150..  Training Loss: 13549.8018..  valid Loss: 57583.5092.. \n",
      "Epoch: 76/150..  Training Loss: 13977.6215..  valid Loss: 57996.9368.. \n",
      "Epoch: 76/150..  Training Loss: 13610.6473..  valid Loss: 57194.0352.. \n",
      "Epoch: 76/150..  Training Loss: 14318.2604..  valid Loss: 58164.6502.. \n",
      "Epoch: 76/150..  Training Loss: 14275.7660..  valid Loss: 57782.3626.. \n",
      "Epoch: 76/150..  Training Loss: 14037.5406..  valid Loss: 57005.1765.. \n",
      "Epoch: 77/150..  Training Loss: 13525.4808..  valid Loss: 58633.0167.. \n",
      "Epoch: 77/150..  Training Loss: 13858.5826..  valid Loss: 58164.9158.. \n",
      "Epoch: 77/150..  Training Loss: 14139.6059..  valid Loss: 56651.6246.. \n",
      "Epoch: 77/150..  Training Loss: 13900.4703..  valid Loss: 57755.1435.. \n",
      "Epoch: 77/150..  Training Loss: 13999.2178..  valid Loss: 57008.7759.. \n",
      "Epoch: 77/150..  Training Loss: 13886.0068..  valid Loss: 57599.4141.. \n",
      "Epoch: 78/150..  Training Loss: 13094.6772..  valid Loss: 57889.2830.. \n",
      "Epoch: 78/150..  Training Loss: 14023.7070..  valid Loss: 57270.1175.. \n",
      "Epoch: 78/150..  Training Loss: 13846.1587..  valid Loss: 57520.6044.. \n",
      "Epoch: 78/150..  Training Loss: 13975.8925..  valid Loss: 58061.8931.. \n",
      "Epoch: 78/150..  Training Loss: 14014.8410..  valid Loss: 58106.4535.. \n",
      "Epoch: 78/150..  Training Loss: 14390.3782..  valid Loss: 57268.7354.. \n",
      "Epoch: 79/150..  Training Loss: 13140.6407..  valid Loss: 58551.3590.. \n",
      "Epoch: 79/150..  Training Loss: 13858.7809..  valid Loss: 56644.2841.. \n",
      "Epoch: 79/150..  Training Loss: 13489.8506..  valid Loss: 57692.8260.. \n",
      "Epoch: 79/150..  Training Loss: 13966.7868..  valid Loss: 56043.3207.. \n",
      "Epoch: 79/150..  Training Loss: 14061.8559..  valid Loss: 58170.4886.. \n",
      "Epoch: 79/150..  Training Loss: 13923.2557..  valid Loss: 57480.0568.. \n",
      "Epoch: 80/150..  Training Loss: 13299.0010..  valid Loss: 57038.8271.. \n",
      "Epoch: 80/150..  Training Loss: 13648.3792..  valid Loss: 58465.9038.. \n",
      "Epoch: 80/150..  Training Loss: 13250.4395..  valid Loss: 57110.3651.. \n",
      "Epoch: 80/150..  Training Loss: 13642.6861..  valid Loss: 58234.2354.. \n",
      "Epoch: 80/150..  Training Loss: 13878.0659..  valid Loss: 57915.8874.. \n",
      "Epoch: 80/150..  Training Loss: 14188.9242..  valid Loss: 58357.1982.. \n",
      "Epoch: 81/150..  Training Loss: 12649.3993..  valid Loss: 57956.6371.. \n",
      "Epoch: 81/150..  Training Loss: 13817.3435..  valid Loss: 56885.2333.. \n",
      "Epoch: 81/150..  Training Loss: 13637.0342..  valid Loss: 57396.8310.. \n",
      "Epoch: 81/150..  Training Loss: 13715.4771..  valid Loss: 58524.5533.. \n",
      "Epoch: 81/150..  Training Loss: 13656.1212..  valid Loss: 57710.4489.. \n",
      "Epoch: 81/150..  Training Loss: 13754.2157..  valid Loss: 58334.7972.. \n",
      "Epoch: 82/150..  Training Loss: 13023.4633..  valid Loss: 57578.5518.. \n",
      "Epoch: 82/150..  Training Loss: 14098.5705..  valid Loss: 57975.2177.. \n",
      "Epoch: 82/150..  Training Loss: 13538.2070..  valid Loss: 58830.2656.. \n",
      "Epoch: 82/150..  Training Loss: 13773.6923..  valid Loss: 57775.5060.. \n",
      "Epoch: 82/150..  Training Loss: 13362.4850..  valid Loss: 56821.5678.. \n",
      "Epoch: 82/150..  Training Loss: 13542.5830..  valid Loss: 57159.3970.. \n",
      "Epoch: 83/150..  Training Loss: 12680.9558..  valid Loss: 57690.6467.. \n",
      "Epoch: 83/150..  Training Loss: 13689.0184..  valid Loss: 58644.1328.. \n",
      "Epoch: 83/150..  Training Loss: 13408.8443..  valid Loss: 58314.1243.. \n",
      "Epoch: 83/150..  Training Loss: 13478.0030..  valid Loss: 58197.0121.. \n",
      "Epoch: 83/150..  Training Loss: 13562.9143..  valid Loss: 57968.8654.. \n",
      "Epoch: 84/150..  Training Loss: 12740.7024..  valid Loss: 59939.4592.. \n",
      "Epoch: 84/150..  Training Loss: 13422.2654..  valid Loss: 58428.4961.. \n",
      "Epoch: 84/150..  Training Loss: 12907.5686..  valid Loss: 57938.1094.. \n",
      "Epoch: 84/150..  Training Loss: 13027.0232..  valid Loss: 58483.6087.. \n",
      "Epoch: 84/150..  Training Loss: 13331.3432..  valid Loss: 57183.3597.. \n",
      "Epoch: 84/150..  Training Loss: 13689.5031..  valid Loss: 57727.6193.. \n",
      "Epoch: 85/150..  Training Loss: 12843.9758..  valid Loss: 57831.6729.. \n",
      "Epoch: 85/150..  Training Loss: 13284.9726..  valid Loss: 57931.9982.. \n",
      "Epoch: 85/150..  Training Loss: 13535.6822..  valid Loss: 57615.5241.. \n",
      "Epoch: 85/150..  Training Loss: 13426.2430..  valid Loss: 58094.4290.. \n",
      "Epoch: 85/150..  Training Loss: 13294.0036..  valid Loss: 58939.8374.. \n",
      "Epoch: 85/150..  Training Loss: 13122.2827..  valid Loss: 57729.6246.. \n",
      "Epoch: 86/150..  Training Loss: 12639.5210..  valid Loss: 60835.3345.. \n",
      "Epoch: 86/150..  Training Loss: 13518.2367..  valid Loss: 58424.6523.. \n",
      "Epoch: 86/150..  Training Loss: 13227.9056..  valid Loss: 57866.4237.. \n",
      "Epoch: 86/150..  Training Loss: 13230.4322..  valid Loss: 57818.4808.. \n",
      "Epoch: 86/150..  Training Loss: 13442.5264..  valid Loss: 58281.4308.. \n",
      "Epoch: 86/150..  Training Loss: 13129.5515..  valid Loss: 58329.2628.. \n",
      "Epoch: 87/150..  Training Loss: 11932.1402..  valid Loss: 58723.4656.. \n",
      "Epoch: 87/150..  Training Loss: 13267.4517..  valid Loss: 58048.2940.. \n",
      "Epoch: 87/150..  Training Loss: 12980.5148..  valid Loss: 58610.3587.. \n",
      "Epoch: 87/150..  Training Loss: 13013.2409..  valid Loss: 58598.1289.. \n",
      "Epoch: 87/150..  Training Loss: 13229.1364..  valid Loss: 57629.6925.. \n",
      "Epoch: 87/150..  Training Loss: 13316.6971..  valid Loss: 59681.0341.. \n",
      "Epoch: 88/150..  Training Loss: 12431.1637..  valid Loss: 58047.9279.. \n",
      "Epoch: 88/150..  Training Loss: 12819.6468..  valid Loss: 58595.0643.. \n",
      "Epoch: 88/150..  Training Loss: 12830.7599..  valid Loss: 58230.1580.. \n",
      "Epoch: 88/150..  Training Loss: 13037.2445..  valid Loss: 58141.3203.. \n",
      "Epoch: 88/150..  Training Loss: 12906.8898..  valid Loss: 58785.7237.. \n",
      "Epoch: 88/150..  Training Loss: 13051.5016..  valid Loss: 59086.5952.. \n",
      "Epoch: 89/150..  Training Loss: 12669.3139..  valid Loss: 57824.3526.. \n",
      "Epoch: 89/150..  Training Loss: 13061.6767..  valid Loss: 58606.1175.. \n",
      "Epoch: 89/150..  Training Loss: 13082.3188..  valid Loss: 57724.5075.. \n",
      "Epoch: 89/150..  Training Loss: 13101.4787..  valid Loss: 59226.6815.. \n",
      "Epoch: 89/150..  Training Loss: 12813.2755..  valid Loss: 58661.1697.. \n",
      "Epoch: 89/150..  Training Loss: 12675.5622..  valid Loss: 58812.0266.. \n",
      "Epoch: 90/150..  Training Loss: 11742.8562..  valid Loss: 57980.4688.. \n",
      "Epoch: 90/150..  Training Loss: 12717.8503..  valid Loss: 57976.2567.. \n",
      "Epoch: 90/150..  Training Loss: 12976.2980..  valid Loss: 59116.6104.. \n",
      "Epoch: 90/150..  Training Loss: 12768.1152..  valid Loss: 59038.5494.. \n",
      "Epoch: 90/150..  Training Loss: 12864.4787..  valid Loss: 58965.1321.. \n",
      "Epoch: 90/150..  Training Loss: 12166.9241..  valid Loss: 60514.4169.. \n",
      "Epoch: 91/150..  Training Loss: 12950.8913..  valid Loss: 57083.6119.. \n",
      "Epoch: 91/150..  Training Loss: 12814.7608..  valid Loss: 58702.7635.. \n",
      "Epoch: 91/150..  Training Loss: 12917.5423..  valid Loss: 59699.9066.. \n",
      "Epoch: 91/150..  Training Loss: 12792.6201..  valid Loss: 58535.0771.. \n",
      "Epoch: 91/150..  Training Loss: 13015.4300..  valid Loss: 58094.9776.. \n",
      "Epoch: 92/150..  Training Loss: 12201.2914..  valid Loss: 58044.6793.. \n",
      "Epoch: 92/150..  Training Loss: 12499.9621..  valid Loss: 58470.5028.. \n",
      "Epoch: 92/150..  Training Loss: 12938.6796..  valid Loss: 59884.9435.. \n",
      "Epoch: 92/150..  Training Loss: 13175.5347..  valid Loss: 59192.2379.. \n",
      "Epoch: 92/150..  Training Loss: 12852.3293..  valid Loss: 58790.7536.. \n",
      "Epoch: 92/150..  Training Loss: 13199.3604..  valid Loss: 58689.7447.. \n",
      "Epoch: 93/150..  Training Loss: 11921.3169..  valid Loss: 59412.6090.. \n",
      "Epoch: 93/150..  Training Loss: 12761.8818..  valid Loss: 59087.6708.. \n",
      "Epoch: 93/150..  Training Loss: 12714.0993..  valid Loss: 58098.0146.. \n",
      "Epoch: 93/150..  Training Loss: 12685.4840..  valid Loss: 58714.8835.. \n",
      "Epoch: 93/150..  Training Loss: 13020.0251..  valid Loss: 58426.4826.. \n",
      "Epoch: 93/150..  Training Loss: 12463.8403..  valid Loss: 59283.3491.. \n",
      "Epoch: 94/150..  Training Loss: 12098.0181..  valid Loss: 57813.9908.. \n",
      "Epoch: 94/150..  Training Loss: 12508.7410..  valid Loss: 58675.3576.. \n",
      "Epoch: 94/150..  Training Loss: 12305.8486..  valid Loss: 58329.9901.. \n",
      "Epoch: 94/150..  Training Loss: 12481.7100..  valid Loss: 59852.6289.. \n",
      "Epoch: 94/150..  Training Loss: 12795.0697..  valid Loss: 57828.7475.. \n",
      "Epoch: 94/150..  Training Loss: 12250.0436..  valid Loss: 58586.2979.. \n",
      "Epoch: 95/150..  Training Loss: 11615.0407..  valid Loss: 59176.0859.. \n",
      "Epoch: 95/150..  Training Loss: 12410.0892..  valid Loss: 59534.3881.. \n",
      "Epoch: 95/150..  Training Loss: 12224.0200..  valid Loss: 59200.1918.. \n",
      "Epoch: 95/150..  Training Loss: 12474.3791..  valid Loss: 58657.2578.. \n",
      "Epoch: 95/150..  Training Loss: 12283.3760..  valid Loss: 58633.0352.. \n",
      "Epoch: 95/150..  Training Loss: 12474.7323..  valid Loss: 58932.9300.. \n",
      "Epoch: 96/150..  Training Loss: 11829.3380..  valid Loss: 58467.6932.. \n",
      "Epoch: 96/150..  Training Loss: 12458.5338..  valid Loss: 59329.4620.. \n",
      "Epoch: 96/150..  Training Loss: 12292.8539..  valid Loss: 59246.3519.. \n",
      "Epoch: 96/150..  Training Loss: 12253.9161..  valid Loss: 59425.4925.. \n",
      "Epoch: 96/150..  Training Loss: 12202.5537..  valid Loss: 58502.4201.. \n",
      "Epoch: 96/150..  Training Loss: 12286.9273..  valid Loss: 59421.2212.. \n",
      "Epoch: 97/150..  Training Loss: 11418.3956..  valid Loss: 59060.9560.. \n",
      "Epoch: 97/150..  Training Loss: 11926.2905..  valid Loss: 58051.8345.. \n",
      "Epoch: 97/150..  Training Loss: 12195.2174..  valid Loss: 58440.3679.. \n",
      "Epoch: 97/150..  Training Loss: 12371.0079..  valid Loss: 59127.6403.. \n",
      "Epoch: 97/150..  Training Loss: 12581.1633..  valid Loss: 59634.5366.. \n",
      "Epoch: 97/150..  Training Loss: 12318.9999..  valid Loss: 59709.4975.. \n",
      "Epoch: 98/150..  Training Loss: 11657.8953..  valid Loss: 59412.7401.. \n",
      "Epoch: 98/150..  Training Loss: 12212.6987..  valid Loss: 58147.6431.. \n",
      "Epoch: 98/150..  Training Loss: 12475.6774..  valid Loss: 59241.3217.. \n",
      "Epoch: 98/150..  Training Loss: 12212.8662..  valid Loss: 59122.8111.. \n",
      "Epoch: 98/150..  Training Loss: 12382.9546..  valid Loss: 58648.3125.. \n",
      "Epoch: 99/150..  Training Loss: 11397.4441..  valid Loss: 59274.7227.. \n",
      "Epoch: 99/150..  Training Loss: 12298.8829..  valid Loss: 58454.0909.. \n",
      "Epoch: 99/150..  Training Loss: 12083.7537..  valid Loss: 58750.8295.. \n",
      "Epoch: 99/150..  Training Loss: 12479.4180..  valid Loss: 59100.4911.. \n",
      "Epoch: 99/150..  Training Loss: 12254.0852..  valid Loss: 59909.5778.. \n",
      "Epoch: 99/150..  Training Loss: 12127.5646..  valid Loss: 58527.5629.. \n",
      "Epoch: 100/150..  Training Loss: 11297.5345..  valid Loss: 59219.4854.. \n",
      "Epoch: 100/150..  Training Loss: 12173.9057..  valid Loss: 58873.5121.. \n",
      "Epoch: 100/150..  Training Loss: 12207.7803..  valid Loss: 58528.0799.. \n",
      "Epoch: 100/150..  Training Loss: 12193.9313..  valid Loss: 59979.3260.. \n",
      "Epoch: 100/150..  Training Loss: 12451.4495..  valid Loss: 59790.7322.. \n",
      "Epoch: 100/150..  Training Loss: 12174.2626..  valid Loss: 58566.5071.. \n",
      "Epoch: 101/150..  Training Loss: 11428.9427..  valid Loss: 60188.1665.. \n",
      "Epoch: 101/150..  Training Loss: 12145.9590..  valid Loss: 59413.4339.. \n",
      "Epoch: 101/150..  Training Loss: 12051.0785..  valid Loss: 59106.7823.. \n",
      "Epoch: 101/150..  Training Loss: 11696.9383..  valid Loss: 58869.0614.. \n",
      "Epoch: 101/150..  Training Loss: 11993.6321..  valid Loss: 59165.5643.. \n",
      "Epoch: 101/150..  Training Loss: 11989.5838..  valid Loss: 59353.7912.. \n",
      "Epoch: 102/150..  Training Loss: 11540.1310..  valid Loss: 58864.9954.. \n",
      "Epoch: 102/150..  Training Loss: 11704.8296..  valid Loss: 59041.4450.. \n",
      "Epoch: 102/150..  Training Loss: 11878.8303..  valid Loss: 59092.0465.. \n",
      "Epoch: 102/150..  Training Loss: 11781.5873..  valid Loss: 59243.4151.. \n",
      "Epoch: 102/150..  Training Loss: 12042.4999..  valid Loss: 59427.4897.. \n",
      "Epoch: 102/150..  Training Loss: 12117.6121..  valid Loss: 58717.5394.. \n",
      "Epoch: 103/150..  Training Loss: 11119.0265..  valid Loss: 59301.0934.. \n",
      "Epoch: 103/150..  Training Loss: 11816.5242..  valid Loss: 59336.6161.. \n",
      "Epoch: 103/150..  Training Loss: 11720.1751..  valid Loss: 59878.0742.. \n",
      "Epoch: 103/150..  Training Loss: 11964.4118..  valid Loss: 59049.6009.. \n",
      "Epoch: 103/150..  Training Loss: 11852.4643..  valid Loss: 59071.5273.. \n",
      "Epoch: 103/150..  Training Loss: 12151.1592..  valid Loss: 59861.2283.. \n",
      "Epoch: 104/150..  Training Loss: 11299.1274..  valid Loss: 62115.9048.. \n",
      "Epoch: 104/150..  Training Loss: 11836.4928..  valid Loss: 59388.1005.. \n",
      "Epoch: 104/150..  Training Loss: 11799.8707..  valid Loss: 58539.7113.. \n",
      "Epoch: 104/150..  Training Loss: 11842.2469..  valid Loss: 59394.4403.. \n",
      "Epoch: 104/150..  Training Loss: 11972.7057..  valid Loss: 59677.1165.. \n",
      "Epoch: 104/150..  Training Loss: 11894.5859..  valid Loss: 60316.7433.. \n",
      "Epoch: 105/150..  Training Loss: 11122.5414..  valid Loss: 59760.4066.. \n",
      "Epoch: 105/150..  Training Loss: 11742.6816..  valid Loss: 60379.3825.. \n",
      "Epoch: 105/150..  Training Loss: 11782.7191..  valid Loss: 59229.7784.. \n",
      "Epoch: 105/150..  Training Loss: 11507.2798..  valid Loss: 60326.7440.. \n",
      "Epoch: 105/150..  Training Loss: 11575.7335..  valid Loss: 59084.7841.. \n",
      "Epoch: 105/150..  Training Loss: 11250.0817..  valid Loss: 59079.6669.. \n",
      "Epoch: 106/150..  Training Loss: 11497.6759..  valid Loss: 59584.9151.. \n",
      "Epoch: 106/150..  Training Loss: 11798.9047..  valid Loss: 59269.9070.. \n",
      "Epoch: 106/150..  Training Loss: 11761.5915..  valid Loss: 59519.3658.. \n",
      "Epoch: 106/150..  Training Loss: 11660.1294..  valid Loss: 59448.9801.. \n",
      "Epoch: 106/150..  Training Loss: 11617.6456..  valid Loss: 59820.4744.. \n",
      "Epoch: 107/150..  Training Loss: 10719.0094..  valid Loss: 60019.1602.. \n",
      "Epoch: 107/150..  Training Loss: 11202.7294..  valid Loss: 58364.1619.. \n",
      "Epoch: 107/150..  Training Loss: 11170.0637..  valid Loss: 59920.2287.. \n",
      "Epoch: 107/150..  Training Loss: 11391.0091..  valid Loss: 59125.9034.. \n",
      "Epoch: 107/150..  Training Loss: 11926.7054..  valid Loss: 60654.2599.. \n",
      "Epoch: 107/150..  Training Loss: 11783.1251..  valid Loss: 58721.1090.. \n",
      "Epoch: 108/150..  Training Loss: 10813.4435..  valid Loss: 59822.3530.. \n",
      "Epoch: 108/150..  Training Loss: 11264.7127..  valid Loss: 60148.9478.. \n",
      "Epoch: 108/150..  Training Loss: 11533.8545..  valid Loss: 59900.5774.. \n",
      "Epoch: 108/150..  Training Loss: 11403.8863..  valid Loss: 59924.0146.. \n",
      "Epoch: 108/150..  Training Loss: 11550.5452..  valid Loss: 59247.9989.. \n",
      "Epoch: 108/150..  Training Loss: 11135.0129..  valid Loss: 60095.3395.. \n",
      "Epoch: 109/150..  Training Loss: 10668.7863..  valid Loss: 60133.0611.. \n",
      "Epoch: 109/150..  Training Loss: 11095.5178..  valid Loss: 58763.1854.. \n",
      "Epoch: 109/150..  Training Loss: 11306.3643..  valid Loss: 60428.4567.. \n",
      "Epoch: 109/150..  Training Loss: 11414.7258..  valid Loss: 59142.2383.. \n",
      "Epoch: 109/150..  Training Loss: 11385.0906..  valid Loss: 59699.9517.. \n",
      "Epoch: 109/150..  Training Loss: 11211.9408..  valid Loss: 60188.7507.. \n",
      "Epoch: 110/150..  Training Loss: 10885.2236..  valid Loss: 60274.0153.. \n",
      "Epoch: 110/150..  Training Loss: 11180.4914..  valid Loss: 59765.9688.. \n",
      "Epoch: 110/150..  Training Loss: 11276.0852..  valid Loss: 59585.4265.. \n",
      "Epoch: 110/150..  Training Loss: 11581.7410..  valid Loss: 59444.5401.. \n",
      "Epoch: 110/150..  Training Loss: 11491.4210..  valid Loss: 59389.8569.. \n",
      "Epoch: 110/150..  Training Loss: 11319.0021..  valid Loss: 59070.8516.. \n",
      "Epoch: 111/150..  Training Loss: 10601.7911..  valid Loss: 60351.1509.. \n",
      "Epoch: 111/150..  Training Loss: 11371.1445..  valid Loss: 59637.3129.. \n",
      "Epoch: 111/150..  Training Loss: 11248.7494..  valid Loss: 59791.4670.. \n",
      "Epoch: 111/150..  Training Loss: 11253.6506..  valid Loss: 59483.9982.. \n",
      "Epoch: 111/150..  Training Loss: 11471.6451..  valid Loss: 59980.7628.. \n",
      "Epoch: 111/150..  Training Loss: 11603.9646..  valid Loss: 59982.5661.. \n",
      "Epoch: 112/150..  Training Loss: 10556.4576..  valid Loss: 59320.3018.. \n",
      "Epoch: 112/150..  Training Loss: 11164.8292..  valid Loss: 61688.9744.. \n",
      "Epoch: 112/150..  Training Loss: 11320.9362..  valid Loss: 59929.5415.. \n",
      "Epoch: 112/150..  Training Loss: 11303.9658..  valid Loss: 60040.9286.. \n",
      "Epoch: 112/150..  Training Loss: 11296.8768..  valid Loss: 59844.5817.. \n",
      "Epoch: 112/150..  Training Loss: 11376.8010..  valid Loss: 59854.9112.. \n",
      "Epoch: 113/150..  Training Loss: 10439.2915..  valid Loss: 59486.6357.. \n",
      "Epoch: 113/150..  Training Loss: 11124.8044..  valid Loss: 59788.5082.. \n",
      "Epoch: 113/150..  Training Loss: 11425.7362..  valid Loss: 59385.6918.. \n",
      "Epoch: 113/150..  Training Loss: 11136.7256..  valid Loss: 59964.5895.. \n",
      "Epoch: 113/150..  Training Loss: 11337.8173..  valid Loss: 59659.4279.. \n",
      "Epoch: 114/150..  Training Loss: 10794.9117..  valid Loss: 60387.6502.. \n",
      "Epoch: 114/150..  Training Loss: 11280.1404..  valid Loss: 59240.8945.. \n",
      "Epoch: 114/150..  Training Loss: 11065.6872..  valid Loss: 59896.7365.. \n",
      "Epoch: 114/150..  Training Loss: 11187.5813..  valid Loss: 60090.2923.. \n",
      "Epoch: 114/150..  Training Loss: 11150.6193..  valid Loss: 59258.2006.. \n",
      "Epoch: 114/150..  Training Loss: 11248.6401..  valid Loss: 60104.6815.. \n",
      "Epoch: 115/150..  Training Loss: 10675.1469..  valid Loss: 60231.3544.. \n",
      "Epoch: 115/150..  Training Loss: 11052.7211..  valid Loss: 59719.4354.. \n",
      "Epoch: 115/150..  Training Loss: 11043.1916..  valid Loss: 59738.9901.. \n",
      "Epoch: 115/150..  Training Loss: 11231.9652..  valid Loss: 59926.1506.. \n",
      "Epoch: 115/150..  Training Loss: 11273.2307..  valid Loss: 59440.3001.. \n",
      "Epoch: 115/150..  Training Loss: 11219.6571..  valid Loss: 60300.1218.. \n",
      "Epoch: 116/150..  Training Loss: 10374.4744..  valid Loss: 60870.5511.. \n",
      "Epoch: 116/150..  Training Loss: 11220.5767..  valid Loss: 58565.8537.. \n",
      "Epoch: 116/150..  Training Loss: 11087.9485..  valid Loss: 60627.0092.. \n",
      "Epoch: 116/150..  Training Loss: 11065.0592..  valid Loss: 60028.0170.. \n",
      "Epoch: 116/150..  Training Loss: 11112.3965..  valid Loss: 60342.1871.. \n",
      "Epoch: 116/150..  Training Loss: 11492.2362..  valid Loss: 59667.3832.. \n",
      "Epoch: 117/150..  Training Loss: 10506.9751..  valid Loss: 60267.5110.. \n",
      "Epoch: 117/150..  Training Loss: 10960.4426..  valid Loss: 58622.9510.. \n",
      "Epoch: 117/150..  Training Loss: 11234.5545..  valid Loss: 60257.8540.. \n",
      "Epoch: 117/150..  Training Loss: 11131.8341..  valid Loss: 59160.0913.. \n",
      "Epoch: 117/150..  Training Loss: 11185.7601..  valid Loss: 60708.0746.. \n",
      "Epoch: 117/150..  Training Loss: 11051.7076..  valid Loss: 60505.7429.. \n",
      "Epoch: 118/150..  Training Loss: 10303.9648..  valid Loss: 59674.7472.. \n",
      "Epoch: 118/150..  Training Loss: 11034.5036..  valid Loss: 59918.6680.. \n",
      "Epoch: 118/150..  Training Loss: 11072.1120..  valid Loss: 60630.9798.. \n",
      "Epoch: 118/150..  Training Loss: 11134.3316..  valid Loss: 58955.2440.. \n",
      "Epoch: 118/150..  Training Loss: 11162.0120..  valid Loss: 60222.2322.. \n",
      "Epoch: 118/150..  Training Loss: 11210.4996..  valid Loss: 60246.4673.. \n",
      "Epoch: 119/150..  Training Loss: 10393.4356..  valid Loss: 60067.5650.. \n",
      "Epoch: 119/150..  Training Loss: 10913.0408..  valid Loss: 59888.5767.. \n",
      "Epoch: 119/150..  Training Loss: 11147.9025..  valid Loss: 59816.7646.. \n",
      "Epoch: 119/150..  Training Loss: 10781.2281..  valid Loss: 59804.0827.. \n",
      "Epoch: 119/150..  Training Loss: 11059.0414..  valid Loss: 59700.4013.. \n",
      "Epoch: 119/150..  Training Loss: 10893.5389..  valid Loss: 59774.9499.. \n",
      "Epoch: 120/150..  Training Loss: 10003.6302..  valid Loss: 59570.9851.. \n",
      "Epoch: 120/150..  Training Loss: 11019.6214..  valid Loss: 59528.2081.. \n",
      "Epoch: 120/150..  Training Loss: 10878.6671..  valid Loss: 59335.3580.. \n",
      "Epoch: 120/150..  Training Loss: 10983.6089..  valid Loss: 61260.9478.. \n",
      "Epoch: 120/150..  Training Loss: 10929.5922..  valid Loss: 59751.9588.. \n",
      "Epoch: 120/150..  Training Loss: 10386.3106..  valid Loss: 60490.8928.. \n",
      "Epoch: 121/150..  Training Loss: 10572.8086..  valid Loss: 60076.7990.. \n",
      "Epoch: 121/150..  Training Loss: 10919.7055..  valid Loss: 59387.3402.. \n",
      "Epoch: 121/150..  Training Loss: 10759.3937..  valid Loss: 60299.2663.. \n",
      "Epoch: 121/150..  Training Loss: 10595.0706..  valid Loss: 59522.4205.. \n",
      "Epoch: 121/150..  Training Loss: 10713.5893..  valid Loss: 59763.4506.. \n",
      "Epoch: 122/150..  Training Loss: 10110.1086..  valid Loss: 60637.1616.. \n",
      "Epoch: 122/150..  Training Loss: 10610.8032..  valid Loss: 59782.0323.. \n",
      "Epoch: 122/150..  Training Loss: 10729.0870..  valid Loss: 59488.1974.. \n",
      "Epoch: 122/150..  Training Loss: 10457.3924..  valid Loss: 59574.6289.. \n",
      "Epoch: 122/150..  Training Loss: 10548.5054..  valid Loss: 59363.4933.. \n",
      "Epoch: 122/150..  Training Loss: 10635.9206..  valid Loss: 60497.4524.. \n",
      "Epoch: 123/150..  Training Loss: 10142.3080..  valid Loss: 60421.5771.. \n",
      "Epoch: 123/150..  Training Loss: 10922.8199..  valid Loss: 59925.2713.. \n",
      "Epoch: 123/150..  Training Loss: 10556.5049..  valid Loss: 60645.5082.. \n",
      "Epoch: 123/150..  Training Loss: 10622.8983..  valid Loss: 59643.1758.. \n",
      "Epoch: 123/150..  Training Loss: 10506.7947..  valid Loss: 61083.7031.. \n",
      "Epoch: 123/150..  Training Loss: 10818.6928..  valid Loss: 60981.6420.. \n",
      "Epoch: 124/150..  Training Loss: 10387.6484..  valid Loss: 61066.8633.. \n",
      "Epoch: 124/150..  Training Loss: 10409.2469..  valid Loss: 60430.3849.. \n",
      "Epoch: 124/150..  Training Loss: 11102.2012..  valid Loss: 59313.7859.. \n",
      "Epoch: 124/150..  Training Loss: 10512.2024..  valid Loss: 60562.7976.. \n",
      "Epoch: 124/150..  Training Loss: 10499.2590..  valid Loss: 59652.2805.. \n",
      "Epoch: 124/150..  Training Loss: 10706.1747..  valid Loss: 59975.1871.. \n",
      "Epoch: 125/150..  Training Loss: 10014.8273..  valid Loss: 60372.3817.. \n",
      "Epoch: 125/150..  Training Loss: 10375.0438..  valid Loss: 59846.3097.. \n",
      "Epoch: 125/150..  Training Loss: 10521.4891..  valid Loss: 60303.9744.. \n",
      "Epoch: 125/150..  Training Loss: 10217.4699..  valid Loss: 60013.3658.. \n",
      "Epoch: 125/150..  Training Loss: 10466.6004..  valid Loss: 61067.4339.. \n",
      "Epoch: 125/150..  Training Loss: 10832.8910..  valid Loss: 60542.1648.. \n",
      "Epoch: 126/150..  Training Loss: 9708.4350..  valid Loss: 59718.3562.. \n",
      "Epoch: 126/150..  Training Loss: 10594.7301..  valid Loss: 60797.5565.. \n",
      "Epoch: 126/150..  Training Loss: 10321.6488..  valid Loss: 60349.1726.. \n",
      "Epoch: 126/150..  Training Loss: 10431.3623..  valid Loss: 61141.9045.. \n",
      "Epoch: 126/150..  Training Loss: 10494.7030..  valid Loss: 60599.6143.. \n",
      "Epoch: 126/150..  Training Loss: 10496.1373..  valid Loss: 59836.9613.. \n",
      "Epoch: 127/150..  Training Loss: 9627.7802..  valid Loss: 61086.3636.. \n",
      "Epoch: 127/150..  Training Loss: 10221.1465..  valid Loss: 60523.5781.. \n",
      "Epoch: 127/150..  Training Loss: 10438.0639..  valid Loss: 60918.2436.. \n",
      "Epoch: 127/150..  Training Loss: 10393.0744..  valid Loss: 61767.1087.. \n",
      "Epoch: 127/150..  Training Loss: 10408.7662..  valid Loss: 60815.6513.. \n",
      "Epoch: 127/150..  Training Loss: 10501.5295..  valid Loss: 60581.9762.. \n",
      "Epoch: 128/150..  Training Loss: 9854.0016..  valid Loss: 60028.3356.. \n",
      "Epoch: 128/150..  Training Loss: 10441.2213..  valid Loss: 61182.6381.. \n",
      "Epoch: 128/150..  Training Loss: 10225.5948..  valid Loss: 60626.3121.. \n",
      "Epoch: 128/150..  Training Loss: 10494.3199..  valid Loss: 60568.3942.. \n",
      "Epoch: 128/150..  Training Loss: 10466.0805..  valid Loss: 60186.6193.. \n",
      "Epoch: 129/150..  Training Loss: 9760.4536..  valid Loss: 61163.4169.. \n",
      "Epoch: 129/150..  Training Loss: 10400.9204..  valid Loss: 60919.3700.. \n",
      "Epoch: 129/150..  Training Loss: 10392.9270..  valid Loss: 59776.8544.. \n",
      "Epoch: 129/150..  Training Loss: 10238.6059..  valid Loss: 60279.3509.. \n",
      "Epoch: 129/150..  Training Loss: 10352.7938..  valid Loss: 60597.5561.. \n",
      "Epoch: 129/150..  Training Loss: 10291.2486..  valid Loss: 60531.6431.. \n",
      "Epoch: 130/150..  Training Loss: 9976.5459..  valid Loss: 60803.5380.. \n",
      "Epoch: 130/150..  Training Loss: 10403.7417..  valid Loss: 60723.1889.. \n",
      "Epoch: 130/150..  Training Loss: 10230.2047..  valid Loss: 61222.4631.. \n",
      "Epoch: 130/150..  Training Loss: 10271.2713..  valid Loss: 61122.9087.. \n",
      "Epoch: 130/150..  Training Loss: 10449.5759..  valid Loss: 60947.8164.. \n",
      "Epoch: 130/150..  Training Loss: 10313.9919..  valid Loss: 60177.3324.. \n",
      "Epoch: 131/150..  Training Loss: 9626.8143..  valid Loss: 60279.5284.. \n",
      "Epoch: 131/150..  Training Loss: 10526.6579..  valid Loss: 61486.2340.. \n",
      "Epoch: 131/150..  Training Loss: 10276.4598..  valid Loss: 60660.6939.. \n",
      "Epoch: 131/150..  Training Loss: 10261.8535..  valid Loss: 60720.0636.. \n",
      "Epoch: 131/150..  Training Loss: 10252.2799..  valid Loss: 61024.7319.. \n",
      "Epoch: 131/150..  Training Loss: 10427.7262..  valid Loss: 60200.5714.. \n",
      "Epoch: 132/150..  Training Loss: 9705.1618..  valid Loss: 60822.0135.. \n",
      "Epoch: 132/150..  Training Loss: 9958.2415..  valid Loss: 60151.6676.. \n",
      "Epoch: 132/150..  Training Loss: 10132.7067..  valid Loss: 60226.3736.. \n",
      "Epoch: 132/150..  Training Loss: 10139.9939..  valid Loss: 60913.8001.. \n",
      "Epoch: 132/150..  Training Loss: 10347.5436..  valid Loss: 61347.5479.. \n",
      "Epoch: 132/150..  Training Loss: 10473.0742..  valid Loss: 60244.4265.. \n",
      "Epoch: 133/150..  Training Loss: 9441.0162..  valid Loss: 60199.7859.. \n",
      "Epoch: 133/150..  Training Loss: 10106.6199..  valid Loss: 61202.5337.. \n",
      "Epoch: 133/150..  Training Loss: 10364.1805..  valid Loss: 60195.0494.. \n",
      "Epoch: 133/150..  Training Loss: 9775.3036..  valid Loss: 61003.2330.. \n",
      "Epoch: 133/150..  Training Loss: 10321.9706..  valid Loss: 60711.5412.. \n",
      "Epoch: 133/150..  Training Loss: 10236.5686..  valid Loss: 60719.1392.. \n",
      "Epoch: 134/150..  Training Loss: 9438.0698..  valid Loss: 59837.1058.. \n",
      "Epoch: 134/150..  Training Loss: 10109.9241..  valid Loss: 60447.3377.. \n",
      "Epoch: 134/150..  Training Loss: 10010.1704..  valid Loss: 60695.1673.. \n",
      "Epoch: 134/150..  Training Loss: 10520.3331..  valid Loss: 59957.6594.. \n",
      "Epoch: 134/150..  Training Loss: 10117.2871..  valid Loss: 61069.2209.. \n",
      "Epoch: 134/150..  Training Loss: 10019.9746..  valid Loss: 60940.6673.. \n",
      "Epoch: 135/150..  Training Loss: 9336.3415..  valid Loss: 60671.5533.. \n",
      "Epoch: 135/150..  Training Loss: 9764.7813..  valid Loss: 60869.1378.. \n",
      "Epoch: 135/150..  Training Loss: 10210.6840..  valid Loss: 60892.7564.. \n",
      "Epoch: 135/150..  Training Loss: 10072.6881..  valid Loss: 60678.9023.. \n",
      "Epoch: 135/150..  Training Loss: 10167.4307..  valid Loss: 61630.6069.. \n",
      "Epoch: 135/150..  Training Loss: 9406.7073..  valid Loss: 60905.2202.. \n",
      "Epoch: 136/150..  Training Loss: 10098.0592..  valid Loss: 60139.0121.. \n",
      "Epoch: 136/150..  Training Loss: 10080.6774..  valid Loss: 61298.5753.. \n",
      "Epoch: 136/150..  Training Loss: 9968.3376..  valid Loss: 60665.7390.. \n",
      "Epoch: 136/150..  Training Loss: 10091.0350..  valid Loss: 61431.3686.. \n",
      "Epoch: 136/150..  Training Loss: 9931.2357..  valid Loss: 61080.4496.. \n",
      "Epoch: 137/150..  Training Loss: 9488.0768..  valid Loss: 60632.9151.. \n",
      "Epoch: 137/150..  Training Loss: 9922.7727..  valid Loss: 60098.5007.. \n",
      "Epoch: 137/150..  Training Loss: 9872.0735..  valid Loss: 60009.0572.. \n",
      "Epoch: 137/150..  Training Loss: 10131.1328..  valid Loss: 60371.0703.. \n",
      "Epoch: 137/150..  Training Loss: 10089.4829..  valid Loss: 61408.3729.. \n",
      "Epoch: 137/150..  Training Loss: 9907.8058..  valid Loss: 60093.0224.. \n",
      "Epoch: 138/150..  Training Loss: 9679.1884..  valid Loss: 60807.8100.. \n",
      "Epoch: 138/150..  Training Loss: 10130.3978..  valid Loss: 60350.5526.. \n",
      "Epoch: 138/150..  Training Loss: 10189.1106..  valid Loss: 60975.3619.. \n",
      "Epoch: 138/150..  Training Loss: 10248.4226..  valid Loss: 60543.5955.. \n",
      "Epoch: 138/150..  Training Loss: 10195.2197..  valid Loss: 60226.3075.. \n",
      "Epoch: 138/150..  Training Loss: 9956.8184..  valid Loss: 61968.6012.. \n",
      "Epoch: 139/150..  Training Loss: 9271.5203..  valid Loss: 60754.0788.. \n",
      "Epoch: 139/150..  Training Loss: 10037.4172..  valid Loss: 60717.3260.. \n",
      "Epoch: 139/150..  Training Loss: 9967.9839..  valid Loss: 60806.5763.. \n",
      "Epoch: 139/150..  Training Loss: 9915.4880..  valid Loss: 60659.6080.. \n",
      "Epoch: 139/150..  Training Loss: 9851.7575..  valid Loss: 61753.0053.. \n",
      "Epoch: 139/150..  Training Loss: 9975.2016..  valid Loss: 60413.8878.. \n",
      "Epoch: 140/150..  Training Loss: 9410.1522..  valid Loss: 60266.5952.. \n",
      "Epoch: 140/150..  Training Loss: 10061.7781..  valid Loss: 59894.5025.. \n",
      "Epoch: 140/150..  Training Loss: 10020.6801..  valid Loss: 61455.7564.. \n",
      "Epoch: 140/150..  Training Loss: 9885.8022..  valid Loss: 61305.1364.. \n",
      "Epoch: 140/150..  Training Loss: 9903.1296..  valid Loss: 60745.8658.. \n",
      "Epoch: 140/150..  Training Loss: 10144.0197..  valid Loss: 61176.4031.. \n",
      "Epoch: 141/150..  Training Loss: 9277.9521..  valid Loss: 61027.6474.. \n",
      "Epoch: 141/150..  Training Loss: 9826.7496..  valid Loss: 60770.8587.. \n",
      "Epoch: 141/150..  Training Loss: 9830.0432..  valid Loss: 60593.1001.. \n",
      "Epoch: 141/150..  Training Loss: 9710.7043..  valid Loss: 61502.0739.. \n",
      "Epoch: 141/150..  Training Loss: 9582.8844..  valid Loss: 61051.9556.. \n",
      "Epoch: 141/150..  Training Loss: 9771.9532..  valid Loss: 60957.0959.. \n",
      "Epoch: 142/150..  Training Loss: 9438.7555..  valid Loss: 60816.9290.. \n",
      "Epoch: 142/150..  Training Loss: 9614.2287..  valid Loss: 60675.6179.. \n",
      "Epoch: 142/150..  Training Loss: 9711.3749..  valid Loss: 60385.7798.. \n",
      "Epoch: 142/150..  Training Loss: 9717.7588..  valid Loss: 60992.4620.. \n",
      "Epoch: 142/150..  Training Loss: 9989.3152..  valid Loss: 60846.7436.. \n",
      "Epoch: 142/150..  Training Loss: 9784.1359..  valid Loss: 61518.5469.. \n",
      "Epoch: 143/150..  Training Loss: 9376.6272..  valid Loss: 60592.0838.. \n",
      "Epoch: 143/150..  Training Loss: 9629.4771..  valid Loss: 60782.8338.. \n",
      "Epoch: 143/150..  Training Loss: 9612.3998..  valid Loss: 60867.1715.. \n",
      "Epoch: 143/150..  Training Loss: 9426.8710..  valid Loss: 60584.4570.. \n",
      "Epoch: 143/150..  Training Loss: 9574.8719..  valid Loss: 60908.8604.. \n",
      "Epoch: 144/150..  Training Loss: 9138.0489..  valid Loss: 60921.3601.. \n",
      "Epoch: 144/150..  Training Loss: 9595.2402..  valid Loss: 61406.5469.. \n",
      "Epoch: 144/150..  Training Loss: 10042.6668..  valid Loss: 61910.0891.. \n",
      "Epoch: 144/150..  Training Loss: 9669.0177..  valid Loss: 61504.5195.. \n",
      "Epoch: 144/150..  Training Loss: 9645.0055..  valid Loss: 60684.8253.. \n",
      "Epoch: 144/150..  Training Loss: 9533.9159..  valid Loss: 60524.4975.. \n",
      "Epoch: 145/150..  Training Loss: 9099.6948..  valid Loss: 61043.0021.. \n",
      "Epoch: 145/150..  Training Loss: 9506.1330..  valid Loss: 60727.3161.. \n",
      "Epoch: 145/150..  Training Loss: 9443.1941..  valid Loss: 61169.7191.. \n",
      "Epoch: 145/150..  Training Loss: 9787.8626..  valid Loss: 60533.5075.. \n",
      "Epoch: 145/150..  Training Loss: 9912.9735..  valid Loss: 61423.6385.. \n",
      "Epoch: 145/150..  Training Loss: 9958.4449..  valid Loss: 61454.1925.. \n",
      "Epoch: 146/150..  Training Loss: 9274.5653..  valid Loss: 61022.2227.. \n",
      "Epoch: 146/150..  Training Loss: 10077.5754..  valid Loss: 60716.4780.. \n",
      "Epoch: 146/150..  Training Loss: 10156.6576..  valid Loss: 61359.5266.. \n",
      "Epoch: 146/150..  Training Loss: 9814.0089..  valid Loss: 61280.8310.. \n",
      "Epoch: 146/150..  Training Loss: 9616.3072..  valid Loss: 61465.8246.. \n",
      "Epoch: 146/150..  Training Loss: 9470.2055..  valid Loss: 60396.7099.. \n",
      "Epoch: 147/150..  Training Loss: 9222.1791..  valid Loss: 59956.7209.. \n",
      "Epoch: 147/150..  Training Loss: 9725.2469..  valid Loss: 60915.5057.. \n",
      "Epoch: 147/150..  Training Loss: 9837.0053..  valid Loss: 61140.2759.. \n",
      "Epoch: 147/150..  Training Loss: 9574.9957..  valid Loss: 61755.9091.. \n",
      "Epoch: 147/150..  Training Loss: 9684.0118..  valid Loss: 60667.6580.. \n",
      "Epoch: 147/150..  Training Loss: 9657.3289..  valid Loss: 61743.2298.. \n",
      "Epoch: 148/150..  Training Loss: 8901.9391..  valid Loss: 60811.2962.. \n",
      "Epoch: 148/150..  Training Loss: 9611.3822..  valid Loss: 61488.5234.. \n",
      "Epoch: 148/150..  Training Loss: 9794.5548..  valid Loss: 60290.7475.. \n",
      "Epoch: 148/150..  Training Loss: 9328.0421..  valid Loss: 61250.1946.. \n",
      "Epoch: 148/150..  Training Loss: 9534.2915..  valid Loss: 60476.8629.. \n",
      "Epoch: 148/150..  Training Loss: 9717.8937..  valid Loss: 60778.5107.. \n",
      "Epoch: 149/150..  Training Loss: 9106.0821..  valid Loss: 60884.9066.. \n",
      "Epoch: 149/150..  Training Loss: 9571.7491..  valid Loss: 60896.4535.. \n",
      "Epoch: 149/150..  Training Loss: 9373.2587..  valid Loss: 61802.9023.. \n",
      "Epoch: 149/150..  Training Loss: 9471.2305..  valid Loss: 60591.5163.. \n",
      "Epoch: 149/150..  Training Loss: 9752.7044..  valid Loss: 61267.5337.. \n",
      "Epoch: 149/150..  Training Loss: 9535.1634..  valid Loss: 61959.8903.. \n",
      "Epoch: 150/150..  Training Loss: 8963.6365..  valid Loss: 61411.7905.. \n",
      "Epoch: 150/150..  Training Loss: 9545.3043..  valid Loss: 61591.1307.. \n",
      "Epoch: 150/150..  Training Loss: 9508.8568..  valid Loss: 61720.9666.. \n",
      "Epoch: 150/150..  Training Loss: 9472.0090..  valid Loss: 60844.6942.. \n",
      "Epoch: 150/150..  Training Loss: 9558.4615..  valid Loss: 60495.7472.. \n",
      "Epoch: 150/150..  Training Loss: 9034.1171..  valid Loss: 61683.4006.. \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 150\n",
    "\n",
    "running_loss = 0\n",
    "steps = 0\n",
    "print_every = 15\n",
    "decoded = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in trainloader:\n",
    "        steps += 1\n",
    "        img, _ = data\n",
    "        img = img.cuda()\n",
    "        \n",
    "        decoded, mu, logvar = model(img)\n",
    "        loss = loss_function(decoded, img, mu, logvar)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_loss = validation(model, validloader)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\n",
    "                  \"Training Loss: {:.4f}.. \".format(running_loss/print_every),\n",
    "                  \"valid Loss: {:.4f}.. \".format(valid_loss/len(validloader)))\n",
    "            running_loss = 0\n",
    "    if epoch % 10 == 0:\n",
    "        save_im(decoded, 'epoch '+str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': running_loss/print_every,\n",
    "            'val_loss': valid_loss/len(validloader)\n",
    "            }, \"./generated_data_vae/ezperiment_13_0.7_mean_mse/model_{}_{}.pkl\".format(epoch, steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder(data_dir + 'test', transform=loader)\n",
    "testloader = torch.utils.data.DataLoader(valid_data, batch_size=256)\n",
    "\n",
    "img, _ = iter(testloader).next()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img.cuda())\n",
    "    save_im(output[0], 'test_output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
